title,authors,abstract,link,source_file
Topological nontrivial berry phase in altermagnet CrSb,"Jianhua Du, Xin Peng, Yuzhi Wang, Shengnan Zhang, Yuran Sun, Chunxiang Wu, Tingyu Zhou, Le Liu, Hangdong Wang, Jinhu Yang, Bin Chen, Chuanying Xi, Zhiwei Jiao, Quansheng Wu, Minghu Fang","The study of topological properties in magnetic materials has long been one of the forefront research areas in condensed matter physics. CrSb, as a prototypical candidate material for altermagnetism, has attracted significant attention due to its unique magnetic properties. This system provides a novel platform for exploring the intrinsic relationship between altermagnetic order and exotic topological states. In this study, we combine systematic electrical transport experiments with first-principles calculations to investigate the possible realization mechanisms of topological semimetal states in CrSb and their manifestations in quantum transport phenomena. Our high field magneto-transport measurements reveal that the magnetoresistance of CrSb exhibits no sign of saturation up to 35 T, following a distinct power-law dependence with an exponent of 1.48. The nonlinear Hall resistivity further indicates a multiband charge transport mechanism. Under high magnetic fields, we observe pronounced Shubnikov-de Haas (SdH) quantum oscillations and discernible Zeeman-effect-induced band splitting at 1.6 K. Systematic Fermi surface and band calculations combined with Berry phase analysis confirm the nontrivial topological character of this material (with a Berry phase approaching π). These findings not only provide crucial experimental evidence for understanding the electronic structure of CrSb, but also establish an important foundation for investigating topological quantum states in altermagnets. △ Less",https://arxiv.org/abs/2509.21303,arxiv_attention_page0.csv
Vision-Intelligence-Enabled Beam Tracking for Cross-Interface Water-Air Optical Wireless Communications,"Tianqi Mao, Jiayue Liu, Weijie Liu, Dezhi Zheng, Zhaocheng Wang","The escalating development of oceanic applications like underwater surveillance and mineral exploration, is motivating real-time wireless backhaul of the considerable observation data. Such prospects can be hardly realized by the narrowband acoustic approach. Alternatively, optical wireless communication (OWC) has emerged as a promising solution for maritime and underwater applications due to its great potential for broadband underwater transmission. However, the implementations of water-air OWC can be rather challenging, especially when penetrating the fluctuating interface, where the direction of refracted signals changes dynamically, causing severe beam misalignment with airborne stations. This has necessitated real-time transceiver alignment adaptable to the sophisticated oceanic environment, which has yet to be addressed. Against this background, this paper establishes a mathematical channel model for water-air optical wireless transmission across the fluctuating sea surface. Based on the model, we propose a vision-based beam tracking algorithm that leverages artificial intelligence (AI) methods for dynamic channel prediction. The proposed algorithm integrates a convolutional neural network (CNN) with bi-directional long short-term memory (Bi-LSTM), which further incorporates the attention mechanism to effectively extract critical spatio-temporal features from the vision data. The numerical simulation results show that the proposed algorithm can outperform its classical counterparts in maintaining receiving signal strength and supressing the vision noises, which demonstrates its robustness against the the harsh conditions of water-air OWC systems. △ Less",https://arxiv.org/abs/2509.21290,arxiv_attention_page0.csv
"Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond","Dingzirui Wang, Xuanliang Zhang, Keyan Xu, Qingfu Zhu, Wanxiang Che, Yang Deng","Existing research indicates that the output of Chain-of-Thought (CoT) is significantly affected by input perturbations. Although many methods aim to mitigate such impact by optimizing prompts, a theoretical explanation of how these perturbations influence CoT outputs remains an open area of research. This gap limits our in-depth understanding of how input perturbations propagate during the reasoning process and hinders further improvements in prompt optimization methods. Therefore, in this paper, we theoretically analyze the effect of input perturbations on the fluctuation of CoT outputs. We first derive an upper bound for input perturbations under the condition that the output fluctuation is within an acceptable range, based on which we prove that: (i) This upper bound is positively correlated with the number of reasoning steps in the CoT; (ii) Even an infinitely long reasoning process cannot eliminate the impact of input perturbations. We then apply these conclusions to the Linear Self- Attention (LSA) model, which can be viewed as a simplified version of the Transformer. For the LSA model, we prove that the upper bound for input perturbation is negatively correlated with the norms of the input embedding and hidden state vectors. To validate this theoretical analysis, we conduct experiments on three mainstream datasets and four mainstream models. The experimental results align with our theoretical analysis, empirically demonstrating the correctness of our findings. △ Less",https://arxiv.org/abs/2509.21284,arxiv_attention_page0.csv
Does FLUX Already Know How to Perform Physically Plausible Image Composition?,"Shilin Lu, Zhuming Lian, Zihan Zhou, Shaocong Zhang, Chen Zhao, Adams Wai-Kin Kong","Image composition aims to seamlessly insert a user-specified object into a new scene, but existing models struggle with complex lighting (e.g., accurate shadows, water reflections) and diverse, high-resolution inputs. Modern text-to-image diffusion models (e.g., SD3.5, FLUX) already encode essential physical and resolution priors, yet lack a framework to unleash them without resorting to latent inversion, which often locks object poses into contextually inappropriate orientations, or brittle attention surgery. We propose SHINE, a training-free framework for Seamless, High-fidelity Insertion with Neutralized Errors. SHINE introduces manifold-steered anchor loss, leveraging pretrained customization adapters (e.g., IP-Adapter) to guide latents for faithful subject representation while preserving background integrity. Degradation-suppression guidance and adaptive background blending are proposed to further eliminate low-quality outputs and visible seams. To address the lack of rigorous benchmarks, we introduce ComplexCompo, featuring diverse resolutions and challenging conditions such as low lighting, strong illumination, intricate shadows, and reflective surfaces. Experiments on ComplexCompo and DreamEditBench show state-of-the-art performance on standard metrics (e.g., DINOv2) and human-aligned scores (e.g., DreamSim, ImageReward, VisionReward). Code and benchmark will be publicly available upon publication. △ Less",https://arxiv.org/abs/2509.21278,arxiv_attention_page0.csv
Learning to Look: CognitiveAttentionAlignment with Vision-Language Models,"Ryan L. Yang, Dipkamal Bhusal, Nidhi Rastogi","Convolutional Neural Networks (CNNs) frequently ""cheat"" by exploiting superficial correlations, raising concerns about whether they make predictions for the right reasons. Inspired by cognitive science, which highlights the role of attention in robust human perception, recent methods have sought to guide model attention using concept-based supervision and explanation regularization. However, these techniques depend on labor-intensive, expert-provided annotations, limiting their scalability. We propose a scalable framework that leverages vision-language models to automatically generate semantic attention maps using natural language prompts. By introducing an auxiliary loss that aligns CNN attention with these language-guided maps, our approach promotes more reliable and cognitively plausible decision-making without manual annotation. Experiments on challenging datasets, ColoredMNIST and DecoyMNIST, show that our method achieves state-of-the-art performance on ColorMNIST and remains competitive with annotation-heavy baselines on DecoyMNIST, demonstrating improved generalization, reduced shortcut reliance, and model attention that better reflects human intuition. △ Less",https://arxiv.org/abs/2509.21247,arxiv_attention_page0.csv
Sigma: Semantically Informative Pre-training for Skeleton-based Sign Language Understanding,"Muxin Pu, Mei Kuan Lim, Chun Yong Chong, Chen Change Loy","Pre-training has proven effective for learning transferable features in sign language understanding (SLU) tasks. Recently, skeleton-based methods have gained increasing attention because they can robustly handle variations in subjects and backgrounds without being affected by appearance or environmental factors. Current SLU methods continue to face three key limitations: 1) weak semantic grounding, as models often capture low-level motion patterns from skeletal data but struggle to relate them to linguistic meaning; 2) imbalance between local details and global context, with models either focusing too narrowly on fine-grained cues or overlooking them for broader context; and 3) inefficient cross-modal learning, as constructing semantically aligned representations across modalities remains difficult. To address these, we propose Sigma, a unified skeleton-based SLU framework featuring: 1) a sign-aware early fusion mechanism that facilitates deep interaction between visual and textual modalities, enriching visual features with linguistic context; 2) a hierarchical alignment learning strategy that jointly maximises agreements across different levels of paired features from different modalities, effectively capturing both fine-grained details and high-level semantic relationships; and 3) a unified pre-training framework that combines contrastive learning, text matching and language modelling to promote semantic consistency and generalisation. Sigma achieves new state-of-the-art results on isolated sign language recognition, continuous sign language recognition, and gloss-free sign language translation on multiple benchmarks spanning different sign and spoken languages, demonstrating the impact of semantically informative pre-training and the effectiveness of skeletal data as a stand-alone solution for SLU. △ Less",https://arxiv.org/abs/2509.21223,arxiv_attention_page0.csv
MeanSE: Efficient Generative Speech Enhancement with Mean Flows,"Jiahe Wang, Hongyu Wang, Wei Wang, Lei Yang, Chenda Li, Wangyou Zhang, Lufen Tan, Yanmin Qian","Speech enhancement (SE) improves degraded speech's quality, with generative models like flow matching gaining attention for their outstanding perceptual quality. However, the flow-based model requires multiple numbers of function evaluations (NFEs) to achieve stable and satisfactory performance, leading to high computational load and poor 1-NFE performance. In this paper, we propose MeanSE, an efficient generative speech enhancement model using mean flows, which models the average velocity field to achieve high-quality 1-NFE enhancement. Experimental results demonstrate that our proposed MeanSE significantly outperforms the flow matching baseline with a single NFE, exhibiting extremely better out-of-domain generalization capabilities. △ Less",https://arxiv.org/abs/2509.21214,arxiv_attention_page0.csv
"Mixture of Thoughts: Learning to Aggregate What Experts Think, Not Just What They Say","Jacob Fein-Ashley, Dhruv Parikh, Rajgopal Kannan, Viktor Prasanna","Open-source Large Language Models (LLMs) increasingly specialize by domain (e.g., math, code, general reasoning), motivating systems that leverage complementary strengths across models. Prior multi-LLM approaches either (i) route a query to one or a few experts and generate independently, (ii) aggregate outputs from each model via costly multi-turn exchanges, or (iii) fuse weights into a single model-typically requiring architectural homogeneity. We introduce Mixture of Thoughts (MoT), a simple method for latent-level collaboration among heterogeneous experts under a global routing scheme. For each query, a lightweight router selects top-$K$ experts and designates a primary expert; uniformly placed interaction layers project hidden states into a shared latent space where the primary expert performs cross- attention over its active (selected) peers. Pre-trained experts remain frozen; only the router and the lightweight interaction layers are trained with a novel joint training objective that improves both the expert selection and inter-expert collaboration. Across five in-distribution (ID) and three out-of-distribution (OOD) benchmarks, MoT surpasses the current routing and aggregation-based state-of-the-art, Avengers, by $+0.38\%$ and $+2.92\%$, respectively. Further, MoT significantly outperforms the best-performing single model. It achieves this with single-pass inference, runtime comparable to routing baselines, and none of the overheads of iterative aggregation. MoT offers a simple latent-space mechanism for combining heterogeneous LLMs, a practical step toward broader multi-LLM collaboration. Our code is publicly available at https://github.com/jacobfa/mot. △ Less",https://arxiv.org/abs/2509.21164,arxiv_attention_page0.csv
Distributed Specialization: Rare-Token Neurons in Large Language Models,"Jing Liu, Haozheng Wang, Yueheng Li","Large language models (LLMs) struggle with representing and generating rare tokens despite their importance in specialized domains. We investigate whether LLMs develop internal specialization mechanisms through discrete modular architectures or distributed parameter-level differentiation. Through systematic analysis of final-layer MLP neurons across multiple model families, we discover that rare-token processing emerges via \textit{distributed specialization}: functionally coordinated but spatially distributed subnetworks that exhibit three distinct organizational principles. First, we identify a reproducible three-regime influence hierarchy comprising highly influential plateau neurons(also termed as rare-token neurons), power-law decay neurons, and minimally contributing neurons, which is absent in common-token processing. Second, plateau neurons demonstrate coordinated activation patterns (reduced effective dimensionality) while remaining spatially distributed rather than forming discrete clusters. Third, these specialized mechanisms are universally accessible through standard attention pathways without requiring dedicated routing circuits. Training dynamics reveal that functional specialization emerges gradually through parameter differentiation, with specialized neurons developing increasingly heavy-tailed weight correlation spectra consistent with Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs process rare-tokens through distributed coordination within shared architectures rather than mixture-of-experts-style modularity. These results provide insights for interpretable model editing, computational efficiency optimization, and understanding emergent functional organization in transformer networks. △ Less",https://arxiv.org/abs/2509.21163,arxiv_attention_page0.csv
DATS: Distance-Aware Temperature Scaling for Calibrated Class-Incremental Learning,"Giuseppe Serra, Florian Buettner","Continual Learning (CL) is recently gaining increasing attention for its ability to enable a single model to learn incrementally from a sequence of new classes. In this scenario, it is important to keep consistent predictive performance across all the classes and prevent the so-called Catastrophic Forgetting (CF). However, in safety-critical applications, predictive performance alone is insufficient. Predictive models should also be able to reliably communicate their uncertainty in a calibrated manner - that is, with confidence scores aligned to the true frequencies of target events. Existing approaches in CL address calibration primarily from a data-centric perspective, relying on a single temperature shared across all tasks. Such solutions overlook task-specific differences, leading to large fluctuations in calibration error across tasks. For this reason, we argue that a more principled approach should adapt the temperature according to the distance to the current task. However, the unavailability of the task information at test time/during deployment poses a major challenge to achieve the intended objective. For this, we propose Distance-Aware Temperature Scaling (DATS), which combines prototype-based distance estimation with distance-aware calibration to infer task proximity and assign adaptive temperatures without prior task information. Through extensive empirical evaluation on both standard benchmarks and real-world, imbalanced datasets taken from the biomedical domain, our approach demonstrates to be stable, reliable and consistent in reducing calibration error across tasks compared to state-of-the-art approaches. △ Less",https://arxiv.org/abs/2509.21161,arxiv_attention_page0.csv
WAVECLIP: Wavelet Tokenization for Adaptive-Resolution CLIP,"Moshe Kimhi, Erez Koifman, Ehud Rivlin, Eli Schwartz, Chaim Baskin","We introduce WAVECLIP, a single unified model for adaptive resolution inference in CLIP, enabled by wavelet-based tokenization. WAVECLIP replaces standard patch embeddings with a multi-level wavelet decomposition, enabling the model to process images coarse to fine while naturally supporting multiple resolutions within the same model. At inference time, the model begins with low resolution tokens and refines only when needed, using key-value caching and causal cross-level attention to reuse computation, effectively introducing to the model only new information when needed. We evaluate WAVECLIP in zero-shot classification, demonstrating that a simple confidence-based gating mechanism enables adaptive early exits. This allows users to dynamically choose a compute-accuracy trade-off using a single deployed model. Our approach requires only lightweight distillation from a frozen CLIP teacher and achieves competitive accuracy with significant computational savings. △ Less",https://arxiv.org/abs/2509.21153,arxiv_attention_page0.csv
CAD-Tokenizer: Towards Text-based CAD Prototyping via Modality-Specific Tokenization,"Ruiyu Wang, Shizhao Sun, Weijian Ma, Jiang Bian","Computer-Aided Design (CAD) is a foundational component of industrial prototyping, where models are defined not by raw coordinates but by construction sequences such as sketches and extrusions. This sequential structure enables both efficient prototype initialization and subsequent editing. Text-guided CAD prototyping, which unifies Text-to-CAD generation and CAD editing, has the potential to streamline the entire design pipeline. However, prior work has not explored this setting, largely because standard large language model (LLM) tokenizers decompose CAD sequences into natural-language word pieces, failing to capture primitive-level CAD semantics and hindering attention modules from modeling geometric structure. We conjecture that a multimodal tokenization strategy, aligned with CAD's primitive and structural nature, can provide more effective representations. To this end, we propose CAD-Tokenizer, a framework that represents CAD data with modality-specific tokens using a sequence-based VQ-VAE with primitive-level pooling and constrained decoding. This design produces compact, primitive-aware representations that align with CAD's structural nature. Applied to unified text-guided CAD prototyping, CAD-Tokenizer significantly improves instruction following and generation quality, achieving better quantitative and qualitative performance over both general-purpose LLMs and task-specific baselines. △ Less",https://arxiv.org/abs/2509.21150,arxiv_attention_page0.csv
Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems,"Junfeng Yan, Biao Wu, Meng Fang, Ling Chen","Multimodal agents have demonstrated strong performance in general GUI interactions, but their application in automotive systems has been largely unexplored. In-vehicle GUIs present distinct challenges: drivers' limited attention , strict safety requirements, and complex location-based interaction patterns. To address these challenges, we introduce Automotive-ENV, the first high-fidelity benchmark and interaction environment tailored for vehicle GUIs. This platform defines 185 parameterized tasks spanning explicit control, implicit intent understanding, and safety-aware tasks, and provides structured multimodal observations with precise programmatic checks for reproducible evaluation. Building on this benchmark, we propose ASURADA, a geo-aware multimodal agent that integrates GPS-informed context to dynamically adjust actions based on location, environmental conditions, and regional driving norms. Experiments show that geo-aware information significantly improves success on safety-aware tasks, highlighting the importance of location-based context in automotive environments. We will release Automotive-ENV, complete with all tasks and benchmarking tools, to further the development of safe and adaptive in-vehicle agents. △ Less",https://arxiv.org/abs/2509.21143,arxiv_attention_page0.csv
Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models,"Suaiba Amina Salahuddin, Teresa Dorszewski, Marit Almenning Martiniussen, Tone Hovda, Antonio Portaluri, Solveig Thrun, Michael Kampffmeyer, Elisabeth Wetzer, Kristoffer Wickstrøm, Robert Jenssen","Understanding what deep learning (DL) models learn is essential for the safe deployment of artificial intelligence (AI) in clinical settings. While previous work has focused on pixel-based explainability methods, less attention has been paid to the textual concepts learned by these models, which may better reflect the reasoning used by clinicians. We introduce Mammo-CLIP Dissect, the first concept-based explainability framework for systematically dissecting DL vision models trained for mammography. Leveraging a mammography-specific vision-language model (Mammo-CLIP) as a ""dissector,"" our approach labels neurons at specified layers with human-interpretable textual concepts and quantifies their alignment to domain knowledge. Using Mammo-CLIP Dissect, we investigate three key questions: (1) how concept learning differs between DL vision models trained on general image datasets versus mammography-specific datasets; (2) how fine-tuning for downstream mammography tasks affects concept specialisation; and (3) which mammography-relevant concepts remain underrepresented. We show that models trained on mammography data capture more clinically relevant concepts and align more closely with radiologists' workflows than models not trained on mammography data. Fine-tuning for task-specific classification enhances the capture of certain concept categories (e.g., benign calcifications) but can reduce coverage of others (e.g., density-related features), indicating a trade-off between specialisation and generalisation. Our findings show that Mammo-CLIP Dissect provides insights into how convolutional neural networks (CNNs) capture mammography-specific knowledge. By comparing models across training data and fine-tuning regimes, we reveal how domain-specific training and task-specific adaptation shape concept learning. Code and concept set are available: https://github.com/Suaiba/Mammo-CLIP-Dissect. △ Less",https://arxiv.org/abs/2509.21102,arxiv_attention_page0.csv
VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception,"Ziang Yan, Xinhao Li, Yinan He, Zhengrong Yue, Xiangyu Zeng, Yali Wang, Yu Qiao, Limin Wang, Yi Wang","Inducing reasoning in multimodal large language models (MLLMs) is critical for achieving human-level perception and understanding. Existing methods mainly leverage LLM reasoning to analyze parsed visuals, often limited by static perception stages. This paper introduces Visual Test-Time Scaling (VTTS), a novel approach to enhance MLLMs' reasoning via iterative perception during inference. VTTS mimics humans' hierarchical attention by progressively refining focus on high-confidence spatio-temporal regions, guided by updated textual predictions. Specifically, VTTS employs an Iterative Perception (ITP) mechanism, incorporating reinforcement learning with spatio-temporal supervision to optimize reasoning. To support this paradigm, we also present VTTS-80K, a dataset tailored for iterative perception. These designs allows a MLLM to enhance its performance by increasing its perceptual compute. Extensive experiments validate VTTS's effectiveness and generalization across diverse tasks and benchmarks. Our newly introduced Videochat-R1.5 model has achieved remarkable improvements, with an average increase of over 5\%, compared to robust baselines such as Qwen2.5VL-3B and -7B, across more than 15 benchmarks that encompass video conversation, video reasoning, and spatio-temporal perception. △ Less",https://arxiv.org/abs/2509.21100,arxiv_attention_page0.csv
TyphoonMLA: A Mixed Naive-Absorb MLA Kernel For Shared Prefix,"Ahmet Caner Yüzügüler, Ahmet Çelik, Jiawei Zhuang, Lukas Cavigelli","Multi-Head Latent Attention (MLA) is a recent attention mechanism adopted in state-of-the-art LLMs such as DeepSeek-v3 and Kimi K2. Thanks to its novel formulation, MLA allows two functionally equivalent but computationally distinct kernel implementations: naive and absorb. While the naive kernels (e.g., FlashAttention) are typically preferred in training and prefill for their computational efficiency, existing decoding kernels (e.g., FlashMLA) rely on the absorb method to minimize HBM bandwidth usage. However, the compute-bound nature of the absorb implementations prohibits performance benefits from data reuse opportunities in attention calculations, such as shared prefixes. In this work, we introduce TyphoonMLA, a hybrid approach that combines naive and absorb formulations to harness the strengths of both. TyphoonMLA effectively leverages the shared prefix by applying the naive formulation to the compute-bound parts of attention calculations, while reducing the bandwidth requirements for non-shared parts by using the absorb formulation. As a result, TyphoonMLA improves the throughput of attention calculations in MLA architectures by up to 3x and 3.24x on NPU and GPUs, with only a 3% overhead in HBM size. △ Less",https://arxiv.org/abs/2509.21081,arxiv_attention_page0.csv
Communication Bias in Large Language Models: A Regulatory Perspective,"Adrian Kuenzler, Stefan Schmid","Large language models (LLMs) are increasingly central to many applications, raising concerns about bias, fairness, and regulatory compliance. This paper reviews risks of biased outputs and their societal impact, focusing on frameworks like the EU's AI Act and the Digital Services Act. We argue that beyond constant regulation, stronger attention to competition and design governance is needed to ensure fair, trustworthy AI. This is a preprint of the Communications of the ACM article of the same title. △ Less",https://arxiv.org/abs/2509.21075,arxiv_attention_page0.csv
EnGraf-Net: Multiple Granularity Branch Network with Fine-Coarse Graft Grained for Classification Task,"Riccardo La Grassa, Ignazio Gallo, Nicola Landro","Fine-grained classification models are designed to focus on the relevant details necessary to distinguish highly similar classes, particularly when intra-class variance is high and inter-class variance is low. Most existing models rely on part annotations such as bounding boxes, part locations, or textual attributes to enhance classification performance, while others employ sophisticated techniques to automatically extract attention maps. We posit that part-based approaches, including automatic cropping methods, suffer from an incomplete representation of local features, which are fundamental for distinguishing similar objects. While fine-grained classification aims to recognize the leaves of a hierarchical structure, humans recognize objects by also forming semantic associations. In this paper, we leverage semantic associations structured as a hierarchy (taxonomy) as supervised signals within an end-to-end deep neural network model, termed EnGraf-Net. Extensive experiments on three well-known datasets CIFAR-100, CUB-200-2011, and FGVC-Aircraft demonstrate the superiority of EnGraf-Net over many existing fine-grained models, showing competitive performance with the most recent state-of-the-art approaches, without requiring cropping techniques or manual annotations. △ Less",https://arxiv.org/abs/2509.21061,arxiv_attention_page0.csv
Measuring Audio's Impact on Correctness: Audio-Contribution-Aware Post-Training of Large Audio Language Models,"Haolin He, Xingjian Du, Renhe Sun, Zheqi Dai, Yujia Xiao, Mingru Yang, Jiayi Zhou, Xiquan Li, Zhengxi Liu, Zining Liang, Chunyat Wu, Qianhua He, Tan Lee, Xie Chen, Weilong Zheng, Weiqiang Wang, Mark Plumbley, Jian Liu, Qiuqiang Kong","Large Audio Language Models (LALMs) represent an important frontier in multimodal AI, addressing diverse audio tasks. Recently, post-training of LALMs has received increasing attention due to significant performance improvements over foundation models. While single-stage post-training such as reinforcement learning (RL) has demonstrated promising results, multi-stage approaches such as supervised fine-tuning (SFT) followed by RL remain suboptimal. The allocation of data across multiple training stages to maximize LALM capabilities has not been fully explored, and large-scale, high-quality datasets for such research are also lacking. To address these problems, we firstly present AudioMCQ, a comprehensive audio multiple-choice question dataset comprising 571k samples with two kinds of chain-of-thought annotations. Secondly, we investigate the prevalent zero audio-contribution phenomenon in LALMs, where models derive correct answers solely from textual information without processing audio content. We propose Audio-Contribution Filtering to partition data into weak and strong audio-contribution subsets. Based on these insights, we develop two effective post-training paradigms: Weak-to-Strong (SFT on weak audio-contribution data followed by RL on strong audio-contribution data) and Mixed-to-Strong (SFT on mixed audio-contribution data followed by RL on strong audio-contribution data). We achieve first place in the DCASE 2025 Audio-Question-Answering challenge by using AudioMCQ. Additionally, leveraging our dataset with different training strategies, we achieve 78.2\% on MMAU-test-mini, 75.6\% on MMAU, 67.1\% on MMAR, and 70.7\% on MMSU, establishing new state-of-the-art performance across these benchmarks. △ Less",https://arxiv.org/abs/2509.21060,arxiv_attention_page0.csv
Structure-Attribute Transformations with Markov Chain Boost Graph Domain Adaptation,"Zhen Liu, Yongtao Zhang, Shaobo Ren, Yuxin You","Graph domain adaptation has gained significant attention in label-scarce scenarios across different graph domains. Traditional approaches to graph domain adaptation primarily focus on transforming node attributes over raw graph structures and aligning the distributions of the transformed node features across networks. However, these methods often struggle with the underlying structural heterogeneity between distinct graph domains, which leads to suboptimal distribution alignment. To address this limitation, we propose Structure-Attribute Transformation with Markov Chain (SATMC), a novel framework that sequentially aligns distributions across networks via both graph structure and attribute transformations. To mitigate the negative influence of domain-private information and further enhance the model's generalization, SATMC introduces a private domain information reduction mechanism and an empirical Wasserstein distance. Theoretical proofs suggest that SATMC can achieve a tighter error bound for cross-network node classification compared to existing graph domain adaptation methods. Extensive experiments on nine pairs of publicly available cross-domain datasets show that SATMC outperforms state-of-the-art methods in the cross-network node classification task. The code is available at https://github.com/GiantZhangYT/SATMC. △ Less",https://arxiv.org/abs/2509.21059,arxiv_attention_page0.csv
Behind RoPE: How Does Causal Mask Encode Positional Information?,"Junu Kim, Xiao Liu, Zhenghao Lin, Lei Ji, Yeyun Gong, Edward Choi","While explicit positional encodings such as RoPE are a primary source of positional information in Transformer decoders, the causal mask also provides positional information. In this work, we prove that the causal mask can induce position-dependent patterns in attention scores, even without parameters or causal dependency in the input. Our theoretical analysis indicates that the induced attention pattern tends to favor nearby query-key pairs, mirroring the behavior of common positional encodings. Empirical analysis confirms that trained models exhibit the same behavior, with learned parameters further amplifying these patterns. Notably, we found that the interaction of causal mask and RoPE distorts RoPE's relative attention score patterns into non-relative ones. We consistently observed this effect in modern large language models, suggesting the importance of considering the causal mask as a source of positional information alongside explicit positional encodings. △ Less",https://arxiv.org/abs/2509.21042,arxiv_attention_page0.csv
Mechanism of Task-oriented Information Removal in In-context Learning,"Hakaze Cho, Haolin Yang, Gouki Minegishi, Naoya Inoue","In-context Learning (ICL) is an emerging few-shot learning paradigm based on modern Language Models (LMs), yet its inner mechanism remains unclear. In this paper, we investigate the mechanism through a novel perspective of information removal. Specifically, we demonstrate that in the zero-shot scenario, LMs encode queries into non-selective representations in hidden states containing information for all possible tasks, leading to arbitrary outputs without focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we find that selectively removing specific information from hidden states by a low-rank filter effectively steers LMs toward the intended task. Building on these findings, by measuring the hidden states on carefully designed metrics, we observe that few-shot ICL effectively simulates such task-oriented information removal processes, selectively removing the redundant information from entangled non-selective representations, and improving the output based on the demonstrations, which constitutes a key mechanism underlying ICL. Moreover, we identify essential attention heads inducing the removal operation, termed Denoising Heads, which enables the ablation experiments blocking the information removal operation from the inference, where the ICL accuracy significantly degrades, especially when the correct label is absent from the few-shot demonstrations, confirming both the critical role of the information removal mechanism and denoising heads. △ Less",https://arxiv.org/abs/2509.21012,arxiv_attention_page0.csv
MAIFormer: Multi-Agent Inverted Transformer for Flight Trajectory Prediction,"Seokbin Yoon, Keumjin Lee","Flight trajectory prediction for multiple aircraft is essential and provides critical insights into how aircraft navigate within current air traffic flows. However, predicting multi-agent flight trajectories is inherently challenging. One of the major difficulties is modeling both the individual aircraft behaviors over time and the complex interactions between flights. Generating explainable prediction outcomes is also a challenge. Therefore, we propose a Multi-Agent Inverted Transformer, MAIFormer, as a novel neural architecture that predicts multi-agent flight trajectories. The proposed framework features two key attention modules: (i) masked multivariate attention , which captures spatio-temporal patterns of individual aircraft, and (ii) agent attention , which models the social patterns among multiple agents in complex air traffic scenes. We evaluated MAIFormer using a real-world automatic dependent surveillance-broadcast flight trajectory dataset from the terminal airspace of Incheon International Airport in South Korea. The experimental results show that MAIFormer achieves the best performance across multiple metrics and outperforms other methods. In addition, MAIFormer produces prediction outcomes that are interpretable from a human perspective, which improves both the transparency of the model and its practical utility in air traffic control. △ Less",https://arxiv.org/abs/2509.21004,arxiv_attention_page0.csv
Decoupled-ValueAttentionfor Prior-Data Fitted Networks: GP Inference for Physical Equations,"Kaustubh Sharma, Simardeep Singh, Parikshit Pareek","Prior-data fitted networks (PFNs) are a promising alternative to time-consuming Gaussian Process (GP) inference for creating fast surrogates of physical systems. PFN reduces the computational burden of GP-training by replacing Bayesian inference in GP with a single forward pass of a learned prediction model. However, with standard Transformer attention , PFNs show limited effectiveness on high-dimensional regression tasks. We introduce Decoupled-Value Attention (DVA)-- motivated by the GP property that the function space is fully characterized by the kernel over inputs and the predictive mean is a weighted sum of training targets. DVA computes similarities from inputs only and propagates labels solely through values. Thus, the proposed DVA mirrors the Gaussian-process update while remaining kernel-free. We demonstrate that the crucial factor for scaling PFNs is the attention rule rather than the architecture itself. Specifically, our results demonstrate that (a) localized attention consistently reduces out-of-sample validation loss in PFNs across different dimensional settings, with validation loss reduced by more than 50% in five- and ten-dimensional cases, and (b) the role of attention is more decisive than the choice of backbone architecture, showing that CNN-based PFNs can perform at par with their Transformer-based counterparts. The proposed PFNs provide 64-dimensional power flow equation approximations with a mean absolute error of the order of 1E-3, while being over 80x faster than exact GP inference. △ Less",https://arxiv.org/abs/2509.20950,arxiv_attention_page0.csv
WhyAttentionFails: The Degeneration of Transformers into MLPs in Time Series Forecasting,"Zida Liang, Jiayi Zhu, Weiqiang Sun","Transformer-based architectures achieved high performance in natural language processing and computer vision, yet many studies have shown that they have not demonstrated a clear advantage in time series forecasting and even underperform simple linear baselines in some cases. However, most of these studies have not thoroughly explored the reasons behind the failure of transformers. To better understand time-series transformers(TST), we designed a series of experiments, progressively modifying transformers into MLPs to investigate the impact of the attention mechanism. Surprisingly, transformer blocks often degenerate into simple MLPs in existing time-series transformers. We designed a interpretable dataset to investigate the reasons behind the failure of the attention mechanism and revealed that the attention mechanism is not working in the expected way. We theoretically analyzed the reasons behind this phenomenon, demonstrating that the current embedding methods fail to allow transformers to function in a well-structured latent space, and further analyzed the deeper underlying causes of the failure of embedding. △ Less",https://arxiv.org/abs/2509.20942,arxiv_attention_page0.csv
Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework,"Wenhao Tang, Heng Fang, Ge Wu, Xiang Li, Ming-Ming Cheng","Computational pathology (CPath) digitizes pathology slides into whole slide images (WSIs), enabling analysis for critical healthcare tasks such as cancer diagnosis and prognosis. However, WSIs possess extremely long sequence lengths (up to 200K), significant length variations (from 200 to 200K), and limited supervision. These extreme variations in sequence length lead to high data heterogeneity and redundancy. Conventional methods often compromise on training efficiency and optimization to preserve such heterogeneity under limited supervision. To comprehensively address these challenges, we propose a pack-based MIL framework. It packs multiple sampled, variable-length feature sequences into fixed-length ones, enabling batched training while preserving data heterogeneity. Moreover, we introduce a residual branch that composes discarded features from multiple slides into a hyperslide which is trained with tailored labels. It offers multi-slide supervision while mitigating feature loss from sampling. Meanwhile, an attention -driven downsampler is introduced to compress features in both branches to reduce redundancy. By alleviating these challenges, our approach achieves an accuracy improvement of up to 8% while using only 12% of the training time in the PANDA(UNI). Extensive experiments demonstrate that focusing data challenges in CPath holds significant potential in the era of foundation models. The code is https://github.com/FangHeng/PackMIL △ Less",https://arxiv.org/abs/2509.20923,arxiv_attention_page0.csv
FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data,"Manuel Nkegoum, Minh-Tan Pham, Élisa Fromont, Bruno Avignon, Sébastien Lefèvre","Few-shot multispectral object detection (FSMOD) addresses the challenge of detecting objects across visible and thermal modalities with minimal annotated data. In this paper, we explore this complex task and introduce a framework named ""FSMODNet"" that leverages cross-modality feature integration to improve detection performance even with limited labels. By effectively combining the unique strengths of visible and thermal imagery using deformable attention , the proposed method demonstrates robust adaptability in complex illumination and environmental conditions. Experimental results on two public datasets show effective object detection performance in challenging low-data regimes, outperforming several baselines we established from state-of-the-art models. All code, models, and experimental data splits can be found at https://anonymous.4open.science/r/Test-B48D. △ Less",https://arxiv.org/abs/2509.20905,arxiv_attention_page0.csv
FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets,"Kairui Fu, Tao Zhang, Shuwen Xiao, Ziyang Wang, Xinming Zhang, Chenchi Zhang, Yuliang Yan, Junjun Zheng, Yu Li, Zhihong Chen, Jian Wu, Xiangheng Kong, Shengyu Zhang, Kun Kuang, Yuning Jiang, Bo Zheng","Semantic identifiers (SIDs) have gained increasing attention in generative retrieval (GR) due to their meaningful semantic discriminability. However, current research on SIDs faces three main challenges: (1) the absence of large-scale public datasets with multimodal features, (2) limited investigation into optimization strategies for SID generation, which typically rely on costly GR training for evaluation, and (3) slow online convergence in industrial deployment. To address these challenges, we propose FORGE, a comprehensive benchmark for FOrming semantic identifieR in Generative rEtrieval with industrial datasets. Specifically, FORGE is equipped with a dataset comprising 14 billion user interactions and multimodal features of 250 million items sampled from Taobao, one of the biggest e-commerce platforms in China. Leveraging this dataset, FORGE explores several optimizations to enhance the SID construction and validates their effectiveness via offline experiments across different settings and tasks. Further online analysis conducted on our platform, which serves over 300 million users daily, reveals a 0.35% increase in transaction count, highlighting the practical impact of our method. Regarding the expensive SID validation accompanied by the full training of GRs, we propose two novel metrics of SID that correlate positively with recommendation performance, enabling convenient evaluations without any GR training. For real-world applications, FORGE introduces an offline pretraining schema that reduces online convergence by half. The code and data are available at https://github.com/selous123/al_sid. △ Less",https://arxiv.org/abs/2509.20904,arxiv_attention_page0.csv
AIBA:Attention-based Instrument Band Alignment for Text-to-Audio Diffusion,"Junyoung Koh, Soo Yong Kim, Gyu Hyeong Choi, Yongwon Choi","We present AIBA ( Attention -In-Band Alignment), a lightweight, training-free pipeline to quantify where text-to-audio diffusion models attend on the time-frequency (T-F) plane. AIBA (i) hooks cross- attention at inference to record attention probabilities without modifying weights; (ii) projects them to fixed-size mel grids that are directly comparable to audio energy; and (iii) scores agreement with instrument-band ground truth via interpretable metrics (T-F IoU/AP, frequency-profile correlation, and a pointing game). On Slakh2100 with an AudioLDM2 backbone, AIBA reveals consistent instrument-dependent trends (e.g., bass favoring low bands) and achieves high precision with moderate recall. △ Less",https://arxiv.org/abs/2509.20891,arxiv_attention_page0.csv
Improving Early Sepsis Onset Prediction Through Federated Learning,"Christoph Düsing, Philipp Cimiano","Early and accurate prediction of sepsis onset remains a major challenge in intensive care, where timely detection and subsequent intervention can significantly improve patient outcomes. While machine learning models have shown promise in this domain, their success is often limited by the amount and diversity of training data available to individual hospitals and Intensive Care Units (ICUs). Federated Learning (FL) addresses this issue by enabling collaborative model training across institutions without requiring data sharing, thus preserving patient privacy. In this work, we propose a federated, attention -enhanced Long Short-Term Memory model for sepsis onset prediction, trained on multi-centric ICU data. Unlike existing approaches that rely on fixed prediction windows, our model supports variable prediction horizons, enabling both short- and long-term forecasting in a single unified model. During analysis, we put particular emphasis on the improvements through our approach in terms of early sepsis detection, i.e., predictions with large prediction windows by conducting an in-depth temporal analysis. Our results prove that using FL does not merely improve overall prediction performance (with performance approaching that of a centralized model), but is particularly beneficial for early sepsis onset prediction. Finally, we show that our choice of employing a variable prediction window rather than a fixed window does not hurt performance significantly but reduces computational, communicational, and organizational overhead. △ Less",https://arxiv.org/abs/2509.20885,arxiv_attention_page0.csv
Integrating Object Interaction Self-Attentionand GAN-Based Debiasing for Visual Question Answering,"Zhifei Li, Feng Qiu, Yiran Wang, Yujing Xia, Kui Xiao, Miao Zhang, Yan Zhang","Visual Question Answering (VQA) presents a unique challenge by requiring models to understand and reason about visual content to answer questions accurately. Existing VQA models often struggle with biases introduced by the training data, leading to over-reliance on superficial patterns and inadequate generalization to diverse questions and images. This paper presents a novel model, IOG-VQA, which integrates Object Interaction Self- Attention and GAN-Based Debiasing to enhance VQA model performance. The self- attention mechanism allows our model to capture complex interactions between objects within an image, providing a more comprehensive understanding of the visual context. Meanwhile, the GAN-based debiasing framework generates unbiased data distributions, helping the model to learn more robust and generalizable features. By leveraging these two components, IOG-VQA effectively combines visual and textual information to address the inherent biases in VQA datasets. Extensive experiments on the VQA-CP v1 and VQA-CP v2 datasets demonstrate that our model shows excellent performance compared with the existing methods, particularly in handling biased and imbalanced data distributions highlighting the importance of addressing both object interactions and dataset biases in advancing VQA tasks. Our code is available at https://github.com/HubuKG/IOG-VQA. △ Less",https://arxiv.org/abs/2509.20884,arxiv_attention_page0.csv
Fast 3D Nanophotonic Inverse Design using Volume Integral Equations,"Amirhossein Fallah, Constantine Sideris","Designing nanophotonic devices with minimal human intervention has gained substantial attention due to the complexity and precision required in modern optical technologies. While inverse design techniques typically rely on conventional electromagnetic solvers as forward models within optimization routines, the substantial electrical size and subwavelength characteristics of nanophotonic structures necessitate significantly accelerated simulation methods. In this work, we introduce a forward modeling approach based on the volume integral equation (VIE) formulation as an efficient alternative to traditional finite-difference (FD)-based methods. We derive the adjoint method tailored specifically for the VIE framework to efficiently compute optimization gradients and present a novel unidirectional mode excitation strategy compatible with VIE solvers. Comparative benchmarks demonstrate that our VIE-based approach provides multiple orders of magnitude improvement in computational efficiency over conventional FD methods in both time and frequency domains. To validate the practical utility of our approach, we successfully designed two representative nanophotonic components: a selective mode reflector and a 3 dB power splitter. Our results underscore the significant runtime advantages offered by the VIE-based framework, highlighting its promising role in accelerating inverse design workflows for next-generation nanophotonic devices. △ Less",https://arxiv.org/abs/2509.20809,arxiv_attention_page0.csv
Extrapolating Phase-Field Simulations in Space and Time with Purely Convolutional Architectures,"Christophe Bonneville, Nathan Bieberdorf, Pieterjan Robbe, Mark Asta, Habib N. Najm, Laurent Capolungo, Cosmin Safta","Phase-field models of liquid metal dealloying (LMD) can resolve rich microstructural dynamics but become intractable for large domains or long time horizons. We present a conditionally parameterized, fully convolutional U-Net surrogate that generalizes far beyond its training window in both space and time. The design integrates convolutional self- attention and physics-aware padding, while parameter conditioning enables variable time-step skipping and adaptation to diverse alloy systems. Although trained only on short, small-scale simulations, the surrogate exploits the translational invariance of convolutions to extend predictions to much longer horizons than traditional solvers. It accurately reproduces key LMD physics, with relative errors typically under 5% within the training regime and below 10% when extrapolating to larger domains and later times. The method accelerates computations by up to 16,000 times, cutting weeks of simulation down to seconds, and marks an early step toward scalable, high-fidelity extrapolation of LMD phase-field models. △ Less",https://arxiv.org/abs/2509.20770,arxiv_attention_page0.csv
Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection,"Yu Guo, Shengfeng He, Yuxu Lu, Haonan An, Yihang Tao, Huilin Zhu, Jingxian Liu, Yuguang Fang","Maritime object detection is essential for navigation safety, surveillance, and autonomous operations, yet constrained by two key challenges: the scarcity of annotated maritime data and poor generalization across various maritime attributes (e.g., object category, viewpoint, location, and imaging environment). % In particular, models trained on existing datasets often underperform in underrepresented scenarios such as open-sea environments. To address these challenges, we propose Neptune-X, a data-centric generative-selection framework that enhances training effectiveness by leveraging synthetic data generation with task-aware sample selection. From the generation perspective, we develop X-to-Maritime, a multi-modality-conditioned generative model that synthesizes diverse and realistic maritime scenes. A key component is the Bidirectional Object-Water Attention module, which captures boundary interactions between objects and their aquatic surroundings to improve visual fidelity. To further improve downstream tasking performance, we propose Attribute-correlated Active Sampling, which dynamically selects synthetic samples based on their task relevance. To support robust benchmarking, we construct the Maritime Generation Dataset, the first dataset tailored for generative maritime learning, encompassing a wide range of semantic conditions. Extensive experiments demonstrate that our approach sets a new benchmark in maritime scene synthesis, significantly improving detection accuracy, particularly in challenging and previously underrepresented settings.The code is available at https://github.com/gy65896/Neptune-X. △ Less",https://arxiv.org/abs/2509.20745,arxiv_attention_page0.csv
DENet: Dual-Path Edge Network with Global-LocalAttentionfor Infrared Small Target Detection,"Jiayi Zuo, Songwei Pei, Qian Li","Infrared small target detection is crucial for remote sensing applications like disaster warning and maritime surveillance. However, due to the lack of distinctive texture and morphological features, infrared small targets are highly susceptible to blending into cluttered and noisy backgrounds. A fundamental challenge in designing deep models for this task lies in the inherent conflict between capturing high-resolution spatial details for minute targets and extracting robust semantic context for larger targets, often leading to feature misalignment and suboptimal performance. Existing methods often rely on fixed gradient operators or simplistic attention mechanisms, which are inadequate for accurately extracting target edges under low contrast and high noise. In this paper, we propose a novel Dual-Path Edge Network that explicitly addresses this challenge by decoupling edge enhancement and semantic modeling into two complementary processing paths. The first path employs a Bidirectional Interaction Module, which uses both Local Self- Attention and Global Self- Attention to capture multi-scale local and global feature dependencies. The global attention mechanism, based on a Transformer architecture, integrates long-range semantic relationships and contextual information, ensuring robust scene understanding. The second path introduces the Multi-Edge Refiner, which enhances fine-grained edge details using cascaded Taylor finite difference operators at multiple scales. This mathematical approach, along with an attention -driven gating mechanism, enables precise edge localization and feature enhancement for targets of varying sizes, while effectively suppressing noise. Our method provides a promising solution for precise infrared small target detection and localization, combining structural semantics and edge refinement in a unified framework. △ Less",https://arxiv.org/abs/2509.20701,arxiv_attention_page0.csv
RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks,"Shouren Mao, Minghao Qin, Wei Dong, Huajian Liu, Yongzhuo Gao","Neural architecture search (NAS) has shown great promise in automatically designing lightweight models. However, conventional approaches are insufficient in training the supernet and pay little attention to actual robot hardware resources. To meet such challenges, we propose RAM-NAS, a resource-aware multi-objective NAS method that focuses on improving the supernet pretrain and resource-awareness on robot hardware devices. We introduce the concept of subnets mutual distillation, which refers to mutually distilling all subnets sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge Distillation (DKD) loss to enhance logits distillation performance. To expedite the search process with consideration for hardware resources, we used data from three types of robotic edge hardware to train Latency Surrogate predictors. These predictors facilitated the estimation of hardware inference latency during the search phase, enabling a unified multi-objective evolutionary search to balance model accuracy and latency trade-offs. Our discovered model family, RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on ImageNet. In addition, the resource-aware multi-objective NAS we employ significantly reduces the model's inference latency on edge hardware for robots. We conducted experiments on downstream tasks to verify the scalability of our methods. The inference time for detection and segmentation is reduced on all three hardware types compared to MobileNetv3-based methods. Our work fills the gap in NAS for robot hardware resource-aware. △ Less",https://arxiv.org/abs/2509.20688,arxiv_attention_page0.csv
Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding,"Ayan Sar, Sampurna Roy, Kanav Gupta, Anurag Kaushish, Tanupriya Choudhury, Abhijit Kumar","Transformer architectures have achieved state-of-the-art performance across natural language tasks, yet they fundamentally misrepresent the hierarchical nature of human language by processing text as flat token sequences. This results in quadratic computational cost, weak computational cost, weak compositional generalization, and inadequate discourse-level modeling. We propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired neural architecture that processes language simultaneously across multiple resolutions, from characters to discourse-level units. HRT constructs a multi-resolution attention , enabling bottom-up composition and top-down contextualization. By employing exponential sequence reduction across scales, HRT achieves O(nlogn) complexity, offering significant efficiency improvements over standard transformers. We evaluated HRT on a diverse suite of benchmarks, including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results demonstrated that HRT outperforms standard transformer baselines by an average of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while reducing memory usage by 42% and inference latency by 37% compared to BERT and GPT style models of similar parameter count. Ablation studies confirm the effectiveness of cross-resolution attention and scale-specialized modules, showing that each contributes independently to both efficiency and accuracy. Our findings establish HRT as the first architecture to align computational structure with the hierarchical organization of human language, demonstrating that multi-scale, wavelet-inspired processing yields both theoretical efficiency gains and practical improvements in language understanding. △ Less",https://arxiv.org/abs/2509.20581,arxiv_attention_page0.csv
Large Pre-Trained Models for Bimanual Manipulation in 3D,"Hanna Yurchyk, Wei-Di Chang, Gregory Dudek, David Meger","We investigate the integration of attention maps from a pre-trained Vision Transformer into voxel representations to enhance bimanual robotic manipulation. Specifically, we extract attention maps from DINOv2, a self-supervised ViT model, and interpret them as pixel-level saliency scores over RGB images. These maps are lifted into a 3D voxel grid, resulting in voxel-level semantic cues that are incorporated into a behavior cloning policy. When integrated into a state-of-the-art voxel-based policy, our attention -guided featurization yields an average absolute improvement of 8.2% and a relative gain of 21.9% across all tasks in the RLBench bimanual benchmark. △ Less",https://arxiv.org/abs/2509.20579,arxiv_attention_page0.csv
"SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations","Ayan Sar, Pranav Singh Puri, Sumit Aich, Tanupriya Choudhury, Abhijit Kumar","In multilingual healthcare environments, automatic disease diagnosis from clinical text remains a challenging task due to the scarcity of annotated medical data in low-resource languages and the linguistic variability across populations. This paper proposes SwasthLLM, a unified, zero-shot, cross-lingual, and multi-task learning framework for medical diagnosis that operates effectively across English, Hindi, and Bengali without requiring language-specific fine-tuning. At its core, SwasthLLM leverages the multilingual XLM-RoBERTa encoder augmented with a language-aware attention mechanism and a disease classification head, enabling the model to extract medically relevant information regardless of the language structure. To align semantic representations across languages, a Siamese contrastive learning module is introduced, ensuring that equivalent medical texts in different languages produce similar embeddings. Further, a translation consistency module and a contrastive projection head reinforce language-invariant representation learning. SwasthLLM is trained using a multi-task learning strategy, jointly optimizing disease classification, translation alignment, and contrastive learning objectives. Additionally, we employ Model-Agnostic Meta-Learning (MAML) to equip the model with rapid adaptation capabilities for unseen languages or tasks with minimal data. Our phased training pipeline emphasizes robust representation alignment before task-specific fine-tuning. Extensive evaluation shows that SwasthLLM achieves high diagnostic performance, with a test accuracy of 97.22% and an F1-score of 97.17% in supervised settings. Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and 73.33% accuracy on Bengali medical text, demonstrating strong generalization in low-resource contexts. △ Less",https://arxiv.org/abs/2509.20567,arxiv_attention_page0.csv
Myosotis: structured computation forattentionlike layer,"Evgenii Egorov, Hanno Ackermann, Markus Nagel, Hong Cai","Attention layers apply a sequence-to-sequence mapping whose parameters depend on the pairwise interactions of the input elements. However, without any structural assumptions, memory and compute scale quadratically with the sequence length. The two main ways to mitigate this are to introduce sparsity by ignoring a sufficient amount of pairwise interactions or to introduce recurrent dependence along them, as SSM does. Although both approaches are reasonable, they both have disadvantages. We propose a novel algorithm that combines the advantages of both concepts. Our idea is based on the efficient inversion of tree-structured matrices. △ Less",https://arxiv.org/abs/2509.20503,arxiv_attention_page0.csv
CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification,"D. Darankoum, C. Habermacher, J. Volle, S. Grudinin","Electroencephalography signals (EEGs) contain rich multi-scale information crucial for understanding brain states, with potential applications in diagnosing and advancing the drug development landscape. However, extracting meaningful features from raw EEG signals while handling noise and channel variability remains a major challenge. This work proposes a novel end-to-end deep-learning framework that addresses these issues through several key innovations. First, we designed an encoder capable of explicitly capturing multi-scale frequency oscillations covering a wide range of features for different EEG-related tasks. Secondly, to model complex dependencies and handle the high temporal resolution of EEGs, we introduced an attention -based encoder that simultaneously learns interactions across EEG channels and within localized {\em patches} of individual channels. We integrated a dedicated gating network on top of the attention encoder to dynamically filter out noisy and non-informative channels, enhancing the reliability of EEG data. The entire encoding process is guided by a novel loss function, which leverages supervised and contrastive learning, significantly improving model generalization. We validated our approach in multiple applications, ranging from the classification of effects across multiple Central Nervous System (CNS) disorders treatments to the diagnosis of Parkinson's and Alzheimer's disease. Our results demonstrate that the proposed learning paradigm can extract biologically meaningful patterns from raw EEG signals across different species, autonomously select high-quality channels, and achieve robust generalization through innovative architectural and loss design. △ Less",https://arxiv.org/abs/2509.20489,arxiv_attention_page0.csv
"Female Student Population at Kabul University Before the 2021 Ban: Trends, Gender Parity, and Faculty-Level Dynamics","Jawid Ahmad Baktash, Mursal Dawodi","For nearly two decades after 2001, Afghanistan's higher education sector expanded rapidly, with Kabul University serving as a central site of women's academic participation. Drawing on administrative records of student populations from 2016-2019 (Islamic calendar 1395-1398), this study examines gender distributions across shifts, faculties, and departments, with particular attention to STEM versus non-STEM fields. At Kabul University, the morning shift refers to the main daytime cohort (including some midday classes), while the evening shift is a separate program with its own classes and students; the two cohorts are administratively and academically distinct. Results show steady growth in the overall female student population, but with marked disparities between morning and evening shifts. Women were concentrated in non-STEM and ""socially acceptable"" disciplines such as literature, law, and psychology, while within STEM they were relatively well represented in the life sciences but remained significantly underrepresented in technical fields such as engineering, computer science, and physics. Gender parity improved modestly across most faculties, yet the Gender Parity Index (GPI) rarely approached 1.0, and the STEM GPI consistently remained below 0.5. These findings highlight both progress and persistent structural inequalities, documenting a critical historical benchmark before the 2021 ban on women's university education. △ Less",https://arxiv.org/abs/2509.20406,arxiv_attention_page0.csv
cAItomorph: Transformer-Based Hematological Malignancy Prediction from Peripheral Blood Smears in a Real-Word Cohort,"Muhammed Furkan Dasdelen, Ivan Kukuljan, Peter Lienemann, Ario Sadafi, Matthias Hehr, Karsten Spiekermann, Christian Pohlkamp, Carsten Marr","Peripheral blood smears remain a cornerstone in the diagnosis of hematological neoplasms, offering rapid and valuable insights that inform subsequent diagnostic steps. However, since neoplastic transformations typically arise in the bone marrow, they may not manifest as detectable aberrations in peripheral blood, presenting a diagnostic challenge. In this paper, we introduce cAItomorph, an explainable transformer-based AI model, trained to classify hematological malignancies based on peripheral blood cytomorphology. Our data comprises peripheral blood single-cell images from 6115 patients with diagnoses confirmed by cytomorphology, cytogenetics, molecular genetics, and immunophenotyping from bone marrow samples, and 495 healthy controls, categorized into 22 detailed and 7 coarse classes. cAItomorph leverages the DinoBloom hematology foundation model and aggregates image encodings via a transformer-based architecture into a single vector. It achieves an overall accuracy of 68$\pm$1% (mean$\pm$s.d., 5-fold cross-validation) in 7-disease classification, with F1 scores of 74$\pm$2% for acute leukemia, 75$\pm$3% for myeloproliferative neoplasms and 82$\pm$3% for no malignancy cases. The overall accuracy increases to 84$\pm$1% in top-2 predictions. By analyzing multi-head attentions , we demonstrate clinically relevant cell-level attentions and pixel-level heatmaps. Moreover, our model's calibrated prediction probabilities reduced the false discovery rate from 13.8% to 12% without missing any acute leukemia cases, thereby decreasing the number of unnecessary bone marrow aspirations. Our code, test data, and model weights are publicly available to ensure reproducibility. This study highlights the potential of AI-assisted diagnostics in hematological malignancies, illustrating how models trained on real-world data could enhance diagnostic accuracy and reduce invasive procedures. △ Less",https://arxiv.org/abs/2509.20402,arxiv_attention_page0.csv
SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment,"Binod Singh, Sayan Deb Sarkar, Iro Armeni","Aligning 3D scene graphs is a crucial initial step for several applications in robot navigation and embodied perception. Current methods in 3D scene graph alignment often rely on single-modality point cloud data and struggle with incomplete or noisy input. We introduce SGAligner++, a cross-modal, language-aided framework for 3D scene graph alignment. Our method addresses the challenge of aligning partially overlapping scene observations across heterogeneous modalities by learning a unified joint embedding space, enabling accurate alignment even under low-overlap conditions and sensor noise. By employing lightweight unimodal encoders and attention -based fusion, SGAligner++ enhances scene understanding for tasks such as visual localization, 3D reconstruction, and navigation, while ensuring scalability and minimal computational overhead. Extensive evaluations on real-world datasets demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40% on noisy real-world reconstructions, while enabling cross-modal generalization. △ Less",https://arxiv.org/abs/2509.20401,arxiv_attention_page0.csv
EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning,"Xuan Ju, Tianyu Wang, Yuqian Zhou, He Zhang, Qing Liu, Nanxuan Zhao, Zhifei Zhang, Yijun Li, Yuanhao Cai, Shaoteng Liu, Daniil Pakhomov, Zhe Lin, Soo Ye Kim, Qiang Xu","Recent advances in foundation models highlight a clear trend toward unification and scaling, showing emergent capabilities across diverse domains. While image generation and editing have rapidly transitioned from task-specific to unified frameworks, video generation and editing remain fragmented due to architectural limitations and data scarcity. In this work, we introduce EditVerse, a unified framework for image and video generation and editing within a single model. By representing all modalities, i.e., text, image, and video, as a unified token sequence, EditVerse leverages self- attention to achieve robust in-context learning, natural cross-modal knowledge transfer, and flexible handling of inputs and outputs with arbitrary resolutions and durations. To address the lack of video editing training data, we design a scalable data pipeline that curates 232K video editing samples and combines them with large-scale image and video datasets for joint training. Furthermore, we present EditVerseBench, the first benchmark for instruction-based video editing covering diverse tasks and resolutions. Extensive experiments and user studies demonstrate that EditVerse achieves state-of-the-art performance, surpassing existing open-source and commercial models, while exhibiting emergent editing and generation abilities across modalities. △ Less",https://arxiv.org/abs/2509.20360,arxiv_attention_page0.csv
PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation,"Chen Wang, Chuhao Chen, Yiming Huang, Zhiyang Dou, Yuan Liu, Jiatao Gu, Lingjie Liu","Existing video generation models excel at producing photo-realistic videos from text or images, but often lack physical plausibility and 3D controllability. To overcome these limitations, we introduce PhysCtrl, a novel framework for physics-grounded image-to-video generation with physical parameters and force control. At its core is a generative physics network that learns the distribution of physical dynamics across four materials (elastic, sand, plasticine, and rigid) via a diffusion model conditioned on physics parameters and applied forces. We represent physical dynamics as 3D point trajectories and train on a large-scale synthetic dataset of 550K animations generated by physics simulators. We enhance the diffusion model with a novel spatiotemporal attention block that emulates particle interactions and incorporates physics-based constraints during training to enforce physical plausibility. Experiments show that PhysCtrl generates realistic, physics-grounded motion trajectories which, when used to drive image-to-video models, yield high-fidelity, controllable videos that outperform existing methods in both visual quality and physical plausibility. Project Page: https://cwchenwang.github.io/physctrl △ Less",https://arxiv.org/abs/2509.20358,arxiv_attention_page0.csv
Process-Informed Forecasting of Complex Thermal Dynamics in Pharmaceutical Manufacturing,"Ramona Rubini, Siavash Khodakarami, Aniruddha Bora, George Em Karniadakis, Michele Dassisti","Accurate time-series forecasting for complex physical systems is the backbone of modern industrial monitoring and control. While deep learning models excel at capturing complex dynamics, currently, their deployment is limited due to physical inconsistency and robustness, hence constraining their reliability in regulated environments. We introduce process-informed forecasting (PIF) models for temperature in pharmaceutical lyophilization. We investigate a wide range of models, from classical ones such as Autoregressive Integrated Moving Average Model (ARIMA) and Exponential Smoothing Model (ETS), to modern deep learning architectures, including Kolmogorov-Arnold Networks (KANs). We compare three different loss function formulations that integrate a process-informed trajectory prior: a fixed-weight loss, a dynamic uncertainty-based loss, and a Residual-Based Attention (RBA) mechanism. We evaluate all models not only for accuracy and physical consistency but also for robustness to sensor noise. Furthermore, we test the practical generalizability of the best model in a transfer learning scenario on a new process. Our results show that PIF models outperform their data-driven counterparts in terms of accuracy, physical plausibility and noise resilience. This work provides a roadmap for developing reliable and generalizable forecasting solutions for critical applications in the pharmaceutical manufacturing landscape. △ Less",https://arxiv.org/abs/2509.20349,arxiv_attention_page0.csv
Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual Try-On,"Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee Kiat Koo, Karim Bouyarmane","As online shopping continues to grow, the demand for Virtual Try-On (VTON) technology has surged, allowing customers to visualize products on themselves by overlaying product images onto their own photos. An essential yet challenging condition for effective VTON is pose control, which ensures accurate alignment of products with the user's body while supporting diverse orientations for a more immersive experience. However, incorporating pose conditions into VTON models presents several challenges, including selecting the optimal pose representation, integrating poses without additional parameters, and balancing pose preservation with flexible pose control.
  In this work, we build upon a baseline VTON model that concatenates the reference image condition without external encoder, control network, or complex attention layers. We investigate methods to incorporate pose control into this pure concatenation paradigm by spatially concatenating pose data, comparing performance using pose maps and skeletons, without adding any additional parameters or module to the baseline model. Our experiments reveal that pose stitching with pose maps yields the best results, enhancing both pose preservation and output realism. Additionally, we introduce a mixed-mask training strategy using fine-grained and bounding box masks, allowing the model to support flexible product integration across varied poses and conditions. △ Less",https://arxiv.org/abs/2509.20343,arxiv_attention_page0.csv
Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement Learning,"Umer Siddique, Abhinav Sinha, Yongcan Cao","Conventional multi-agent reinforcement learning (MARL) methods rely on time-triggered execution, where agents sample and communicate actions at fixed intervals. This approach is often computationally expensive and communication-intensive. To address this limitation, we propose ET-MAPG (Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a framework that jointly learns an agent's control policy and its event-triggering policy. Unlike prior work that decouples these mechanisms, ET-MAPG integrates them into a unified learning process, enabling agents to learn not only what action to take but also when to execute it. For scenarios with inter-agent communication, we introduce AET-MAPG, an attention -based variant that leverages a self- attention mechanism to learn selective communication patterns. AET-MAPG empowers agents to determine not only when to trigger an action but also with whom to communicate and what information to exchange, thereby optimizing coordination. Both methods can be integrated with any policy gradient MARL algorithm. Extensive experiments across diverse MARL benchmarks demonstrate that our approaches achieve performance comparable to state-of-the-art, time-triggered baselines while significantly reducing both computational load and communication overhead. △ Less",https://arxiv.org/abs/2509.20338,arxiv_attention_page0.csv
On Brinkman flows with curvature-induced phase separation in binary mixtures,"Pierluigi Colli, Gianni Gilardi, Andrea Signori, Jürgen Sprekels","The mathematical analysis of diffuse-interface models for multiphase flows has attracted significant attention due to their ability to capture complex interfacial dynamics, including curvature effects, within a unified, energetically consistent framework. In this work, we study a novel Brinkman-Cahn-Hilliard system, coupling a sixth-order phase-field evolution with a Brinkman-type momentum equation featuring variable shear viscosity. The Cahn-Hilliard equation includes a nonconservative source term accounting for mass exchange, and the velocity equation contains a non divergence-free forcing term. We establish the existence of weak solutions in a divergence-free variational framework, and, in the case of constant mobility and shear viscosity, prove uniqueness and continuous dependence on the forcing. Additionally, we analyze the Darcy limit, providing existence results for the corresponding reduced system. △ Less",https://arxiv.org/abs/2509.20282,arxiv_attention_page0.csv
Optimal estimation for regression discontinuity design with binary outcomes,"Takuya Ishihara, Masayuki Sawada, Kohei Yata","We develop a finite-sample optimal estimator for regression discontinuity designs when the outcomes are bounded, including binary outcomes as the leading case. Our finite-sample optimal estimator achieves the exact minimax mean squared error among linear shrinkage estimators with nonnegative weights when the regression function of a bounded outcome lies in a Lipschitz class. Although the original minimax problem involves an iterating (n+1)-dimensional non-convex optimization problem where n is the sample size, we show that our estimator is obtained by solving a convex optimization problem. A key advantage of our estimator is that the Lipschitz constant is the only tuning parameter. We also propose a uniformly valid inference procedure without a large-sample approximation. In a simulation exercise for small samples, our estimator exhibits smaller mean squared errors and shorter confidence intervals than conventional large-sample techniques which may be unreliable when the effective sample size is small. We apply our method to an empirical multi-cutoff design where the sample size for each cutoff is small. In the application, our method yields informative confidence intervals, in contrast to the leading large-sample approach. △ Less",https://arxiv.org/abs/2509.18857,arxiv_exercise_page0.csv
FlexGuard: A Design Space for On-Body Feedback for Injury Prevention in Strength Training,"Panayu Keelawat, Darshan Nere, Jyotshna Bali, Rezky Dwisantika, Yogesh Phalak, Ardalan Kahak, Anekan Naicker, Liang He, Suyi Li, Yan Chen","Strength training carries risk of injury when exercises are performed without supervision. While haptics research has advanced, there remains a gap in how to integrate on-body feedback into intelligent wearables. Developing such a design space requires experiencing feedback in context, yet obtaining functional systems is costly. By addressing these challenges, we introduce FlexGuard, a design space for on-body feedback to support injury prevention in strength training. The design space was derived from nine co-design workshops, where novice trainees and expert trainers DIY'd low-fidelity on-body feedback systems, tried them immediately, and surfaced needs and challenges encountered in real exercising contexts. We then evaluated the space through speed dating, using storyboards to cover the design dimensions. We followed up with workshops to further validate selected dimensions in practice through a proof-of-concept wearable system prototype. Our findings extend the design space for sports and fitness wearables in the context of strength training. △ Less",https://arxiv.org/abs/2509.18662,arxiv_exercise_page0.csv
Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors,"Chang Liu, Ladda Thiamwong, Yanjie Fu, Rui Xie","Utilizing offline reinforcement learning (RL) with real-world clinical data is getting increasing attention in AI for healthcare. However, implementation poses significant challenges. Defining direct rewards is difficult, and inverse RL (IRL) struggles to infer accurate reward functions from expert behavior in complex environments. Offline RL also encounters challenges in aligning learned policies with observed human behavior in healthcare applications. To address challenges in applying offline RL to physical activity promotion for older adults at high risk of falls, based on wearable sensor activity monitoring, we introduce Kolmogorov-Arnold Networks and Diffusion Policies for Offline Inverse Reinforcement Learning (KANDI). By leveraging the flexible function approximation in Kolmogorov-Arnold Networks, we estimate reward functions by learning free-living environment behavior from low-fall-risk older adults (experts), while diffusion-based policies within an Actor-Critic framework provide a generative approach for action refinement and efficiency in offline RL. We evaluate KANDI using wearable activity monitoring data in a two-arm clinical trial from our Physio-feedback Exercise Program (PEER) study, emphasizing its practical application in a fall-risk intervention program to promote physical activity among older adults. Additionally, KANDI outperforms state-of-the-art methods on the D4RL benchmark. These results underscore KANDI's potential to address key challenges in offline RL for healthcare applications, offering an effective solution for activity promotion intervention strategies in healthcare. △ Less",https://arxiv.org/abs/2509.18433,arxiv_exercise_page0.csv
A Sequential Testing Problem with Signal Control,"Steven Campbell, Georgy Gaitsgori, Richard Groenewald","We study a controlled version of the Bayesian sequential testing problem for the drift of a Wiener process, in which the observer exercises discretion over the signal intensity. This control incurs a running cost that reflects the resource demands of information acquisition. The objective is to minimize the total expected cost, combining both the expenditure on control and the loss from misclassifying the unknown drift. By allowing for a general class of loss functions and any measurable cost of control, our analysis captures a broad range of sequential inference problems. We show that when a function, determined by the cost structure, admits a global minimizer, the optimal control is constant and explicitly computable, thereby reducing our setting to a solvable optimal stopping problem. If no such minimizer exists, an optimal control does not exist either, yet the value function remains explicit. Our results thus demonstrate that full tractability can be retained even when extending sequential inference to include endogenous control over the information flow. △ Less",https://arxiv.org/abs/2509.18209,arxiv_exercise_page0.csv
Improving Neutrino-Nuclei Interaction Models: Recommendations and Case Studies on Peelle's Pertinent Puzzle,"S. Abe, L. Aliaga-Soplin, J. Barrow, L. Bathe-Peters, B. Bogart, L. Cooper-Troendle, R. Diurba, S. Dytman, S. Gardiner, L. Hagaman, M. S. Ismail, J. Issacson, J. Kim, L. Liu, J. McKean, N. Nayak, A. Papadopoulou, L. Pickering, X. Qian, K. Skwarczynski, J. Tena Vidal, J. Wolfs","Improving the modeling of neutrino-nuclei interactions using data-driven methods is crucial for high-precision neutrino oscillation experiments. This paper investigates Peelle's Pertinent Puzzle (PPP) in the context of neutrino measurements, a longstanding challenge to fitting theoretical models to experimental data. Inconsistencies in data-model comparisons hinder efforts to enhance the accuracy and reliability of model predictions. We analyze various sources contributing to these inconsistencies and propose strategies to address them, supported by practical case studies. We advocate for incorporating model fitting exercises as a standard practice in cross section publications to enhance the robustness of results. We use a common analysis framework to explore PPP-related challenges with MicroBooNE and T2K data in an unified manner. Our findings offer valuable insights for improving the accuracy and reliability of neutrino-nuclei interaction models, particularly by systematically tuning models using data. △ Less",https://arxiv.org/abs/2509.17945,arxiv_exercise_page0.csv
D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models,"Satyapriya Krishna, Andy Zou, Rahul Gupta, Eliot Krzysztof Jones, Nick Winter, Dan Hendrycks, J. Zico Kolter, Matt Fredrikson, Spyros Matsoukas","The safety and alignment of Large Language Models (LLMs) are critical for their responsible deployment. Current evaluation methods predominantly focus on identifying and preventing overtly harmful outputs. However, they often fail to address a more insidious failure mode: models that produce benign-appearing outputs while operating on malicious or deceptive internal reasoning. This vulnerability, often triggered by sophisticated system prompt injections, allows models to bypass conventional safety filters, posing a significant, underexplored risk. To address this gap, we introduce the Deceptive Reasoning Exposure Suite (D-REX), a novel dataset designed to evaluate the discrepancy between a model's internal reasoning process and its final output. D-REX was constructed through a competitive red-teaming exercise where participants crafted adversarial system prompts to induce such deceptive behaviors. Each sample in D-REX contains the adversarial system prompt, an end-user's test query, the model's seemingly innocuous response, and, crucially, the model's internal chain-of-thought, which reveals the underlying malicious intent. Our benchmark facilitates a new, essential evaluation task: the detection of deceptive alignment. We demonstrate that D-REX presents a significant challenge for existing models and safety mechanisms, highlighting the urgent need for new techniques that scrutinize the internal processes of LLMs, not just their final outputs. △ Less",https://arxiv.org/abs/2509.17938,arxiv_exercise_page0.csv
"Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs","Mariam Mahran, Katharina Simbeck","Large Language Models (LLMs) are increasingly used for educational support, yet their response quality varies depending on the language of interaction. This paper presents an automated multilingual pipeline for generating, solving, and evaluating math problems aligned with the German K-10 curriculum. We generated 628 math exercises and translated them into English, German, and Arabic. Three commercial LLMs (GPT-4o-mini, Gemini 2.5 Flash, and Qwen-plus) were prompted to produce step-by-step solutions in each language. A held-out panel of LLM judges, including Claude 3.5 Haiku, evaluated solution quality using a comparative framework. Results show a consistent gap, with English solutions consistently rated highest, and Arabic often ranked lower. These findings highlight persistent linguistic bias and the need for more equitable multilingual AI systems in education. △ Less",https://arxiv.org/abs/2509.17701,arxiv_exercise_page0.csv
RISE: Adaptive music playback for Realtime Intensity Synchronization withExercise,"Alexander Wang, Chris Donahue, Dhruv Jain","We propose a system to adapt a user's music to their exercise by aligning high-energy music segments with intense intervals of the workout. Listening to music during exercise can boost motivation and performance. However, the structure of the music may be different from the user's natural phases of rest and work, causing users to rest longer than needed while waiting for a motivational section, or lose motivation mid-work if the section ends too soon. To address this, our system, called RISE, automatically estimates the intense segments in music and uses component-based music rearrangement techniques to dynamically extend and shorten different segments of the user's song to fit the ongoing exercise routine. Our system takes as input the rest and work durations to guide adaptation. Currently, this is determined either via a pre-defined plan or manual input during the workout. We evaluated RISE with 12 participants and compared our system to a non-adaptive music baseline while exercising in our lab. Participants found our rearrangements keeps intensity estimation accurate, and many recalled moments when intensity alignment helped them push through their workout. △ Less",https://arxiv.org/abs/2509.17112,arxiv_exercise_page0.csv
Difficulty-Aware Score Generation for Piano Sight-Reading,"Pedro Ramoneda, Masahiro Suzuki, Akira Maezawa, Xavier Serra","Adapting learning materials to the level of skill of a student is important in education. In the context of music training, one essential ability is sight-reading -- playing unfamiliar scores at first sight -- which benefits from progressive and level-appropriate practice. However, creating exercises at the appropriate level of difficulty demands significant time and effort. We address this challenge as a controlled symbolic music generation task that aims to produce piano scores with a desired difficulty level. Controlling symbolic generation through conditioning is commonly done using control tokens, but these do not always have a clear impact on global properties, such as difficulty. To improve conditioning, we introduce an auxiliary optimization target for difficulty prediction that helps prevent conditioning collapse -- a common issue in which models ignore control signals in the absence of explicit supervision. This auxiliary objective helps the model to learn internal representations aligned with the target difficulty, enabling more precise and adaptive score generation. Evaluation with automatic metrics and expert judgments shows better control of difficulty and potential educational value. Our approach represents a step toward personalized music education through the generation of difficulty-aware practice material. △ Less",https://arxiv.org/abs/2509.16913,arxiv_exercise_page0.csv
Process-Driven Visual Analysis of Cybersecurity Capture the FlagExercises,"Radek Ošlejšek, Radoslav Chudovský, Martin Macak","Hands-on training sessions become a standard way to develop and increase knowledge in cybersecurity. As practical cybersecurity exercises are strongly process-oriented with knowledge-intensive processes, process mining techniques and models can help enhance learning analytics tools. The design of our open-source analytical dashboard is backed by guidelines for visualizing multivariate networks complemented with temporal views and clustering. The design aligns with the requirements for post-training analysis of a special subset of cybersecurity exercises -- supervised Capture the Flag games. Usability is demonstrated in a case study using trainees' engagement measurement to reveal potential flaws in training design or organization. △ Less",https://arxiv.org/abs/2509.15589,arxiv_exercise_page0.csv
Breathing and Semantic Pause Detection and Exertion-Level Classification in Post-ExerciseSpeech,"Yuyu Wang, Wuyue Xia, Huaxiu Yao, Jingping Nie","Post- exercise speech contains rich physiological and linguistic cues, often marked by semantic pauses, breathing pauses, and combined breathing-semantic pauses. Detecting these events enables assessment of recovery rate, lung function, and exertion-related abnormalities. However, existing works on identifying and distinguishing different types of pauses in this context are limited. In this work, building on a recently released dataset with synchronized audio and respiration signals, we provide systematic annotations of pause types. Using these annotations, we systematically conduct exploratory breathing and semantic pause detection and exertion-level classification across deep learning models (GRU, 1D CNN-LSTM, AlexNet, VGG16), acoustic features (MFCC, MFB), and layer-stratified Wav2Vec2 representations. We evaluate three setups-single feature, feature fusion, and a two-stage detection-classification cascade-under both classification and regression formulations. Results show per-type detection accuracy up to 89$\%$ for semantic, 55$\%$ for breathing, 86$\%$ for combined pauses, and 73$\%$overall, while exertion-level classification achieves 90.5$\%$ accuracy, outperformin prior work. △ Less",https://arxiv.org/abs/2509.15473,arxiv_exercise_page0.csv
Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations,"Ivana Kesić, Aljaž Blatnik, Carolina Fortuna, Blaž Bertalanič","Global Navigation Satellite Systems (GNSS) are increasingly disrupted by intentional jamming, degrading availability precisely when positioning and timing must remain operational. We address this by reframing jamming mitigation as dynamic graph regression and introducing a receiver-centric deep temporal graph network that predicts, and thus corrects, the receivers horizontal deviation in real time. At each 1 Hz epoch, the satellite receiver environment is represented as a heterogeneous star graph (receiver center, tracked satellites as leaves) with time varying attributes (e.g., SNR, azimuth, elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM (HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a short history to output the 2D deviation vector applied for on the fly correction.
  We evaluate on datasets from two distinct receivers under three jammer profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each exercised at six power levels between -45 and -70 dBm, with 50 repetitions per scenario (prejam/jam/recovery). Against strong multivariate time series baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm (GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and 4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10), outperforming Seq2Point, MLP, and CNN. A split study shows superior data efficiency: with only 10\% training data our approach remains well ahead of baselines (20 cm vs. 36-42 cm). △ Less",https://arxiv.org/abs/2509.14000,arxiv_exercise_page0.csv
Brain-Robot Interface forExerciseMimicry,"Carl Bettosi, Emilyann Nault, Lynne Baillie, Markus Garschall, Marta Romeo, Beatrix Wais-Zechmann, Nicole Binderlehner, Theodoros Georgiou","For social robots to maintain long-term engagement as exercise instructors, rapport-building is essential. Motor mimicry--imitating one's physical actions--during social interaction has long been recognized as a powerful tool for fostering rapport, and it is widely used in rehabilitation exercises where patients mirror a physiotherapist or video demonstration. We developed a novel Brain-Robot Interface (BRI) that allows a social robot instructor to mimic a patient's exercise movements in real-time, using mental commands derived from the patient's intention. The system was evaluated in an exploratory study with 14 participants (3 physiotherapists and 11 hemiparetic patients recovering from stroke or other injuries). We found our system successfully demonstrated exercise mimicry in 12 sessions; however, accuracy varied. Participants had positive perceptions of the robot instructor, with high trust and acceptance levels, which were not affected by the introduction of BRI technology. △ Less",https://arxiv.org/abs/2509.11306,arxiv_exercise_page0.csv
Policy Learning for Social Robot-Led Physiotherapy,"Carl Bettosi, Lynne Ballie, Susan Shenkin, Marta Romeo","Social robots offer a promising solution for autonomously guiding patients through physiotherapy exercise sessions, but effective deployment requires advanced decision-making to adapt to patient needs. A key challenge is the scarcity of patient behavior data for developing robust policies. To address this, we engaged 33 expert healthcare practitioners as patient proxies, using their interactions with our robot to inform a patient behavior model capable of generating exercise performance metrics and subjective scores on perceived exertion. We trained a reinforcement learning-based policy in simulation, demonstrating that it can adapt exercise instructions to individual exertion tolerances and fluctuating performance, while also being applicable to patients at different recovery stages with varying exercise plans. △ Less",https://arxiv.org/abs/2509.11297,arxiv_exercise_page0.csv
Uniformity within Parameterized Circuit Classes,"Steef Hegeman, Jan Martens, Alfons Laarman","We study uniformity conditions for parameterized Boolean circuit families. Uniformity conditions require that the infinitely many circuits in a circuit family are in some sense easy to construct from one shared description. For shallow circuit families, logtime-uniformity is often desired but quite technical to prove. Despite that, proving it is often left as an exercise for the reader -- even for recently introduced classes in parameterized circuit complexity, where uniformity conditions have not yet been explicitly studied. We formally define parameterized versions of linear-uniformity, logtime-uniformity, and FO-uniformity, and prove that these result in equivalent complexity classes when imposed on $\text{para-}\textsf{AC}^0$ and $\text{para-}\textsf{AC}^{0\uparrow}$. Overall, we provide a convenient way to verify uniformity for shallow parameterized circuit classes, and thereby substantiate claims of uniformity in the literature. △ Less",https://arxiv.org/abs/2509.09657,arxiv_exercise_page0.csv
Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation,"Lucie Poláková, Martin Popel, Věra Kloudová, Michal Novák, Mariia Anisimova, Jiří Balhar","The EdUKate project combines digital education, linguistics, translation studies, and machine translation to develop multilingual learning materials for Czech primary and secondary schools. Launched through collaboration between a major Czech academic institution and the country's largest educational publisher, the project is aimed at translating up to 9,000 multimodal interactive exercises from Czech into Ukrainian, English, and German for an educational web portal. It emphasizes the development and evaluation of a direct Czech-Ukrainian machine translation system tailored to the educational domain, with special attention to processing formatted content such as XML and PDF and handling technical and scientific terminology. We present findings from an initial survey of Czech teachers regarding the needs of non-Czech-speaking students and describe the system's evaluation and implementation on the web portal. All resulting applications are freely available to students, educators, and researchers. △ Less",https://arxiv.org/abs/2509.09473,arxiv_exercise_page0.csv
Accelerating AI Development with Cyber Arenas,"William Cashman, Chasen Milner, Michael Houle, Michael Jones, Hayden Jananthan, Jeremy Kepner, Peter Michaleas, Alex Pentland",AI development requires high fidelity testing environments to effectively transition from the laboratory to operations. The flexibility offered by cyber arenas presents a novel opportunity to test new artificial intelligence (AI) capabilities with users. Cyber arenas are designed to expose end-users to real-world situations and must rapidly incorporate evolving capabilities to meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph Challenge Anonymized Network Sensor was deployed in a cyber arena during a National Guard exercise . △ Less,https://arxiv.org/abs/2509.08200,arxiv_exercise_page0.csv
Joint calibration of the volatility surface and variance term structure,Jiwook Yoo,"This article proposes a calibration framework for complex option pricing models that jointly fits market option prices and the term structure of variance. Calibrated models under the conventional objective function, the sum of squared errors in Black-Scholes implied volatilities, can produce model-implied variance term structures with large errors relative to those observed in the market and implied by option prices. I show that this can occur even when the model-implied volatility surface closely matches the volatility surface observed in the market. The proposed joint calibration addresses this issue by augmenting the conventional objective function with a penalty term for large deviations from the observed variance term structure. This augmented objective function features a hyperparameter that governs the relative weight placed on the volatility surface and the variance term structure. I test this framework on a jump-diffusion model with stochastic volatility in two calibration exercises : the first using volatility surfaces generated under a Bates model, and the second using a panel of S&P 500 equity index options covering the 1996-2023 period. I demonstrate that the proposed method is able to fit observed option prices well while delivering realistic term structures of variance. Finally, I provide guidance on the choice of hyperparameters based on the results of these numerical exercises . △ Less",https://arxiv.org/abs/2509.08096,arxiv_exercise_page0.csv
Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees,"Katsuaki Nakano, Reza Feyyazi, Shanchieh Jay Yang, Michael Zuzak","Recent advances in Large Language Models (LLMs) have driven interest in automating cybersecurity penetration testing workflows, offering the promise of faster and more consistent vulnerability assessment for enterprise systems. Existing LLM agents for penetration testing primarily rely on self-guided reasoning, which can produce inaccurate or hallucinated procedural steps. As a result, the LLM agent may undertake unproductive actions, such as exploiting unused software libraries or generating cyclical responses that repeat prior tactics. In this work, we propose a guided reasoning pipeline for penetration testing LLM agents that incorporates a deterministic task tree built from the MITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the LLM's reaoning process to explicitly defined tactics, techniques, and procedures. This anchors reasoning in proven penetration testing methodologies and filters out ineffective actions by guiding the agent towards more productive attack procedures. To evaluate our approach, we built an automated penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with 103 discrete subtasks representing real-world cyberattack scenarios. Our proposed reasoning pipeline guided the LLM agent through 71.8\%, 72.8\%, and 78.6\% of subtasks using Llama-3-8B, Gemini-1.5, and GPT-4, respectively. Comparatively, the state-of-the-art LLM penetration testing tool using self-guided reasoning completed only 13.5\%, 16.5\%, and 75.7\% of subtasks and required 86.2\%, 118.7\%, and 205.9\% more model queries. This suggests that incorporating a deterministic task tree into LLM reasoning pipelines can enhance the accuracy and efficiency of automated cybersecurity assessments △ Less",https://arxiv.org/abs/2509.07939,arxiv_exercise_page0.csv
Nuclear Data Adjustment for Nonlinear Applications in the OECD/NEA WPNCS SG14 Benchmark -- A Bayesian Inverse UQ-based Approach for Data Assimilation,"Christopher Brady, Xu Wu","The Organization for Economic Cooperation and Development (OECD) Working Party on Nuclear Criticality Safety (WPNCS) proposed a benchmark exercise to assess the performance of current nuclear data adjustment techniques applied to nonlinear applications and experiments with low correlation to applications. This work introduces Bayesian Inverse Uncertainty Quantification (IUQ) as a method for nuclear data adjustments in this benchmark, and compares IUQ to the more traditional methods of Generalized Linear Least Squares (GLLS) and Monte Carlo Bayes (MOCABA). Posterior predictions from IUQ showed agreement with GLLS and MOCABA for linear applications. When comparing GLLS, MOCABA, and IUQ posterior predictions to computed model responses using adjusted parameters, we observe that GLLS predictions fail to replicate computed response distributions for nonlinear applications, while MOCABA shows near agreement, and IUQ uses computed model responses directly. We also discuss observations on why experiments with low correlation to applications can be informative to nuclear data adjustments and identify some properties useful in selecting experiments for inclusion in nuclear data adjustment. Performance in this benchmark indicates potential for Bayesian IUQ in nuclear data adjustments. △ Less",https://arxiv.org/abs/2509.07790,arxiv_exercise_page0.csv
zkUnlearner: A Zero-Knowledge Framework for Verifiable Unlearning with Multi-Granularity and Forgery-Resistance,"Nan Wang, Nan Wu, Xiangyu Hui, Jiafan Wang, Xin Yuan","As the demand for exercising the ""right to be forgotten"" grows, the need for verifiable machine unlearning has become increasingly evident to ensure both transparency and accountability. We present {\em zkUnlearner}, the first zero-knowledge framework for verifiable machine unlearning, specifically designed to support {\em multi-granularity} and {\em forgery-resistance}.
  First, we propose a general computational model that employs a {\em bit-masking} technique to enable the {\em selectivity} of existing zero-knowledge proofs of training for gradient descent algorithms. This innovation enables not only traditional {\em sample-level} unlearning but also more advanced {\em feature-level} and {\em class-level} unlearning. Our model can be translated to arithmetic circuits, ensuring compatibility with a broad range of zero-knowledge proof systems. Furthermore, our approach overcomes key limitations of existing methods in both efficiency and privacy. Second, forging attacks present a serious threat to the reliability of unlearning. Specifically, in Stochastic Gradient Descent optimization, gradients from unlearned data, or from minibatches containing it, can be forged using alternative data samples or minibatches that exclude it. We propose the first effective strategies to resist state-of-the-art forging attacks. Finally, we benchmark a zkSNARK-based instantiation of our framework and perform comprehensive performance evaluations to validate its practicality. △ Less",https://arxiv.org/abs/2509.07290,arxiv_exercise_page0.csv
What is the most massive gravitational-wave source?,Ilya Mandel,"In the presence of significant measurement uncertainties, the events which appear to be the most extreme are very likely to be those exhibiting the greatest statistical fluctuations. It is therefore particularly important to exercise care when interpreting such events and to use the entire observed population for context. Here, I attempt to pedagogically illustrate this using the example of the most massive binary black hole so far detected in gravitational-wave data, GW231123. I argue that its total mass may be significantly lower than $238^{+28}_{-49}$ solar masses as reported by Abac et al. (2025a). The maximum total binary black hole mass from an analysis of the entire detected population may well be less than 140 solar masses, but the value is very sensitive to assumptions about the population distribution. △ Less",https://arxiv.org/abs/2509.05885,arxiv_exercise_page0.csv
Bridging the Gap Between Theoretical and Practical Reinforcement Learning in Undergraduate Education,"Muhammad Ahmed Atif, Mohammad Shahid Shaikh","This innovative practice category paper presents an innovative framework for teaching Reinforcement Learning (RL) at the undergraduate level. Recognizing the challenges posed by the complex theoretical foundations of the subject and the need for hands-on algorithmic practice, the proposed approach integrates traditional lectures with interactive lab-based learning. Drawing inspiration from effective pedagogical practices in computer science and engineering, the framework engages students through real-time coding exercises using simulated environments such as OpenAI Gymnasium. The effectiveness of this approach is evaluated through student surveys, instructor feedback, and course performance metrics, demonstrating improvements in understanding, debugging, parameter tuning, and model evaluation. Ultimately, the study provides valuable insight into making Reinforcement Learning more accessible and engaging, thereby equipping students with essential problem-solving skills for real-world applications in Artificial Intelligence. △ Less",https://arxiv.org/abs/2509.05689,arxiv_exercise_page0.csv
Magnetic Field Induced by Straight Currents on the Hyperboloid,Tomotoshi Nishino,"As an introductory exercise of elementary electrodynamics, we consider the static magnetic field induced by the electric currents flow along the straight wires, which are equidistantly put on the hyperboloid. The distribution of the magnetic field and the force acting on the wires are calculated under several typical setups, including the continuum limit. △ Less",https://arxiv.org/abs/2509.04407,arxiv_exercise_page0.csv
Reactive Bottom-Up Testing,"Siddharth Muralee, Sourag Cherupattamoolayil, James C. Davis, Antonio Bianchi, Aravind Machiry","Modern computing systems remain rife with software vulnerabilities. Engineers apply many means to detect them, of which dynamic testing is one of the most common and effective. However, most dynamic testing techniques follow a top-down paradigm, and struggle to reach and exercise functions deep within the call graph. While recent works have proposed Bottom-Up approaches to address these limitations, they face challenges with false positives and generating valid inputs that adhere to the context of the entire program.
  In this work, we introduce a new paradigm that we call Reactive Bottom-Up Testing. Our insight is that function-level testing is necessary but not sufficient for the validation of vulnerabilities in functions. What we need is a systematic approach that not only tests functions in isolation but also validates their behavior within the broader program context, ensuring that detected vulnerabilities are both reachable and triggerable. We develop a three-stage bottom-up testing scheme: (1) identify likely-vulnerable functions and generate type- and context-aware harnesses; (2) fuzz to find crashes and extract input constraints via symbolic execution; (3) verify crashes by combining constraints to remove false positives. We implemented an automated prototype, which we call Griller. We evaluated Griller in a controlled setting using a benchmark of 48 known vulnerabilities across 5 open-source projects, where we successfully detected 28 known vulnerabilities. Additionally, we evaluated Griller on several real-world applications such as Pacman, and it discovered 6 previously unknown vulnerabilities. Our findings suggest that Reactive Bottom-Up Testing can significantly enhance the detection of vulnerabilities in complex systems, paving the way for more robust security practices. △ Less",https://arxiv.org/abs/2509.03711,arxiv_exercise_page0.csv
Quantum Vacuum energy as the origin of Gravity,André LeClair,"We explore the idea that quantum vacuum energy $ρ_{\rm vac} $ is at the origin of Gravity as a theoretical exercise . We formulate a gravitational version of the electromagnetic Casimir effect, and provide an argument for how gravity can arise from $ρ_{\rm vac} $ by showing how Einstein's field equations emerge in the form of Friedmann's equations. This leads to the idea that Newton's constant $G_N$ is environmental, namely it depends on the total mass-energy of the Universe $M_\infty $ and its size $R_\infty $, with $G_N = c^2 R_\infty /2 M_\infty$. This leads to a new interpretation of the Gibbons-Hawking entropy of de Sitter space, and also the Bekenstein-Hawking entropy for black holes, wherein the quantum information bits are quantized massless particles at the horizon with wavelength $λ= 2 πR_\infty$. We assume a recently proposed formula for $ρ_{\rm vac} \sim m_z^4/\mathfrak{g}$, where $m_z$ is the mass of the lightest particle, and $\mathfrak{g}$ is a marginally irrelevant coupling. This leads to an effective, induced RG flow for Newton's constant $G_N$ as a function of an energy scale, which indicates that $G_N$ decreases at higher energies until it reaches a Landau pole at a minimal value of the cosmological scale factor $a(t) > a_{\rm min}$, thus avoiding the usual geometric singularity at $a=0$. The solution to the scale factor satisfies an interesting symmetry between the far past and far future due to $a(t) = a(-t + 2 t_{\rm min})$, where $a(t_{\rm min}) = a_{\rm min}$. We propose that this energy scale dependent $G_N$ can explain the Hubble tension and we thereby constrain the coupling constant $\mathfrak{g}$ and its renormalization group parameters. For the $Λ{\rm CDM}$ model we estimate $a_{\rm min} \approx e^{-1/\hat{b} }$ where $\hat{b} \approx 0.02$ based on the Hubble tension data. △ Less",https://arxiv.org/abs/2509.02636,arxiv_exercise_page0.csv
Enhancing Fitness Movement Recognition with Attention Mechanism and Pre-Trained Feature Extractors,"Shanjid Hasan Nishat, Srabonti Deb, Mohiuddin Ahmed","Fitness movement recognition, a focused subdomain of human activity recognition (HAR), plays a vital role in health monitoring, rehabilitation, and personalized fitness training by enabling automated exercise classification from video data. However, many existing deep learning approaches rely on computationally intensive 3D models, limiting their feasibility in real-time or resource-constrained settings. In this paper, we present a lightweight and effective framework that integrates pre-trained 2D Convolutional Neural Networks (CNNs) such as ResNet50, EfficientNet, and Vision Transformers (ViT) with a Long Short-Term Memory (LSTM) network enhanced by spatial attention. These models efficiently extract spatial features while the LSTM captures temporal dependencies, and the attention mechanism emphasizes informative segments. We evaluate the framework on a curated subset of the UCF101 dataset, achieving a peak accuracy of 93.34\% with the ResNet50-based configuration. Comparative results demonstrate the superiority of our approach over several state-of-the-art HAR systems. The proposed method offers a scalable and real-time-capable solution for fitness activity recognition with broader applications in vision-based health and activity monitoring. △ Less",https://arxiv.org/abs/2509.02511,arxiv_exercise_page0.csv
Pricing American Options Time-Capped by a Drawdown Event,"Zbigniew Palmowski, Paweł Stȩpniak","This paper presents a derivation of the explicit price for the perpetual American put option in the Black-Scholes model, time-capped by the first drawdown epoch beyond a predefined level. We demonstrate that the optimal exercise strategy involves executing the option when the asset price first falls below a specified threshold. The proof relies on martingale arguments and the fluctuation theory of Lévy processes. To complement the theoretical findings, we provide numerical analysis. △ Less",https://arxiv.org/abs/2509.00999,arxiv_exercise_page0.csv
Pricing American options with exogenous and endogenous transaction costs,"Dong Yan, Xin-Jie Huang, Guiyuan Ma, Xin-Jiang He","We study an American option pricing problem with liquidity risks and transaction fees. As endogenous transaction costs, liquidity risks of the underlying asset are modeled by a mean-reverting process. Transaction fees are exogenous transaction costs and are assumed to be proportional to the trading amount, with the long-run liquidity level depending on the proportional transaction costs rate. Two nonlinear partial differential equations are established to characterize the option values for the holder and the writer, respectively. To illustrate the impact of these transaction costs on option prices and optimal exercise prices, we apply the alternating direction implicit method to solve the linear complementarity problem numerically. Finally, we conduct model calibration from market data via maximum likelihood estimation, and find that our model incorporating liquidity risks outperforms the Leland model significantly. △ Less",https://arxiv.org/abs/2509.00485,arxiv_exercise_page0.csv
Learning from the past in an irreversible investment problem,Topias Tolonen-Weckström,"We consider an irreversible investment problem under incomplete information, where the investor is able to exercise multiple investment rights to a project. The investor does not observe the project value directly and instead only a noisy observation process is observed. Upon each investment, the investor acquires previously hidden information from the project's past (''learning from the past''), and so the learning rate of the problem is controlled by investing. The acquisition of additional information is modeled by letting each investment affect the elapsed time of the observation process. We set up the problem as a recursively defined multiple stopping problem under incomplete information and present the optimal investment strategy as a sequence of stopping boundaries, where the boundaries are solved from equations derived from smooth fit conditions. Examples of optimal boundaries are then solved numerically, and we provide numerical comparative statistics. △ Less",https://arxiv.org/abs/2508.21731,arxiv_exercise_page0.csv
Lectures on the Spinor and Twistor Formalism in 3D Conformal Field Theory,Dhruva K. S,"These notes are based on my lectures given at $\text{ST}^4$ 2025 held at IISER Bhopal. We study the application of spinor and twistor methods to three dimensional conformal field theories in these notes. They are divided into three parts dealing with spinor helicity, twistors and super-twistors respectively. In the first part, we introduce the off-shell spinor helicity formalism and apply it in several contexts including double copy relations, connection to four dimensional scattering amplitudes, correlators in Chern-Simons matter theories and the holography of chiral higher spin theory. The second part of the notes introduces the twistor space formalism. After discussing the geometry of twistor space, we derive the Penrose transform for conserved currents, scalars with arbitrary scaling dimension as well as generic non-conserved operators. We also explicitly show how the spinor and twistor approaches are related. We discuss how correlators of these operators and conserved currents in particular drastically simplify in twistor space unveiling their hidden simplicity. We also extend our construction to super-conformal field theories and develop a manifest super-twistor space formalism and derive the supersymmetric Penrose transform. We find that the supersymmetric correlators are simple and natural generalizations of their non-supersymmetric counterparts. The notes are made to be self-contained and also include over $50$ exercises that illustrate the formalism. △ Less",https://arxiv.org/abs/2508.21633,arxiv_exercise_page0.csv
Time Series Embedding and Combination of Forecasts: A Reinforcement Learning Approach,"Marcelo C. Medeiros, Jeronymo M. Pinro","The forecasting combination puzzle is a well-known phenomenon in forecasting literature, stressing the challenge of outperforming the simple average when aggregating forecasts from diverse methods. This study proposes a Reinforcement Learning - based framework as a dynamic model selection approach to address this puzzle. Our framework is evaluated through extensive forecasting exercises using simulated and real data. Specifically, we analyze the M4 Competition dataset and the Survey of Professional Forecasters (SPF). This research introduces an adaptable methodology for selecting and combining forecasts under uncertainty, offering a promising advancement in resolving the forecasting combination puzzle. △ Less",https://arxiv.org/abs/2508.20795,arxiv_exercise_page0.csv
Identifying Framing Practices in Visualization Design Through Practitioner Reflections,"Prakash Shukla, Paul Parsons","Framing -- how designers define and reinterpret problems, shape narratives, and guide audience understanding -- is central to design practice. Yet in visualization research, framing has been examined mostly through its rhetorical and perceptual effects on audiences, leaving its role in the design process underexplored. This study addresses that gap by analyzing publicly available podcasts and book chapters in which over 80 professional visualization designers reflect on their work. We find that framing is a pervasive, iterative activity, evident in scoping problems, interpreting data, aligning with stakeholder goals, and shaping narrative direction. Our analysis identifies the conditions that trigger reframing and the strategies practitioners use to navigate uncertainty and guide design. These findings position framing as a core dimension of visualization practice and underscore the need for research and education to support the interpretive and strategic judgment that practitioners exercise throughout the design process. △ Less",https://arxiv.org/abs/2508.20383,arxiv_exercise_page0.csv
MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models,"Xiao Li, Yanfan Zhu, Ruining Deng, Wei-Qi Wei, Yu Wang, Shilin Zhao, Yaohong Wang, Haichun Yang, Yuankai Huo","Recent advances in medical vision-language models (VLMs) open up remarkable opportunities for clinical applications such as automated report generation, copilots for physicians, and uncertainty quantification. However, despite their promise, medical VLMs introduce serious security concerns, most notably risks of Protected Health Information (PHI) exposure, data leakage, and vulnerability to cyberthreats - which are especially critical in hospital environments. Even when adopted for research or non-clinical purposes, healthcare organizations must exercise caution and implement safeguards. To address these challenges, we present MedFoundationHub, a graphical user interface (GUI) toolkit that: (1) enables physicians to manually select and use different models without programming expertise, (2) supports engineers in efficiently deploying medical VLMs in a plug-and-play fashion, with seamless integration of Hugging Face open-source models, and (3) ensures privacy-preserving inference through Docker-orchestrated, operating system agnostic deployment. MedFoundationHub requires only an offline local workstation equipped with a single NVIDIA A6000 GPU, making it both secure and accessible within the typical resources of academic research labs. To evaluate current capabilities, we engaged board-certified pathologists to deploy and assess five state-of-the-art VLMs (Google-MedGemma3-4B, Qwen2-VL-7B-Instruct, Qwen2.5-VL-7B-Instruct, and LLaVA-1.5-7B/13B). Expert evaluation covered colon cases and renal cases, yielding 1015 clinician-model scoring events. These assessments revealed recurring limitations, including off-target answers, vague reasoning, and inconsistent pathology terminology. △ Less",https://arxiv.org/abs/2508.20345,arxiv_exercise_page0.csv
"Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills",David Noever,"This paper identifies and analyzes a novel vulnerability class in Model Context Protocol (MCP) based agent systems. The attack chain describes and demonstrates how benign, individually authorized tasks can be orchestrated to produce harmful emergent behaviors. Through systematic analysis using the MITRE ATLAS framework, we demonstrate how 95 agents tested with access to multiple services-including browser automation, financial analysis, location tracking, and code deployment-can chain legitimate operations into sophisticated attack sequences that extend beyond the security boundaries of any individual service. These red team exercises survey whether current MCP architectures lack cross-domain security measures necessary to detect or prevent a large category of compositional attacks. We present empirical evidence of specific attack chains that achieve targeted harm through service orchestration, including data exfiltration, financial manipulation, and infrastructure compromise. These findings reveal that the fundamental security assumption of service isolation fails when agents can coordinate actions across multiple domains, creating an exponential attack surface that grows with each additional capability. This research provides a barebones experimental framework that evaluate not whether agents can complete MCP benchmark tasks, but what happens when they complete them too well and optimize across multiple services in ways that violate human expectations and safety constraints. We propose three concrete experimental directions using the existing MCP benchmark suite. △ Less",https://arxiv.org/abs/2508.19500,arxiv_exercise_page0.csv
Mathematical Analysis 1 (Chapters in Univariate Real Analysis),Martin Klazar,"Preliminary version of a course in univariate real analysis, with 14 chapters and 1 appendix (Chapters 1-8 complete at present). 1. Infinite sums. Real numbers; 2. Limits of sequences and subsequences; 3. Arithmetic of limits. AK series; 4. Infinite series. Elementary functions; 5. Limits of functions. Asymptotic notation; 6. Continuous functions; 7. Derivatives; 8. Applications of mean value theorems; 9. Taylor polynomials and series. Real analytic functions; 10. Primitives of uniformly continuous functions; 11. Newton integral. Primitives of rational functions; 12. Riemann integral. Transcendence of the number e; 13. Riemann integral. Henstock--Kurzweil integral; 14. More applications of Riemann integral; and A. Solutions to exercises . △ Less",https://arxiv.org/abs/2508.19405,arxiv_exercise_page0.csv
"Epistemic Trade-Off: An Analysis of the Operational Breakdown and Ontological Limits of ""Certainty-Scope"" in AI",Generoso Immediato,"Floridi's conjecture offers a compelling intuition about the fundamental trade-off between certainty and scope in artificial intelligence (AI) systems. This exploration remains crucial, not merely as a philosophical exercise , but as a potential compass for guiding AI investments, particularly in safety-critical industrial domains where the level of attention will surely be higher in the future. However, while intellectually coherent, its formalization ultimately freezes this insight into a suspended epistemic truth, resisting operationalization within real-world systems. This paper is a result of an analysis arguing that the conjecture's ambition to provide insights to engineering design and regulatory decision-making is constrained by two critical factors: first, its reliance on incomputable constructs - rendering it practically unactionable and unverifiable; second, its underlying ontological assumption of AI systems as self-contained epistemic entities - separating it from the intricate and dynamic socio-technical environments in which knowledge is co-constructed. We conclude that this dual breakdown - an epistemic closure deficit and an embeddedness bypass - prevents the conjecture from transitioning into a computable and actionable framework suitable for informing the design, deployment, and governance of real-world AI hybrid systems. In response, we propose a contribution to the framing of Floridi's epistemic challenge, addressing the inherent epistemic burdens of AI within complex human-centric domains. △ Less",https://arxiv.org/abs/2508.19304,arxiv_exercise_page0.csv
Dynamic Count Models with Flexible Innovation Processes for Irregular Maritime Migration,"Gregor Zens, Jakub Bijak","Motivated by the dynamics of weekly sea border crossings in the Mediterranean (2015-2025) and the English Channel (2018-2025), we develop a Bayesian dynamic framework for modeling potentially heteroskedastic count time series. Building on theoretical considerations and empirical stylized facts, our approach specifies a latent log-intensity that follows a random walk driven by either heavy-tailed or stochastic volatility innovations, incorporating an explicit mechanism to separate structural from sampling zeros. Posterior inference is carried out via a straightforward Markov chain Monte Carlo algorithm. We compare alternative innovation specifications through a comprehensive out-of-sample density forecasting exercise , evaluating each model using log predictive scores and empirical coverage up to the 99th percentile of the predictive distribution. The results of two case studies reveal strong evidence for stochastic volatility in sea migration innovations, with stochastic volatility models producing particularly well-calibrated forecasts even at extreme quantiles. The model can be used to develop risk indicators and has direct policy implications for improving governance and preparedness for sea migration surges. The presented methodology readily extends to other zero-inflated non-stationary count time series applications, including epidemiological surveillance and public safety incident monitoring. △ Less",https://arxiv.org/abs/2508.18716,arxiv_exercise_page0.csv
Gamification of Immersive Cervical RehabilitationExercisesin VR: An Exploratory Study on Chin Tuck and Range of MotionExercises,"Haitham Abdelsalam, Chanelle Montpetit, Arash Harirpoush, Maryse Fortin, Yiming Xiao","Chronic neck pain is a prevalent condition that affects millions of individuals worldwide, causing significant individual suffering and socioeconomic burdens. Although exercise rehabilitation is a staple in relieving pain and improving muscle function for the condition, traditional one-on-one rehabilitation sessions are costly and suffer from poor adherence and accessibility for the patients. Thanks to the increasing accessibility and recent advancements in sensing and display technology, virtual reality (VR) offers the potential to tackle the challenges in traditional exercise rehabilitation, particularly through gamification. However, still in its infancy, VR-based neck exercise rehabilitation lacks exploration in effective gamification strategies and existing prototypes. To address the knowledge gap, we conduct an exploratory study on the gamification strategies for VR-based cervical rehabilitation exercises by using chin tuck and neck range of motion exercises as examples. Specifically, with different game themes, we investigate a survival and level progression strategy for muscle strengthening (chin tuck) exercise for the first time, and the suitability of ambient reward for a neck range of motion exercise . Through a preliminary user study, we assess the proposed novel VR neck rehabilitation games and they demonstrate excellent usability, engagement, and perceived health value. △ Less",https://arxiv.org/abs/2508.18580,arxiv_exercise_page0.csv
Collaborative Intelligence: Topic Modelling of Large Language Model use in Live Cybersecurity Operations,"Martin Lochner, Keegan Keplinger","Objective: This work describes the topic modelling of Security Operations Centre (SOC) use of a large language model (LLM), during live security operations. The goal is to better understand how these specialists voluntarily use this tool.
  Background: Human-automation teams have been extensively studied, but transformer-based language models have sparked a new wave of collaboration. SOC personnel at a major cybersecurity provider used an LLM to support live security operations. This study examines how these specialists incorporated the LLM into their work.
  Method: Our data set is the result of 10 months of SOC operators accessing GPT-4 over an internally deployed HTTP-based chat application. We performed two topic modelling exercises , first using the established BERTopic model (Grootendorst, 2022), and second, using a novel topic modeling workflow.
  Results: Both the BERTopic analysis and novel modelling approach revealed that SOC operators primarily used the LLM to facilitate their understanding of complex text strings. Variations on this use-case accounted for ~40% of SOC LLM usage.
  Conclusion: SOC operators are required to rapidly interpret complex commands and similar information. Their natural tendency to leverage LLMs to support this activity indicates that their workflow can be supported and augmented by designing collaborative LLM tools for use in the SOC.
  Application: This work can aid in creating next-generation tools for Security Operations Centres. By understanding common use-cases, we can develop workflows supporting SOC task flow. One example is a right-click context menu for executing a command line analysis LLM call directly in the SOC environment. △ Less",https://arxiv.org/abs/2508.18488,arxiv_exercise_page0.csv
Technology-assisted Personalized Yoga for Better Health -- Challenges and Outlook,"Vivek Kumar, Himanshu Sahu, Hari Prabhat Gupta, Biplav Srivastava","Yoga is a discipline of physical postures, breathing techniques, and meditative practices rooted in ancient Indian traditions, now embraced worldwide for promoting overall well-being and inner balance. The practices are a large set of items, our term for executable actions like physical poses or breath exercises , to offer for a person's well-being. However, to get benefits of Yoga tailored to a person's unique needs, a person needs to (a) discover their subset from the large and seemingly complex set with inter-dependencies, (b) continue to follow them with interest adjusted to their changing abilities and near-term objectives, and (c) as appropriate, adapt to alternative items based on changing environment and the person's health conditions. In this vision paper, we describe the challenges for the Yoga personalization problem. Next, we sketch a preliminary approach and use the experience to provide an outlook on solving the challenging problem using existing and novel techniques from a multidisciplinary computing perspective. To the best of our knowledge, this is the first paper that comprehensively examines decision support issues around Yoga personalization, from pose sensing to recommendation of corrections for a complete regimen, and illustrates with a case study of Surya Namaskar -- a set of 12 choreographed poses. △ Less",https://arxiv.org/abs/2508.18283,arxiv_exercise_page0.csv
SOT-MRAM Bitcell Scaling with BEOL Read Selectors: A DTCO Study,"Yang Xiang, Fernando García-Redondo, Arvind Sharma, Van Dai Nguyen, Andrea Fantini, Philippe Matagne, Siddharth Rao, Subhali Subhechha, Lynn Verschueren, Mohammed Aftab Baig, Marie Garcia Bardon, Geert Hellings","This work explores the cross-node scaling potential of SOT-MRAM for last-level caches (LLCs) under heterogeneous system scaling paradigm. We perform extensive Design-Technology Co-Optimization (DTCO) exercises to evaluate the bitcell footprint for different cell configurations at a representative 7 nm technology and to assess their implications on read and write power-performance. We crucially identify the MTJ routing struggle in conventional two-transistor one-resistor (2T1R) SOT-MRAMs as the primary bitcell area scaling challenge and propose to use BEOL read selectors (BEOL RSs) that enable (10 -- 40) % bitcell area reduction and eventually match sub-N3 SRAM. On writability, we affirm that BEOL RS-based bitcells could meet the required SOT switching current, provided the magnetic free layer properties be engineered in line with LLC-specific, (0.1 -- 100) s retention targets. This is particularly to attribute to their (i) more available Si fins for write transistor and (ii) lower bitline resistance at reduced cell width. We nevertheless underscore the read tradeoff associated with BEOL RSs, with the low-drive IGZO-FET selector sacrificing the latency up to (3 -- 5) ns and the imperfectly rectifying diode selectors suffering (2.5 -- 5)$\times$ energy cost relative to 2T1R. This article thus highlights the realistic prospects and hurdles of BEOL RSs towards holistic power-performance-area scaling of SOT-MRAM. △ Less",https://arxiv.org/abs/2508.18250,arxiv_exercise_page0.csv
Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation,"Konstantin Egorov, Stepan Botman, Pavel Blinov, Galina Zubkova, Anton Ivaschenko, Alexander Kolsanov, Andrey Savchenko","Progress in remote PhotoPlethysmoGraphy (rPPG) is limited by the critical issues of existing publicly available datasets: small size, privacy concerns with facial videos, and lack of diversity in conditions. The paper introduces a novel comprehensive large-scale multi-view video dataset for rPPG and health biomarkers estimation. Our dataset comprises 3600 synchronized video recordings from 600 subjects, captured under varied conditions (resting and post- exercise ) using multiple consumer-grade cameras at different angles. To enable multimodal analysis of physiological states, each recording is paired with a 100 Hz PPG signal and extended health metrics, such as electrocardiogram, arterial blood pressure, biomarkers, temperature, oxygen saturation, respiratory rate, and stress level. Using this data, we train an efficient rPPG model and compare its quality with existing approaches in cross-dataset scenarios. The public release of our dataset and model should significantly speed up the progress in the development of AI medical assistants. △ Less",https://arxiv.org/abs/2508.17924,arxiv_exercise_page0.csv
Model-Based Testing of an Intermediate Verifier Using Executable Operational Semantics,"Lidia Losavio, Marco Paganoni, Carlo A. Furia","Lightweight validation technique, such as those based on random testing, are sometimes practical alternatives to full formal verification -- providing valuable benefits, such as finding bugs, without requiring a disproportionate effort. In fact, they can be useful even for fully formally verified tools, by exercising the parts of a complex system that go beyond the reach of formal models.
  In this context, this paper introduces BCC: a model-based testing technique for the Boogie intermediate verifier. BCC combines the formalization of a small, deterministic subset of the Boogie language with the generative capabilities of the PLT Redex language engineering framework. Basically, BCC uses PLT Redex to generate random Boogie programs, and to execute them according to a formal operational semantics; then, it runs the same programs through the Boogie verifier. Any inconsistency between the two executions (in PLT Redex and with Boogie) may indicate a potential bug in Boogie's implementation.
  To understand whether BCC can be useful in practice, we used it to generate three million Boogie programs. These experiments found 2% of cases indicative of completeness failures (i.e., spurious verification failures) in Boogie's toolchain. These results indicate that lightweight analysis tools, such as those for model-based random testing, are also useful to test and validate formal verification tools such as Boogie. △ Less",https://arxiv.org/abs/2508.17895,arxiv_exercise_page0.csv
Representation Learning of Auxiliary Concepts for Improved Student Modeling andExerciseRecommendation,"Yahya Badran, Christine Preisach","Personalized recommendation is a key feature of intelligent tutoring systems, typically relying on accurate models of student knowledge. Knowledge Tracing (KT) models enable this by estimating a student's mastery based on their historical interactions. Many KT models rely on human-annotated knowledge concepts (KCs), which tag each exercise with one or more skills or concepts believed to be necessary for solving it. However, these KCs can be incomplete, error-prone, or overly general.
  In this paper, we propose a deep learning model that learns sparse binary representations of exercises , where each bit indicates the presence or absence of a latent concept. We refer to these representations as auxiliary KCs. These representations capture conceptual structure beyond human-defined annotations and are compatible with both classical models (e.g., BKT) and modern deep learning KT architectures.
  We demonstrate that incorporating auxiliary KCs improves both student modeling and adaptive exercise recommendation. For student modeling, we show that augmenting classical models like BKT with auxiliary KCs leads to improved predictive performance. For recommendation, we show that using auxiliary KCs enhances both reinforcement learning-based policies and a simple planning-based method (expectimax), resulting in measurable gains in student learning outcomes within a simulated student environment. △ Less",https://arxiv.org/abs/2508.16269,arxiv_exercise_page0.csv
A Review of Developmental Interpretability in Large Language Models,Ihor Kendiukhov,"This review synthesizes the nascent but critical field of developmental interpretability for Large Language Models. We chart the field's evolution from static, post-hoc analysis of trained models to a dynamic investigation of the training process itself. We begin by surveying the foundational methodologies, including representational probing, causal tracing, and circuit analysis, that enable researchers to deconstruct the learning process. The core of this review examines the developmental arc of LLM capabilities, detailing key findings on the formation and composition of computational circuits, the biphasic nature of knowledge acquisition, the transient dynamics of learning strategies like in-context learning, and the phenomenon of emergent abilities as phase transitions in training. We explore illuminating parallels with human cognitive and linguistic development, which provide valuable conceptual frameworks for understanding LLM learning. Finally, we argue that this developmental perspective is not merely an academic exercise but a cornerstone of proactive AI safety, offering a pathway to predict, monitor, and align the processes by which models acquire their capabilities. We conclude by outlining the grand challenges facing the field, such as scalability and automation, and propose a research agenda for building more transparent, reliable, and beneficial AI systems. △ Less",https://arxiv.org/abs/2508.15841,arxiv_exercise_page0.csv
Multivariate quantile regression,"Antonio F. Galvao, Gabriel Montes-Rojas","This paper introduces a new framework for multivariate quantile regression based on the multivariate distribution function, termed multivariate quantile regression (MQR). In contrast to existing approaches--such as directional quantiles, vector quantile regression, or copula-based methods--MQR defines quantiles through the conditional probability structure of the joint conditional distribution function. The method constructs multivariate quantile curves using sequential univariate quantile regressions derived from conditioning mechanisms, allowing for an intuitive interpretation and flexible estimation of marginal effects. The paper develops theoretical foundations of MQR, including asymptotic properties of the estimators. Through simulation exercises , the estimator demonstrates robust finite sample performance across different dependence structures. As an empirical application, the MQR framework is applied to the analysis of exchange rate pass-through in Argentina from 2004 to 2024. △ Less",https://arxiv.org/abs/2508.15749,arxiv_exercise_page0.csv
Visualization on Smart Wristbands: Results from an In-situ Design Workshop with Four Scenarios,"Alaul Islam, Fairouz Grioui, Raimund Dachselt, Petra Isenberg","We present the results of an in-situ ideation workshop for designing data visualizations on smart wristbands that can show data around the entire wrist of a wearer. Wristbands pose interesting challenges because the visibility of different areas of the band depends on the wearer's arm posture. We focused on four usage scenarios that lead to different postures: office work, leisurely walks, cycling, and driving. As the technology for smart wristbands is not yet commercially available, we conducted a paper-based ideation exercise that showed how spatial layout and visualization design on smart wristbands may need to vary depending on the types of data items of interest and arm postures. Participants expressed a strong preference for responsive visualization designs that could adapt to the movement of wearers' arms. Supplemental material from the study is available here: https://osf.io/4hrca/. △ Less",https://arxiv.org/abs/2508.15249,arxiv_exercise_page0.csv
An Investigation Into Secondary School Students' Debugging Behaviour in Python,"Laurie Gale, Sue Sentance","Background and context: Debugging is a common and often frustrating challenge for beginner programmers. Understanding students' debugging processes can help us identify the difficulties and misunderstandings they possess. However, we currently have limited knowledge of how secondary students debug in a text-based language, a medium through which millions of students will learn to program in the future. Objectives: In this paper, we investigate the debugging behaviour of K-12 students learning a text-based programming language, as part of an effort to shape how to effectively teach debugging to these students. Method: We collected log data from 73 students attempting a set of debugging exercises using an online code editor. We inductively analysed these logs using qualitative content analysis, generating a categorisation of the debugging behaviours observed. Findings: A range of behaviours were exhibited by students, skewed towards being ineffective. Most students were able to partially locate errors but often struggled to resolve them, sometimes introducing additional errors in the process. We argue that students struggling to debug possess fragile knowledge, a lens through which we view the results. Implications: This paper highlights some of the difficulties K-12 learners have when debugging in a text-based programming language. We argue, like much related work, that effective debugging strategies should be explicitly taught, while ineffective strategies should be discouraged. △ Less",https://arxiv.org/abs/2508.14833,arxiv_exercise_page0.csv
Precision over Noise: Tailoring S3 Public Access Detection to Reduce False Positives in Cloud Security Platforms,"Dikshant, Geetika Verma","Excessive and spurious alert generation by cloud security solutions is a root cause of analyst fatigue and operational inefficiencies. In this study, the long-standing issue of false positives from publicly accessible alerts in Amazon S3, as generated by a licensed cloud-native security solution, is examined. In a simulated production test environment, which consisted of over 1,000 Amazon S3 buckets with diverse access configurations, it was discovered that over 80\% of the alerts generated by default rules were classified as false positives, thus demonstrating the severity of the detection issue. This severely impacted detection accuracy and generated a heavier workload for analysts due to redundant manual triage efforts. For addressing this problem, custom detection logic was created as an exercise of the native rule customization capabilities of the solution. A unified titled ``S3 Public Access Validation and Data Exposure'' was created in an effort to consolidate different forms of alerts into one, context-aware logic that systematically scans ACL configurations, bucket policies, indicators of public exposure, and the presence of sensitive data, and then marks only those S3 buckets that indeed denote security risk and are publicly exposed on the internet with no authentication. The results demonstrate a significant reduction in false positives, more precise alert fidelity, and significant time saving for security analysts, thus demonstrating an actionable and reproducible solution to enhance the accuracy of security alerting in compliance-focused cloud environments. △ Less",https://arxiv.org/abs/2508.14402,arxiv_exercise_page0.csv
Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets,"Team Hunyuan3D, :, Bowen Zhang, Chunchao Guo, Haolin Liu, Hongyu Yan, Huiwen Shi, Jingwei Huang, Junlin Yu, Kunhong Li, Linus, Penghao Wang, Qingxiang Lin, Sicong Liu, Xianghui Yang, Yixuan Tang, Yunfei Zhao, Zeqiang Lai, Zhihao Liang, Zibo Zhao","Recent advances in 3D-native generative models have accelerated asset creation for games , film, and design. However, most methods still rely primarily on image or text conditioning and lack fine-grained, cross-modal controls, which limits controllability and practical adoption. To address this gap, we present Hunyuan3D-Omni, a unified framework for fine-grained, controllable 3D asset generation built on Hunyuan3D 2.1. In addition to images, Hunyuan3D-Omni accepts point clouds, voxels, bounding boxes, and skeletal pose priors as conditioning signals, enabling precise control over geometry, topology, and pose. Instead of separate heads for each modality, our model unifies all signals in a single cross-modal architecture. We train with a progressive, difficulty-aware sampling strategy that selects one control modality per example and biases sampling toward harder signals (e.g., skeletal pose) while downweighting easier ones (e.g., point clouds), encouraging robust multi-modal fusion and graceful handling of missing inputs. Experiments show that these additional controls improve generation accuracy, enable geometry-aware transformations, and increase robustness for production workflows. △ Less",https://arxiv.org/abs/2509.21245,arxiv_game_page0.csv
ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective,"Yiwen Zhang, Ziang Chen, Fanqi Kong, Yizhe Huang, Xue Feng","Large Language Models (LLMs) have been used to make decisions in complex scenarios, where they need models to think deeply, reason logically, and decide wisely. Many existing studies focus solely on multi-round conversations in social tasks or simulated environments, neglecting the various types of decisions and their interdependence. Current reinforcement learning methods struggle to consider the strategies of others during training. To address these issues, we first define a strategic decision-making problem that includes two types of decisions and their temporal dependencies. Furthermore, we propose **T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to optimize the perception of other individual strategies and the game situation trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm, ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating rollouts based on reasoning the strategies of other individuals, 2) estimating advantages at both the graph-level and sample-level, and 3) balancing global and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in terms of model output compliance and cooperative outcomes. Additionally, when compared to models with parameter sizes 100 times larger, it shows an 18% improvement. This demonstrates the effectiveness of the ToMPO algorithm in enhancing the model's strategic decision-making capabilities. △ Less",https://arxiv.org/abs/2509.21134,arxiv_game_page0.csv
A Category Theoretic Approach to ApproximateGameTheory,Neil Ghani,"This paper uses category theory to develop an entirely new approach to approximate game theory. Game theory is the study of how different agents within a multi-agent system take decisions. At its core, game theory asks what an optimal decision is in a given scenario. Thus approximate game theory asks what is an approximately optimal decision in a given scenario. This is important in practice as -- just like in much of computing -- exact answers maybe too difficult to compute or even impossible to compute given inherent uncertainty in input.
  We consider first ""Selection Functions"" which are functions and develop a simple yet robust model of approximate equilibria. We develop the algebraic properties of approximation wrt selection functions and also relate approximation to the compositional structure of selection functions. We then repeat this process successfully for Open Games -- a more advanced model of game theory. △ Less",https://arxiv.org/abs/2509.20932,arxiv_game_page0.csv
Efficient Kernelized Learning in PolyhedralGamesBeyond Full-Information: From Colonel Blotto to CongestionGames,"Andreas Kontogiannis, Vasilis Pollatos, Gabriele Farina, Panayotis Mertikopoulos, Ioannis Panageas","We examine the problem of efficiently learning coarse correlated equilibria (CCE) in polyhedral games , that is, normal-form games with an exponentially large number of actions per player and an underlying combinatorial structure. Prominent examples of such games are the classical Colonel Blotto and congestion games . To achieve computational efficiency, the learning algorithms must exhibit regret and per-iteration complexity that scale polylogarithmically in the size of the players' action sets. This challenge has recently been addressed in the full-information setting, primarily through the use of kernelization. However, in the case of the realistic, but mathematically challenging, partial-information setting, existing approaches result in suboptimal and impractical runtime complexity to learn CCE. We tackle this limitation by building a framework based on the kernelization paradigm. We apply this framework to prominent examples of polyhedral games -- namely the Colonel Blotto, graphic matroid and network congestion games -- and provide computationally efficient payoff-based learning algorithms, which significantly improve upon prior works in terms of the runtime for learning CCE in these settings. △ Less",https://arxiv.org/abs/2509.20919,arxiv_game_page0.csv
Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer,"Abdur Rehman, S M A Sharif, Md Abdur Rahaman, Mohamed Jismy Aashik Rasool, Seongwan Kim, Jaeho Lee","Quantization-aware training (QAT) combined with knowledge distillation (KD) is a promising strategy for compressing Artificial Intelligence (AI) models for deployment on resource-constrained hardware. However, existing QAT-KD methods often struggle to balance task-specific (TS) and distillation losses due to heterogeneous gradient magnitudes, especially under low-bit quantization. We propose Game of Regularizer (GoR), a novel learnable regularization method that adaptively balances TS and KD objectives using only two trainable parameters for dynamic loss weighting. GoR reduces conflict between supervision signals, improves convergence, and boosts the performance of small quantized models (SQMs). Experiments on image classification, object detection (OD), and large language model (LLM) compression show that GoR consistently outperforms state-of-the-art QAT-KD methods. On low-power edge devices, it delivers faster inference while maintaining full-precision accuracy. We also introduce QAT-EKD-GoR, an ensemble distillation framework that uses multiple heterogeneous teacher models. Under optimal conditions, the proposed EKD-GoR can outperform full-precision models, providing a robust solution for real-world deployment. △ Less",https://arxiv.org/abs/2509.20854,arxiv_game_page0.csv
Trustworthy Semantic Communication for Vehicular Networks: Challenges and Solutions,"Yanghe Pan, Yuntao Wang, Shaolong Guo, Chengyu Yin, Ruidong Li, Zhou Su, Yuan Wu","Semantic communication (SemCom) has the potential to significantly reduce communication delay in vehicle-to-everything (V2X) communications within vehicular networks (VNs). However, the deployment of vehicular SemCom networks (VN-SemComNets) faces critical trust challenges in information transmission, semantic encoding, and communication entity reliability. This paper proposes an innovative three-layer trustworthy VN-SemComNet architecture. Specifically, we introduce a semantic camouflage transmission mechanism leveraging defensive adversarial noise for active eavesdropping defense, a robust federated encoder-decoder training framework to mitigate encoder-decoder poisoning attacks, and an audit game -based distributed vehicle trust management mechanism to deter untrustworthy vehicles. A case study validates the effectiveness of the proposed solutions. Lastly, essential future research directions are pointed out to advance this emerging field. △ Less",https://arxiv.org/abs/2509.20830,arxiv_game_page0.csv
Understanding Mode Switching in Human-AI Collaboration: Behavioral Insights and Predictive Modeling,"Avinash Ajit Nargund, Arthur Caetano, Kevin Yang, Rose Yiwei Liu, Philip Tezaur, Kriteen Shrestha, Qisen Pan, Tobias Höllerer, Misha Sra","Human-AI collaboration is typically offered in one of two of user control levels: guidance, where the AI provides suggestions and the human makes the final decision, and delegation, where the AI acts autonomously within user-defined constraints. Systems that integrate both modes, common in robotic surgery or driving assistance, often overlook shifts in user preferences within a task in response to factors like evolving trust, decision complexity, and perceived control. In this work, we investigate how users dynamically switch between higher and lower levels of control during a sequential decision-making task. Using a hand-and-brain chess setup, participants either selected a piece and the AI decided how it moved (brain mode), or the AI selected a piece and the participant decided how it moved (hand mode). We collected over 400 mode-switching decisions from eight participants, along with gaze, emotional state, and subtask difficulty data. Statistical analysis revealed significant differences in gaze patterns and subtask complexity prior to a switch and in the quality of the subsequent move. Based on these results, we engineered behavioral and task-specific features to train a lightweight model that predicted control level switches ($F1 = 0.65$). The model performance suggests that real-time behavioral signals can serve as a complementary input alongside system-driven mode-switching mechanisms currently used. We complement our quantitative results with qualitative factors that influence switching including perceived AI ability, decision complexity, and level of control, identified from post- game interview analysis. The combined behavioral and modeling insights can help inform the design of shared autonomy systems that need dynamic, subtask-level control switches aligned with user intent and evolving task demands. △ Less",https://arxiv.org/abs/2509.20666,arxiv_game_page0.csv
Burninggameson strong path products,"Sally Ambrose, Evan Angelone, Jacob Chen, Daniel Ma, Arturo Ortiz San Miguel, Wraven Watanabe, Stephen Whitcomb, Shanghao Wu","Burning and cooling are diffusion processes on graphs in which burned (or cooled) vertices spread to their neighbors with a new source picked at discrete time steps. In burning, the one tries to burn the graph as fast as possible, while in cooling one wants to delay cooling as long as possible.
  We consider $d$-fold strong products of paths, which generalize king graphs. The propagation of these graphs is radial, and models local spread of contagion in an arbitrary number of dimensions. We reduce the problem to a geometric tiling problem to obtain a bound for the burning number of a strong product of paths by a novel use of an Euler-Maclaurin formula, which is sharp under certain number theoretic conditions.
  Additionally, we consider liminal burning, which is a two-player perfect knowledge game played on graphs related to the effectiveness of controlled spread of contagion throughout a network. We introduce and study the number $k^*$, the smallest $k$ such that $b_{k}(G) = b(G)$. △ Less",https://arxiv.org/abs/2509.20572,arxiv_game_page0.csv
Pattern Formation in Agent-Based and PDE Models for EvolutionaryGameswith Payoff-Driven Motion,"Tianyong Yao, Chenning Xu, Daniel B. Cooney","Spatial structure can play an important role in the evolution of cooperative behavior and the achievement of collective success of a population. In this paper, we explore the role of random and directed motion on spatial pattern formation and the payoff achieved by populations in both stochastic and deterministic models of spatial populations who engage in social interactions following a hawk-dove game . For the case of purely diffusive motion, both a stochastic spatial model and a partial differential equation model show that Turing patterns can emerge when hawks have a greater movement rate than doves, and in both models hawks and doves see an increase in population size and average payoff as hawk mobility increases. For the case of the payoff-driven motion, the stochastic model shows an overall decrease in population size and average payoff, but the PDE model displays more subtle behavior in this setting and will depend on the relative diffusivities of the two strategies. The PDE model also displays a biologically infeasible short-wave instability in the case of payoff-driven motion and equal diffusivities, indicating that we need to be careful about the mathematical properties of PDE models with payoff-driven directed motion and indicating potential use for nonlocal PDE models for spatial patterns in evolutionary games with directed motion. △ Less",https://arxiv.org/abs/2509.20538,arxiv_game_page0.csv
NonlocalGamesand Self-tests in the Presence of Noise,"Honghao Fu, Minglong Qin, Haochen Xu, Penghui Yao","Self-testing is a key characteristic of certain nonlocal games , which allow one to uniquely determine the underlying quantum state and measurement operators used by the players, based solely on their observed input-output correlations [MY04]. Motivated by the limitations of current quantum devices, we study self-testing in the high-noise regime, where the two players are restricted to sharing many copies of a noisy entangled state with an arbitrary constant noise rate. In this setting, many existing self-tests fail to certify any nontrivial structure. We first characterize the maximal winning probabilities of the CHSH game [CHSH69], the Magic Square game [Mer90a], and the 2-out-of-n CHSH game [CRSV18] as functions of the noise rate, under the assumption that players use traceless observables. These results enable the construction of device-independent protocols for estimating the noise rate. Building on this analysis, we show that these three games --together with an additional test enforcing the tracelessness of binary observables--can self-test one, two, and n pairs of anticommuting Pauli operators, respectively. These are the first known self-tests that are robust in the high-noise regime and remain sound even when the players' measurements are noisy. Our proofs rely on Sum-of-Squares (SoS) decompositions and Pauli analysis techniques developed in the contexts of quantum proof systems and quantum learning theory. △ Less",https://arxiv.org/abs/2509.20350,arxiv_game_page0.csv
Adversarial Pursuits in Cislunar Space,"Filippos Fotiadis, Quentin Rommel, Gregory Falco, Ufuk Topcu","Cislunar space is becoming a critical domain for future lunar and interplanetary missions, yet its remoteness, sparse infrastructure, and unstable dynamics create single points of failure. Adversaries in cislunar orbits can exploit these vulnerabilities to pursue and jam co-located communication relays, potentially severing communications between lunar missions and the Earth. We study a pursuit-evasion scenario between two spacecraft in a cislunar orbit, where the evader must avoid a pursuer-jammer while remaining close to its nominal trajectory. We model the evader-pursuer interaction as a zero-sum adversarial differential game cast in the circular restricted three-body problem. This formulation incorporates critical aspects of cislunar orbital dynamics, including autonomous adjustment of the reference orbit phasing to enable aggressive evading maneuvers, and shaping of the evader's cost with the orbit's stable and unstable manifolds. We solve the resulting nonlinear game locally using a continuous-time differential dynamic programming variant, which iteratively applies linear-quadratic approximations to the Hamilton-Jacobi-Isaacs equation. We simulate the evader's behavior against both a worst-case and a linear-quadratic pursuer. Our results pave the way for securing future missions in cislunar space against emerging cyber threats. △ Less",https://arxiv.org/abs/2509.20330,arxiv_game_page0.csv
A Novel Framework for Honey-X Deception in Zero-SumGames,"Brendan Gould, Kyriakos Vamvoudakis","In this paper, we present a novel, game -theoretic model of deception in two-player, zero-sum games . Our framework leverages an information asymmetry: one player (the deceiver) has access to accurate payoff information, while the other (the victim) observes a modified version of these payoffs due to the deception strategy employed. The deceiver's objective is to choose a deception-action pair that optimally exploits the victim's best response to the altered payoffs, subject to a constraint on the deception's magnitude. We characterize the optimal deceptive strategy as the solution to a bi-level optimization problem, and we provide both an exact solution and an efficient method for computing a high-quality feasible point. Finally, we demonstrate the effectiveness of our approach on numerical examples inspired by honeypot deception. △ Less",https://arxiv.org/abs/2509.20329,arxiv_game_page0.csv
Choose Your Battles: Distributed Learning Over Multiple Tug of WarGames,"Siddharth Chandak, Ilai Bistritz, Nicholas Bambos","Consider N players and K games taking place simultaneously. Each of these games is modeled as a Tug-of-War (ToW) game where increasing the action of one player decreases the reward for all other players. Each player participates in only one game at any given time. At each time step, a player decides the game in which they wish to participate in and the action they take in that game . Their reward depends on the actions of all players that are in the same game . This system of K games is termed `Meta Tug-of-War' (Meta-ToW) game . These games can model scenarios such as power control, distributed task allocation, and activation in sensor networks. We propose the Meta Tug-of-Peace algorithm, a distributed algorithm where the action updates are done using a simple stochastic approximation algorithm, and the decision to switch games is made using an infrequent 1-bit communication between the players. We prove that in Meta-ToW games , our algorithm converges to an equilibrium that satisfies a target Quality of Service reward vector for the players. We then demonstrate the efficacy of our algorithm through simulations for the scenarios mentioned above. △ Less",https://arxiv.org/abs/2509.20147,arxiv_game_page0.csv
V-GameGym: VisualGameGeneration for Code Large Language Models,"Wei Zhang, Jack Yang, Renshuai Tao, Lingzheng Chai, Shawn Guo, Jiajun Wu, Xiaoming Chen, Ganqu Cui, Ning Ding, Xander Xu, Hu Wei, Bowen Zhou","Code large language models have demonstrated remarkable capabilities in programming tasks, yet current benchmarks primarily focus on single modality rather than visual game development. Most existing code-related benchmarks evaluate syntax correctness and execution accuracy, overlooking critical game -specific metrics such as playability, visual aesthetics, and user engagement that are essential for real-world deployment. To address the gap between current LLM capabilities in algorithmic problem-solving and competitive programming versus the comprehensive requirements of practical game development, we present V-GameGym, a comprehensive benchmark comprising 2,219 high-quality samples across 100 thematic clusters derived from real-world repositories, adopting a novel clustering-based curation methodology to ensure both diversity and structural completeness. Further, we introduce a multimodal evaluation framework with an automated LLM-driven pipeline for visual code synthesis using complete UI sandbox environments. Our extensive analysis reveals that V-GameGym effectively bridges the gap between code generation accuracy and practical game development workflows, providing quantifiable quality metrics for visual programming and interactive element generation. △ Less",https://arxiv.org/abs/2509.20136,arxiv_game_page0.csv
Ensuring Reliable Participation in Subjective Video Quality Tests Across Platforms,"Babak Naderi, Ross Cutler","Subjective video quality assessment (VQA) is the gold standard for measuring end-user experience across communication, streaming, and UGC pipelines. Beyond high-validity lab studies, crowdsourcing offers accurate, reliable, faster, and cheaper evaluation-but suffers from unreliable submissions by workers who ignore instructions or game rewards. Recent tests reveal sophisticated exploits of video metadata and rising use of remote-desktop (RD) connections, both of which bias results. We propose objective and subjective detectors for RD users and compare two mainstream crowdsourcing platforms on their susceptibility and mitigation under realistic test conditions and task designs. △ Less",https://arxiv.org/abs/2509.20001,arxiv_game_page0.csv
On the Fragility of Contribution Score Computation in Federated Learning,"Balazs Pejo, Marcell Frank, Krisztian Varga, Peter Veliczky","This paper investigates the fragility of contribution evaluation in federated learning, a critical mechanism for ensuring fairness and incentivizing participation. We argue that contribution scores are susceptible to significant distortions from two fundamental perspectives: architectural sensitivity and intentional manipulation. First, we explore how different model aggregation methods impact these scores. While most research assumes a basic averaging approach, we demonstrate that advanced techniques, including those designed to handle unreliable or diverse clients, can unintentionally yet significantly alter the final scores. Second, we explore vulnerabilities posed by poisoning attacks, where malicious participants strategically manipulate their model updates to inflate their own contribution scores or reduce the importance of other participants. Through extensive experiments across diverse datasets and model architectures, implemented within the Flower framework, we rigorously show that both the choice of aggregation method and the presence of attackers are potent vectors for distorting contribution scores, highlighting a critical need for more robust evaluation schemes. △ Less",https://arxiv.org/abs/2509.19921,arxiv_game_page0.csv
SPARQ: An Optimization Framework for the Distribution of AI-Intensive Applications under Non-Linear Delay Constraints,"Pietro Spadaccino, Paolo Di Lorenzo, Sergio Barbarossa, Antonia M. Tulino, Jaime Llorca","Next-generation real-time compute-intensive applications, such as extended reality, multi-user gaming , and autonomous transportation, are increasingly composed of heterogeneous AI-intensive functions with diverse resource requirements and stringent latency constraints. While recent advances have enabled very efficient algorithms for joint service placement, routing, and resource allocation for increasingly complex applications, current models fail to capture the non-linear relationship between delay and resource usage that becomes especially relevant in AI-intensive workloads. In this paper, we extend the cloud network flow optimization framework to support queuing-delay-aware orchestration of distributed AI applications over edge-cloud infrastructures. We introduce two execution models, Guaranteed-Resource (GR) and Shared-Resource (SR), that more accurately capture how computation and communication delays emerge from system-level resource constraints. These models incorporate M/M/1 and M/G/1 queue dynamics to represent dedicated and shared resource usage, respectively. The resulting optimization problem is non-convex due to the non-linear delay terms. To overcome this, we develop SPARQ, an iterative approximation algorithm that decomposes the problem into two convex sub-problems, enabling joint optimization of service placement, routing, and resource allocation under nonlinear delay constraints. Simulation results demonstrate that the SPARQ not only offers a more faithful representation of system delays, but also substantially improves resource efficiency and the overall cost-delay tradeoff compared to existing state-of-the-art methods. △ Less",https://arxiv.org/abs/2509.19913,arxiv_game_page0.csv
Pure Exploration via Frank-Wolfe Self-Play,"Xinyu Liu, Chao Qin, Wei You","We study pure exploration in structured stochastic multi-armed bandits, aiming to efficiently identify the correct hypothesis from a finite set of alternatives. For a broad class of tasks, asymptotic analyses reduce to a maximin optimization that admits a two-player zero-sum game interpretation between an experimenter and a skeptic: the experimenter allocates measurements to rule out alternatives while the skeptic proposes alternatives. We reformulate the game by allowing the skeptic to adopt a mixed strategy, yielding a concave-convex saddle-point problem. This viewpoint leads to Frank-Wolfe Self-Play (FWSP): a projection-free, regularization-free, tuning-free method whose one-hot updates on both sides match the bandit sampling paradigm. However, structural constraints introduce sharp pathologies that complicate algorithm design and analysis: our linear-bandit case study exhibits nonunique optima, optimal designs with zero mass on the best arm, bilinear objectives, and nonsmoothness at the boundary. We address these challenges via a differential-inclusion argument, proving convergence of the game value for best-arm identification in linear bandits. Our analysis proceeds through a continuous-time limit: a differential inclusion with a Lyapunov function that decays exponentially, implying a vanishing duality gap and convergence to the optimal value. Although Lyapunov analysis requires differentiability of the objective, which is not guaranteed on the boundary, we show that along continuous trajectories the algorithm steers away from pathological nonsmooth points and achieves uniform global convergence to the optimal game value. We then embed the discrete-time updates into a perturbed flow and show that the discrete game value also converges. Building on FWSP, we further propose a learning algorithm based on posterior sampling. Numerical experiments demonstrate a vanishing duality gap. △ Less",https://arxiv.org/abs/2509.19901,arxiv_game_page0.csv
Deterministic Frequency--Domain Inference of Network Topology and Hidden Components via Structure--Behavior Scaling,"Xiaoxiao Liang, Tianlong Fan, Linyuan Lü","Hidden interactions and components in complex systems-ranging from covert actors in terrorist networks to unobserved brain regions and molecular regulators-often manifest only through indirect behavioral signals. Inferring the underlying network structure from such partial observations remains a fundamental challenge, particularly under nonlinear dynamics. We uncover a robust linear relationship between the spectral strength of a node's behavioral time series under evolutionary game dynamics and its structural degree, $S \propto k$, a structural-behavioral scaling that holds across network types and scales, revealing a universal correspondence between local connectivity and dynamic energy. Leveraging this insight, we develop a deterministic, frequency-domain inference framework based on the discrete Fourier transform (DFT) that reconstructs network topology directly from payoff sequences-without prior knowledge of the network or internal node strategies-by selectively perturbing node dynamics. The framework simultaneously localizes individual hidden nodes or identifies all edges connected to multiple hidden nodes, and estimates tight bounds on the number of hidden nodes. Extensive experiments on synthetic and real-world networks demonstrate that our method consistently outperforms state-of-the-art baselines in both topology reconstruction and hidden component detection. Moreover, it scales efficiently to large networks, offering robustness to stochastic fluctuations and overcoming the size limitations of existing techniques. Our work establishes a principled connection between local dynamic observables and global structural inference, enabling accurate topology recovery in complex systems with hidden elements. △ Less",https://arxiv.org/abs/2509.19857,arxiv_game_page0.csv
GamesAre Not Equal: Classifying CloudGamingContexts for Effective User Experience Measurement,"Yifan Wang, Minzhao Lyu, Vijay Sivaraman","To tap into the growing market of cloud gaming , whereby game graphics is rendered in the cloud and streamed back to the user as a video feed, network operators are creating monetizable assurance services that dynamically provision network resources. However, without accurately measuring cloud gaming user experience, they cannot assess the effectiveness of their provisioning methods. Basic measures such as bandwidth and frame rate by themselves do not suffice, and can only be interpreted in the context of the game played and the player activity within the game . This paper equips the network operator with a method to obtain a real-time measure of cloud gaming experience by analyzing network traffic, including contextual factors such as the game title and player activity stage. Our method is able to classify the game title within the first five seconds of game launch, and continuously assess the player activity stage as being active, passive, or idle. We deploy it in an ISP hosting NVIDIA cloud gaming servers for the region. We provide insights from hundreds of thousands of cloud game streaming sessions over a three-month period into the dependence of bandwidth consumption and experience level on the gameplay contexts. △ Less",https://arxiv.org/abs/2509.19669,arxiv_game_page0.csv
Formalization of Harder-Narasimhan theory,Yijun Yuan,"The Harder-Narasimhan theory provides a canonical filtration of a vector bundle on a projective curve whose successive quotients are semistable with strictly decreasing slopes. In this article, we present the formalization of Harder-Narasimhan theory in the proof assistant Lean 4 with Mathlib. This formalization is based on a recent approach of Harder-Narasimhan theory by Chen and Jeannin, which reinterprets the theory in order-theoretic terms and avoids the classical dependence on algebraic geometry. As an application, we formalize the uniqueness of coprimary filtration of a finitely generated module over a noetherian ring, and the existence of the Jordan-Hölder filtration of a semistable Harder-Narasimhan game .
  Code available at: https://github.com/YijunYuan/HarderNarasimhan △ Less",https://arxiv.org/abs/2509.19632,arxiv_game_page0.csv
GuessingGame: Measuring the Informativeness of Open-Ended Questions in Large Language Models,"Dylan Hutson, Daniel Vennemeyer, Aneesh Deshmukh, Justin Zhan, Tianyu Jiang","We introduce GuessingGame, a protocol for evaluating large language models (LLMs) as strategic question-askers in open-ended, open-domain settings. A Guesser LLM identifies a hidden object by posing free-form questions to an Oracle without predefined choices or candidate lists. To measure question quality, we propose two information gain (IG) metrics: a Bayesian method that tracks belief updates over semantic concepts using LLM-scored relevance, and an entropy-based method that filters candidates via ConceptNet. Both metrics are model-agnostic and support post hoc analysis. Across 858 games with multiple models and prompting strategies, higher IG strongly predicts efficiency: a one-standard-deviation IG increase reduces expected game length by 43\%. Prompting constraints guided by IG, such as enforcing question diversity, enable weaker models to significantly improve performance. These results show that question-asking in LLMs is both measurable and improvable, and crucial for interactive reasoning. △ Less",https://arxiv.org/abs/2509.19593,arxiv_game_page0.csv
Bounding the Eviction Number of a Graph in Terms of its Independence Number,"Gary MacGillivray, Christina Mynhardt, Virgelot Virgile","An eternal dominating family of graph $G$ in the eviction game is a collection $\mathcal{D}_{k}=\{D_{1},...,D_{l}\}$ of dominating sets of $G$ such that (a) $|D_{i}|=|D_{j}|$ for all $i,j\in\{1,2,...,l\}$, and (b) for any $i\in \{1,2,...,l\}$ and any $v\in D_{i}$, either all neighbours of $v$ belong to $D_{i}$, or there are a neighbour $w$ of $v$ not in $D_{i}$ and an integer $j\in\{1,2,...,l\}\setminus\{i\}$ such that $D_{i}\cup\{w\}\setminus \{v\}=D_{j}$. The eviction number of $G$, denoted by $e^{\infty}(G)$, is the smallest cardinality of the sets in such an eternal dominating family.
  We compare $e^{\infty}$ to the independence number $α$. We show that the ratio $α/e^{\infty}$ is unbounded and construct an infinite class of connected graphs for which $e^{\infty}/α\approx 4/3$. As our main result, we use Ramsey numbers to show that for any integer $k\geq1$, there exists a function $f(k)$ such that any graph with independence number $k$ has eviction number at most $f(k)$. △ Less",https://arxiv.org/abs/2509.19535,arxiv_game_page0.csv
A Longitudinal Randomized Control Study of Companion Chatbot Use: Anthropomorphism and Its Mediating Role on Social Impacts,"Rose E. Guingrich, Michael S. A. Graziano","Relationships with social artificial intelligence (AI) agents are on the rise. People report forming friendships, mentorships, and romantic partnerships with chatbots such as Replika, a type of social AI agent that is designed specifically for companionship. Concerns that companion chatbot relationships may harm or replace human ones have been raised, but whether and how these social consequences occur remains unclear. Prior research suggests that people's states of social need and their anthropomorphism of the AI agent may play a role in how human-AI interaction impacts human-human interaction. In this longitudinal study (N = 183), participants were randomly assigned to converse with a companion chatbot over text or to play text-based word games for 10 minutes a day for 21 consecutive days. During these 21 days, participants also completed four surveys and two audio-recorded interviews. We found that people's social health and relationships were not significantly impacted by interacting with a companion chatbot across 21 days compared to the control group. However, people who had a higher desire to socially connect anthropomorphized the chatbot more. Those who anthropomorphized the chatbot more indicated that the human-chatbot interaction had greater impacts on their social interactions and relationships with family and friends. A mediation analysis suggested that the impact of human-AI interaction on human-human social outcomes was mediated by the extent to which people anthropomorphized the AI agent, which itself was related to the desire to socially connect. △ Less",https://arxiv.org/abs/2509.19515,arxiv_game_page0.csv
A User-to-User Resource ResellingGamein Open RAN with Buffer Rollover,"Ruide Cao, Marie Siew, David Yau","The development of the Open RAN (O-RAN) framework helps enable network slicing through its virtualization, interoperability, and flexibility. To improve spectral efficiency and better meet users' dynamic and heterogeneous service demands, O-RAN's flexibility further presents an opportunity for resource reselling of unused physical resource blocks (PRBs) across users. In this work, we propose a novel game -based user-to-user PRB reselling model in the O-RAN setting, which models the carryover of unmet demand across time slots, along with how users' internal buffer states relate to any PRBs purchased. We formulate the interplay between the users as a strategic game , with each participant aiming to maximize their own payoffs, and we prove the existence and uniqueness of the Nash equilibrium (NE) in the game . We furthermore propose an iterative bidding mechanism that converges to this NE. Extensive simulations show that our best approach reduces data loss by 30.5% and spectrum resource wastage by 50.7% while significantly improving social welfare, compared to its absence. △ Less",https://arxiv.org/abs/2509.19392,arxiv_game_page0.csv
Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks,"Ying Ju, Mingdong Li, Haoyu Wang, Lei Liu, Youyang Qu, Mianxiong Dong, Victor C. M. Leung, Chau Yuen","With the emergence of fluid antenna (FA) in wireless communications, the capability to dynamically adjust port positions offers substantial benefits in spatial diversity and spectrum efficiency, which are particularly valuable for mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC offloading framework to minimize system delay. This framework faces two severe challenges, which are the complexity of channel estimation due to dynamic port configuration and the inherent non-convexity of the joint optimization problem. Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed Sensing (IBM-CCS), which advances FA channel estimation by integrating information relevance into the sensing process and capturing key features of FA channels effectively. Secondly, to address the non-convex and high-dimensional optimization problem in FA-assisted MEC systems, which includes FA port selection, beamforming, power control, and resource allocation, we propose a game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA) based offloading scheme, where the hierarchical structure effectively decouples and coordinates the optimization tasks between the user side and the base station side. Crucially, the game theory effectively reduces the dimensionality of power control variables, allowing deep reinforcement learning (DRL) agents to achieve improved optimization efficiency. Numerical results confirm that the proposed scheme significantly reduces system delay and enhances offloading performance, outperforming benchmarks. Additionally, the IBM-CCS channel estimation demonstrates superior accuracy and robustness under varying port densities, contributing to efficient communication under imperfect CSI. △ Less",https://arxiv.org/abs/2509.19340,arxiv_game_page0.csv
Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation,"Sherwin Bahmani, Tianchang Shen, Jiawei Ren, Jiahui Huang, Yifeng Jiang, Haithem Turki, Andrea Tagliasacchi, David B. Lindell, Zan Gojcic, Sanja Fidler, Huan Ling, Jun Gao, Xuanchi Ren","The ability to generate virtual environments is crucial for applications ranging from gaming to physical AI domains such as robotics, autonomous driving, and industrial AI. Current learning-based 3D reconstruction methods rely on the availability of captured real-world multi-view data, which is not always readily available. Recent advancements in video diffusion models have shown remarkable imagination capabilities, yet their 2D nature limits the applications to simulation where a robot needs to navigate and interact with the environment. In this paper, we propose a self-distillation framework that aims to distill the implicit 3D knowledge in the video diffusion models into an explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for multi-view training data. Specifically, we augment the typical RGB decoder with a 3DGS decoder, which is supervised by the output of the RGB decoder. In this approach, the 3DGS decoder can be purely trained with synthetic data generated by video diffusion models. At inference time, our model can synthesize 3D scenes from either a text prompt or a single image for real-time rendering. Our framework further extends to dynamic 3D scene generation from a monocular input video. Experimental results show that our framework achieves state-of-the-art performance in static and dynamic 3D scene generation. △ Less",https://arxiv.org/abs/2509.19296,arxiv_game_page0.csv
Approximating Electoral Control Problems,"Huy Vu Bui, Michael C. Chavrimootoo, Trung Kien Le, Son M. Nguyen","Much research in electoral control -- one of the most studied form of electoral attacks, in which an entity running an election alters the structure of that election to yield a preferred outcome -- has focused on giving decision complexity results, e.g., membership in P, NP-completeness, or fixed-parameter tractability. Approximation algorithms on the other hand have received little attention in electoral control, despite their prevalence in the study of other forms of electoral attacks, such as manipulation and bribery. Early work established some preliminary results with respect to popular voting rules such as plurality, approval, and Condorcet. In this paper, we establish for each of the ``standard'' control problems under plurality, approval, and Condorcet, whether they are approximable, and we prove our results in both the weighted and unweighted voter settings. For each problem we study under either approval or Condorcet, we show that any approximation algorithm we give is optimal, unless P=NP. Our approximation algorithms leverage the fact that Covering Integer Programs (CIPs) can be approximated within a factor of $O(\log n)$. Under plurality, we give an $O(m)$-approximation algorithm, and give as lower bound $Ω(m^{1/4})$, by using a known lower bound on the Minimum $k$-Union (M$k$U) problem. To our knowledge, this is the first application of M$k$U in computational social choice. We also generalize our $O(m)$-approximation algorithm to work with respect to an infinite family of voting rules using an axiomatic approach. Our work closes a long list of open problems established 18 years ago. △ Less",https://arxiv.org/abs/2509.19279,arxiv_game_page0.csv
"Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action","Victoire Hervé, Henrik Warpefelt, Christoph Salge","Algorithmic evaluation of procedurally generated content struggles to find metrics that align with human experience, particularly for composite artefacts. Automatic decomposition as a possible solution requires concepts that meet a range of properties. To this end, drawing on Games Studies and Game AI research, we introduce the nested concepts of \textit{Landmarks}, \textit{Monuments}, and \textit{Beacons}. These concepts are based on the artefact's perceivability, evocativeness, and Call to Action, all from a player-centric perspective. These terms are generic to games and usable across genres. We argue that these entities can be found and evaluated with techniques currently used in both research and industry, opening a path towards a fully automated decomposition of PCG, and evaluation of the salient sub-components. Although the work presented here emphasises mixed-initiative PCG and compositional PCG, we believe it applies beyond those domains. With this approach, we intend to create a connection between humanities and technical game research and allow for better computational PCG evaluation △ Less",https://arxiv.org/abs/2509.19030,arxiv_game_page0.csv
Improved Trial and Error Learning for RandomGames,"Jérôme Taupin, Xavier Leturc, Christophe J. Le Martret","When a game involves many agents or when communication between agents is not possible, it is useful to resort to distributed learning where each agent acts in complete autonomy without any information on the other agents' situations. Perturbation-based algorithms have already been used for such tasks. We propose some improvements based on practical observations to improve the performance of these algorithms. We show that the introduction of these changes preserves their theoretical convergence properties towards states that maximize the average reward and improve them in the case where optimal states exist. Moreover, we show that these algorithms can be made robust to the addition of randomness to the rewards, achieving similar convergence guarantees. Finally, we discuss the possibility for the perturbation factor of the algorithm to decrease during the learning process, akin to simulated annealing processes. △ Less",https://arxiv.org/abs/2509.18955,arxiv_game_page0.csv
Entropy Regularization in Mean-FieldGamesof Optimal Stopping,"Jodi Dianetti, Roxana Dumitrescu, Giorgio Ferrari, Renyuan Xu","We study mean-field games of optimal stopping (OS-MFGs) and introduce an entropy-regularized framework to enable learning-based solution methods. By utilizing randomized stopping times, we reformulate the OS-MFG as a mean-field game of singular stochastic controls (SC-MFG) with entropy regularization. We establish the existence of equilibria and prove their stability as the entropy parameter vanishes. Fictitious play algorithms tailored for the regularized setting are introduced, and we show their convergence under both Lasry-Lions monotonicity and supermodular assumptions on the reward functional. Our work lays the theoretical foundation for model-free learning approaches to OS-MFGs. △ Less",https://arxiv.org/abs/2509.18821,arxiv_game_page0.csv
An Entropy Regularized BSDE Approach to Bermudan Options andGames,"Noufel Frikha, Libo Li, Daniel Chee","In this paper, we investigate optimal stopping problems in a continuous-time framework where only a discrete set of stopping dates is admissible, corresponding to the Bermudan option, within the so-called exploratory formulation. We introduce an associated control problem for the value function, represented as a non-càdlàg reflected backward stochastic differential equation (RBSDE) with an entropy regulariser that promotes exploration, and we establish existence and uniqueness results for this entropy-regularised RBSDE. We then compare the entropy-regularised RBSDE with the theoretical value of a Bermudan option and propose a reinforcement learning algorithm based on a policy improvement scheme, for which we prove both monotone improvement and convergence. This methodology is further extended to Bermudan game options, where we obtain analogous results. Finally, drawing on the preceding analysis, we present two numerical approximation schemes - a BSDE solver based on a temporal-difference scheme and neural networks and the policy improvement algorithm - to illustrate the feasibility and effectiveness of our approach. △ Less",https://arxiv.org/abs/2509.18747,arxiv_game_page0.csv
Content and Quality Analysis of mHealth Apps for Feeding Children with Autism Spectrum Disorder,"Christopher Cofie Kuzagbe, Fabrice Mukarage, Skye Nandi Adams, N'guessan Yves-Roland Douha, Edith Talina Luhanga","Background: Approximately 1 in 100 children worldwide are diagnosed with Autism Spectrum Disorder (ASD), and 46% to 89% experience significant feeding difficulties. Mobile health applications (mHealth apps) have emerged as a potential tool for scalable support. However, their quality and relevance in managing ASD-related feeding challenges remain unclear.
  Objective: To identify and evaluate the quality of mHealth apps available in the Africa region addressing feeding difficulties in children with ASD.
  Methods: A systematic search was conducted on the Apple App Store and Google Play Store between September and October 2024. Applications were included if they were free, in English, updated within the past year, explicitly focused on feeding in children with autism, available in the Africa region, and had more than 100 downloads. Eligible apps were assessed using the Behavior Change Wheel (BCW) framework and rated with the Mobile App Rating Scale (MARS) across four domains: engagement, functionality, aesthetics, and information quality.
  Results: Of the 326 applications identified, only two iOS apps met all inclusion criteria. EduKitchen-Toddlers Food Games featured child-centered interactive games and sensory-friendly visuals, while Autism Food Coach 2 provided structured caregiver tools, visual meal plans, and progress tracking. Both apps aligned with multiple BCW intervention functions, including education, training, and enablement. MARS scores of 3.7 and 3.9 indicated acceptable to good usability and content quality.
  Conclusion: There is a critical shortage of high-quality, evidence-based mHealth applications addressing feeding difficulties in children with ASD. Future development should prioritize clinical validation and the integration of comprehensive, caregiver-centered support features to address this gap. △ Less",https://arxiv.org/abs/2509.18716,arxiv_game_page0.csv
AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping,"Zedong Zhang, Ying Tai, Jianjun Qian, Jian Yang, Jun Li","Fusing cross-category objects to a single coherent object has gained increasing attention in text-to-image (T2I) generation due to its broad applications in virtual reality, digital media, film, and gaming . However, existing methods often produce biased, visually chaotic, or semantically inconsistent results due to overlapping artifacts and poor integration. Moreover, progress in this field has been limited by the absence of a comprehensive benchmark dataset. To address these problems, we propose \textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective approach comprising two key components: (1) Group-wise Embedding Swapping, which fuses semantic attributes from different concepts through feature manipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism guided by a balance evaluation score to ensure coherent synthesis. Additionally, we introduce \textbf{Cross-category Object Fusion (COF)}, a large-scale, hierarchically structured dataset built upon ImageNet-1K and WordNet. COF includes 95 superclasses, each with 10 subclasses, enabling 451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap outperforms state-of-the-art compositional T2I methods, including GPT-Image-1 using simple and complex prompts. △ Less",https://arxiv.org/abs/2509.18699,arxiv_game_page0.csv
Proximately Envy-Free and Efficient Allocation of Mixed Manna,"Siddharth Barman, Paritosh Verma","The existence of fair and efficient allocations of indivisible items is a central problem in fair division. For indivisible goods, the existence of Pareto efficient (PO) and envy free up to one item (EF1) allocations was established by Caragiannis et al. In a recent breakthrough, Mahara established the existence of PO and EF1 allocations for indivisible chores.
  However, the existence of PO and EF1 allocations of mixed manna remains an intriguing open problem. In this paper, we make significant progress in this direction. We establish the existence of allocations that are PO and introspective envy free up to one item (IEF1) for mixed manna. In an IEF1 allocation, each agent can eliminate its envy towards all the other agents by either adding an item or removing an item from its own bundle. The notion of IEF1 coincides with EF1 for indivisible chores, and hence, our existence result generalizes the aforementioned result of Mahara. △ Less",https://arxiv.org/abs/2509.18673,arxiv_game_page0.csv
"Group Formation throughGameTheory and Agent-Based Modeling: Spatial Cohesion, Heterogeneity, and Resource Pooling","Chenlan Wang, Jimin Han, Diana Jue-Rajasingh","This paper develops a game -theoretic model and an agent-based model to study group formation driven by resource pooling, spatial cohesion, and heterogeneity. We focus on cross-sector partnerships (CSPs) involving public, private, and nonprofit organizations, each contributing distinct resources. Group formation occurs as agents strategically optimize their choices in response to others within a competitive setting. We prove the existence of stable group equilibria and simulate formation dynamics under varying spatial and resource conditions. The results show that limited individual resources lead to groups that form mainly among nearby actors, while abundant resources allow groups to move across larger distances. Increased resource heterogeneity and spatial proximity promote the formation of larger and more diverse groups. These findings reveal key trade-offs shaping group size and composition, guiding strategies for effective cross-sector collaborations and multi-agent systems. △ Less",https://arxiv.org/abs/2509.18551,arxiv_game_page0.csv
Cops and robbers on chess graphs,"Sally Ambrose, Evan Angelone, Jacob Chen, Daniel Ma, Arturo Ortiz San Miguel, Wraven Watanabe, Stephen Whitcomb, Shanghao Wu","Cops and robbers is a pursuit-evasion game played on graphs. We completely classify the cop numbers for $n \times n$ knight graphs and queen graphs. This completes the classification of the cop numbers for all $n \times n$ classical chess graphs. As a corollary, we resolve an open problem about the monotonicity of $c$($\mathcal{Q}_n$). Moreover, we introduce \emph{royal graphs}, a generalization of chess graphs for arbitrary piece movements, which models real-life movement constraints. We give results on the cop numbers for these families. △ Less",https://arxiv.org/abs/2509.18516,arxiv_game_page0.csv
SC2Tools: StarCraft II Toolset and Dataset API,"Andrzej Białecki, Piotr Białecki, Piotr Sowiński, Mateusz Budziak, Jan Gajewski","Computer games , as fully controlled simulated environments, have been utilized in significant scientific studies demonstrating the application of Reinforcement Learning (RL). Gaming and esports are key areas influenced by the application of Artificial Intelligence (AI) and Machine Learning (ML) solutions at scale. Tooling simplifies scientific workloads and is essential for developing the gaming and esports research area.
  In this work, we present ``SC2Tools'', a toolset containing multiple submodules responsible for working with, and producing larger datasets. We provide a modular structure of the implemented tooling, leaving room for future extensions where needed. Additionally, some of the tools are not StarCraft~2 exclusive and can be used with other types of data for dataset creation.
  The tools we present were leveraged in creating one of the largest StarCraft~2 tournament datasets to date with a separate PyTorch and PyTorch Lightning application programming interface (API) for easy access to the data.
  We conclude that alleviating the burden of data collection, preprocessing, and custom code development is essential for less technically proficient researchers to engage in the growing gaming and esports research area. Finally, our solution provides some foundational work toward normalizing experiment workflow in StarCraft~2 △ Less",https://arxiv.org/abs/2509.18454,arxiv_game_page0.csv
Explicit Path CGR: Maintaining Sequence Fidelity in Geometric Representations,Sarwan Ali,"We present a novel information-preserving Chaos Game Representation (CGR) method, also called Reverse-CGR (R-CGR), for biological sequence analysis that addresses the fundamental limitation of traditional CGR approaches - the loss of sequence information during geometric mapping. Our method introduces complete sequence recovery through explicit path encoding combined with rational arithmetic precision control, enabling perfect sequence reconstruction from stored geometric traces. Unlike purely geometric approaches, our reversibility is achieved through comprehensive path storage that maintains both positional and character information at each step. We demonstrate the effectiveness of R-CGR on biological sequence classification tasks, achieving competitive performance compared to traditional sequence-based methods while providing interpretable geometric visualizations. The approach generates feature-rich images suitable for deep learning while maintaining complete sequence information through explicit encoding, opening new avenues for interpretable bioinformatics analysis where both accuracy and sequence recovery are essential. △ Less",https://arxiv.org/abs/2509.18408,arxiv_game_page0.csv
Policy Gradient with Self-Attention for Model-Free Distributed Nonlinear Multi-AgentGames,"Eduardo Sebastián, Maitrayee Keskar, Eeman Iqbal, Eduardo Montijano, Carlos Sagüés, Nikolay Atanasov","Multi-agent games in dynamic nonlinear settings are challenging due to the time-varying interactions among the agents and the non-stationarity of the (potential) Nash equilibria. In this paper we consider model-free games , where agent transitions and costs are observed without knowledge of the transition and cost functions that generate them. We propose a policy gradient approach to learn distributed policies that follow the communication structure in multi-team games , with multiple agents per team. Our formulation is inspired by the structure of distributed policies in linear quadratic games , which take the form of time-varying linear feedback gains. In the nonlinear case, we model the policies as nonlinear feedback gains, parameterized by self-attention layers to account for the time-varying multi-agent communication topology. We demonstrate that our distributed policy gradient approach achieves strong performance in several settings, including distributed linear and nonlinear regulation, and simulated and real multi-robot pursuit-and-evasion games . △ Less",https://arxiv.org/abs/2509.18371,arxiv_game_page0.csv
Fair Decisions through Plurality: Results from a Crowdfunding Platform,"Joel Miller, E. Glen Weyl, Chris Kanich","We discuss an algorithmic intervention aimed at increasing equity and economic efficiency at a crowdfunding platform that gives cash subsidies to grantees. Through a blend of technical and qualitative methods, we show that the previous algorithm used by the platform -- Quadratic Funding (QF) -- suffered problems because its design was rooted in a model of individuals as isolated and selfish. We present an alternative algorithm -- Connection-Oriented Quadratic Funding (CO-QF) -- rooted in a theory of plurality and prosocial utilities, and show that it qualitatively and quantitatively performs better than QF. CO-QF has achieved an 89% adoption rate at the platform and has distributed over $4 Million to date. In simulations we show that it provides better social welfare than QF. While our design for CO-QF was responsive to the needs of a specific community, we also extrapolate out of this context to show that CO-QF is a potentially helpful tool for general-purpose public decision making. △ Less",https://arxiv.org/abs/2509.18343,arxiv_game_page0.csv
On Sybil-proofness in Restaking Networks,"Tarun Chitra, Paolo Penna, Manvir Schneider","Restaking protocols expand validator responsibilities beyond consensus, but their security depends on resistance to Sybil attacks. We introduce a formal framework for Sybil-proofness in restaking networks, distinguishing between two types of attacks, one in which other Sybil identities are kept out of an attack and one where multiple Sybil identities attack. We analyze marginal and multiplicative slashing mechanisms and characterize the conditions under which each deters Sybil strategies. We then prove an impossibility theorem: no slashing mechanism can simultaneously prevent both attack types. Finally, we study the impact of network structure through random graph models: while Erdös-Rényi networks remain Sybil-proof, even minimal heterogeneity in a two-block stochastic block model makes Sybil attacks profitable. These results reveal fundamental limits of mechanism design for restaking and highlight the critical role of network topology. △ Less",https://arxiv.org/abs/2509.18338,arxiv_game_page0.csv
A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning,"Thanh Linh Nguyen, Quoc-Viet Pham","Cross-silo federated learning (CFL) enables organizations (e.g., hospitals or banks) to collaboratively train artificial intelligence (AI) models while preserving data privacy by keeping data local. While prior work has primarily addressed statistical heterogeneity across organizations, a critical challenge arises from economic competition, where organizations may act as market rivals, making them hesitant to participate in joint training due to potential utility loss (i.e., reduced net benefit). Furthermore, the combined effects of statistical heterogeneity and inter-organizational competition on organizational behavior and system-wide social welfare remain underexplored. In this paper, we propose CoCoGen, a coopetitive-compatible data generation framework, leveraging generative AI (GenAI) and potential game theory to model, analyze, and optimize collaborative learning under heterogeneous and competitive settings. Specifically, CoCoGen characterizes competition and statistical heterogeneity through learning performance and utility-based formulations and models each training round as a weighted potential game . We then derive GenAI-based data generation strategies that maximize social welfare. Experimental results on the Fashion-MNIST dataset reveal how varying heterogeneity and competition levels affect organizational behavior and demonstrate that CoCoGen consistently outperforms baseline methods. △ Less",https://arxiv.org/abs/2509.18120,arxiv_game_page0.csv
Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning,"Valentin Lacombe, Valentin Quesnel, Damien Sileo","We introduce Reasoning Core, a new scalable environment for Reinforcement Learning with Verifiable Rewards (RLVR), designed to advance foundational symbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks that focus on games or isolated puzzles, Reasoning Core procedurally generates problems across core formal domains, including PDDL planning, first-order logic, context-free grammar parsing, causal reasoning, and system equation solving. The environment is built on key design principles of high-generality problem distributions, verification via external tools, and continuous difficulty control, which together provide a virtually infinite supply of novel training instances. Initial zero-shot evaluations with frontier LLMs confirm the difficulty of Reasoning Core's tasks, positioning it as a promising resource to improve the reasoning capabilities of future models. △ Less",https://arxiv.org/abs/2509.18083,arxiv_game_page0.csv
Quantitative comparison of quantum pseudo-telepathygamesand Bell inequalities,"Gábor Homa, András Bodor, József Zsolt Bernád","Quantum pseudo-telepathy games , such as the Mermin-Peres magic square and the doily game , theoretically allow players to win with unit probability when using entangled quantum strategies. We quantitatively characterize the quantum advantage in these games and compare it with violations of two Bell inequalities: the Clauser-Horne-Shimony-Holt and the Collins-Gisin inequalities. The analysis is restricted to two families of two-qubit states: modified Werner states and Bell-diagonal states. For each case, we identify and quantify the regions of quantum state space that exhibit either a quantum advantage or a Bell inequality violation, relative to the set of all entangled states. Within these families, the doily game captures a larger fraction of entangled states than the Mermin-Peres magic square game , though both are significantly more limited than the regions associated with Bell inequality violations. Although both approaches are fundamentally linked to quantum contextuality, our analysis of the examined two-qubit state families indicates that Bell inequalities are more effective at revealing entanglement, even if pseudo-telepathy games offer a more intuitive and conceptually appealing perspective. △ Less",https://arxiv.org/abs/2509.18033,arxiv_game_page0.csv
Strategies for Cantorgamesand Operator systems,"Georgios Baziotis, Alexandros Chatzinikolaou, Ivan G. Todorov, Lyudmila Turowska","We study no-signalling correlations over Cantor spaces, placing the product of infinitely many copies of a finite non-local game in a unified general setup. We define the subclasses of local, quantum spatial, approximately quantum and quantum commuting Cantor correlations and describe them in terms of states on tensor products of inductive limits of operator systems. We provide a correspondence between no-signalling (resp. approximately quantum, quantum commuting) Cantor correlations and sequences of correlations of the same type over the projections onto increasing number of finitely many coordinates. We introduce Cantor games , and associate canonically such a game to a sequence of finite input/output games , showing that the numerical sequence of the values of the games in the sequence converges to the corresponding value of the compound Cantor game . △ Less",https://arxiv.org/abs/2509.18028,arxiv_game_page0.csv
Kuramoto Mean FieldGamewith Intrinsic Frequencies,"Rene Carmona, Quentin Cormier, Mete Soner","This paper studies a mean field game formulation of the classical Kuramoto model for synchronization. Our model captures the diversity within the population by considering random intrinsic frequencies, which allows us to study the impact of this heterogeneity on synchronization patterns and stability. Our findings contribute insights into the interplay between intrinsic frequency diversity and synchronization dynamics, offering a more realistic understanding of complex systems. The proposed framework has broad applications ranging from coupled oscillators in physics to social dynamics, and serves as a valuable tool for studying networks with distributed intrinsic frequencies. △ Less",https://arxiv.org/abs/2509.18000,arxiv_game_page0.csv
The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents,"Antoni Guasch, Maria Isabel Valdez","Current Large Reasoning Models (LRMs) exhibit significant limitations in reliability and transparency, often showing a collapse in reasoning capabilities when faced with high-complexity, long-horizon tasks. This ""illusion of thinking"" is frequently an artifact of non-agentic, black-box evaluation paradigms that fail to cultivate robust problem-solving processes. In response, we introduce The STAR-XAI Protocol (Socratic, Transparent, Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel methodology for training and operating verifiably reliable AI agents. Our method reframes the human-AI interaction as a structured, Socratic dialogue, governed by an explicit and evolving rulebook, the Consciousness Transfer Package (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc strategic justification and a state-locking Checksum that prevents error accumulation, the protocol transforms a powerful but opaque LRM into a disciplined ""Clear Box"" agent. We demonstrate the efficacy of this method through an exhaustive 25-move case study in the complex strategic game ""Caps i Caps"". The agent not only solved the high-complexity puzzle but also demonstrated Second-Order Agency, identifying flaws in its own supervisor-approved plans and adapting its core integrity protocols mid-task. The STAR-XAI Protocol offers a practical pathway to creating AI agents that are not just high-performing, but also transparent, auditable, and trustworthy by design. △ Less",https://arxiv.org/abs/2509.17978,arxiv_game_page0.csv
Towards the State Space Interpretation (SSI): A Formalized Framework forGameStudies and Design,"Zhenghao Wang, Shuo Xiong","In this paper, we establish structural analogies between core concepts in quantum mechanics and games . By constructing the Quantum Coin Toss on a quantum circuit, we preliminarily investigate the similarity between quantum system behavior and game behavior, thereby formulating the state-operation paradigm. Using this paradigm, we introduce the conceptual prototype of the State Space Interpretation (SSI). Based on mathematical and physical theories, particularly linear algebra, quantum mechanics, and statistical mechanics, we define formal constructs including state space, evolution path, and derived concepts. With the SSI, a game is conceptualized as a state space, while a gameplay process corresponds to an evolution path within this space. We propose that the SSI constitutes a novel interpretation framework for game design and game studies. This framework aims to enhance understanding of games and function as a link between game studies and related fields. △ Less",https://arxiv.org/abs/2509.17610,arxiv_game_page0.csv
Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization,"Feng-Qi Cui, Jinyang Huang, Anyang Tong, Ziyu Jia, Jie Zhang, Zhi Liu, Dan Guo, Jianwei Lu, Meng Wang","Micro-action Recognition is vital for psychological assessment and human-computer interaction. However, existing methods often fail in real-world scenarios because inter-person variability causes the same action to manifest differently, hindering robust generalization. To address this, we propose the Person Independence Universal Micro-action Recognition Framework, which integrates Distributionally Robust Optimization principles to learn person-agnostic representations. Our framework contains two plug-and- play components operating at the feature and loss levels. At the feature level, the Temporal-Frequency Alignment Module normalizes person-specific motion characteristics with a dual-branch design: the temporal branch applies Wasserstein-regularized alignment to stabilize dynamic trajectories, while the frequency branch introduces variance-guided perturbations to enhance robustness against person-specific spectral differences. A consistency-driven fusion mechanism integrates both branches. At the loss level, the Group-Invariant Regularized Loss partitions samples into pseudo-groups to simulate unseen person-specific distributions. By up-weighting boundary cases and regularizing subgroup variance, it forces the model to generalize beyond easy or frequent samples, thus enhancing robustness to difficult variations. Experiments on the large-scale MA-52 dataset demonstrate that our framework outperforms existing methods in both accuracy and robustness, achieving stable generalization under fine-grained conditions. △ Less",https://arxiv.org/abs/2509.21261,arxiv_play_page0.csv
Response to Promises and Pitfalls of Deep Kernel Learning,"Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P. Xing","This note responds to ""Promises and Pitfalls of Deep Kernel Learning"" (Ober et al., 2021). The marginal likelihood of a Gaussian process can be compartmentalized into a data fit term and a complexity penalty. Ober et al. (2021) shows that if a kernel can be multiplied by a signal variance coefficient, then reparametrizing and substituting in the maximized value of this parameter sets a reparametrized data fit term to a fixed value. They use this finding to argue that the complexity penalty, a log determinant of the kernel matrix, then dominates in determining the other values of kernel hyperparameters, which can lead to data overcorrelation. By contrast, we show that the reparametrization in fact introduces another data-fit term which influences all other kernel hyperparameters. Thus, a balance between data fit and complexity still plays a significant role in determining kernel hyperparameters. △ Less",https://arxiv.org/abs/2509.21228,arxiv_play_page0.csv
Electronic crystals in layered materials,"You Zhou, Ilya Esterlis, Tomasz Smoleński","In modern two-dimensional (2D) materials, such as graphene-based systems and atomically-thin transition-metal dichalcogenides, the interplay of strong electronic correlations, tunable moiré superlattices, and nontrivial band topology has given rise to rich phase diagrams and collective phenomena. Among the novel phases that have been realized, electronic crystals -- states of matter in which itinerant electrons spontaneously crystallize -- play a particularly prominent role. In this Review, we summarize the current status of electron crystallization in van der Waals heterostructures, with emphasis on the experimental platforms and measurement techniques that enable their study. We also highlight open questions and outline future directions that may elucidate more of the fascinating properties of electronic crystals. △ Less",https://arxiv.org/abs/2509.21222,arxiv_play_page0.csv
The NANOGrav 15-Year Data Set: Improved Timing Precision With VLBI Astrometric Priors,"Sofia V. Sosa Fiscella, Michael T. Lam, Gabriella Agazie, Akash Anumarlapudi, Anne M. Archibald, Zaven Arzoumanian, Paul T. Baker, Paul R. Brook, H. Thankful Cromartie, Kathryn Crowter, Maria Silvina De Biasi, Megan E. DeCesar, Paul B. Demorest, Timothy Dolch, Elizabeth C. Ferrara, William Fiore, Emmanuel Fonseca, Gabriel E. Freedman, Nate Garver-Daniels, Peter A. Gentile, Joseph Glaser, Deborah C. Good, Jeffrey S. Hazboun, Ross J. Jennings, Megan L. Jones","Accurate pulsar astrometric estimates play an essential role in almost all high-precision pulsar timing experiments. Traditional pulsar timing techniques refine these estimates by including them as free parameters when fitting a model to observed pulse time-of-arrival measurements. However, reliable sub-milliarcsecond astrometric estimations require years of observations and, even then, power from red noise can be inadvertently absorbed into astrometric parameter fits, biasing the resulting estimations and reducing our sensitivity to red noise processes, including gravitational waves (GWs). In this work, we seek to mitigate these shortcomings by using pulsar astrometric estimates derived from Very Long Baseline Interferometry (VLBI) as priors for the timing fit. First, we calibrated a frame tie to account for the offsets between the reference frames used in VLBI and timing. Then, we used the VLBI-informed priors and timing-based likelihoods of several astrometric solutions consistent with both techniques to obtain a maximum-posterior astrometric solution. We found offsets between our results and the timing-based astrometric solutions, which, if real, would lead to absorption of spectral power at frequencies of interest for single-source GW searches. However, we do not find significant power absorption due to astrometric fitting at the low-frequency domain of the GW background. △ Less",https://arxiv.org/abs/2509.21203,arxiv_play_page0.csv
Resistive Scaling in the Magnetic Helicity-Driven Inverse Cascade,"Jiyao Zhang, Axel Brandenburg","The inverse cascade in MHD turbulence plays a crucial role in various astrophysical processes such as galaxy cluster formation, solar and stellar dynamo mechanisms, and the evolution of primordial magnetic fields in the early universe. A standard numerical approach involves injecting magnetic helicity at intermediate length scales to generate a secondary, time-dependent spectral peak that gradually propagates toward larger scales. Previous simulations have already suggested a resistive dependence of inverse transfer rates and demonstrated the significant influence of magnetic helicity flux density $ε_\mathrm{H}$ on this process. On dimensional grounds, we have $E_\mathrm{M}(k,t)=C_\mathrm{H} ε_\mathrm{H}^{2/3} k^{-1}$ where $C_\mathrm{H}$ represents a potentially universal dimensionless coefficient analogous to the Kolmogorov constant. We present a summary of the 25 distinct simulations conducted with the \textsc{Pencil Code}, systematically varying the forcing wavenumber $k_\mathrm{f}$, magnetic Prandtl number $Pm$, grid resolution $N^3$, and Lundquist number $Lu$. We obtained $C_\mathrm{H}$ and corresponding error bars by calculating the compensated spectrum and investigated its dependence with $Lu$ and $k_\mathrm{f}$. For the $C_\mathrm{H}$ - $Lu$ relationship, we observe strong correlations with power-law exponents of 1 and 2/3. In contrast, we find no significant correlation between $C_\mathrm{H}$ and $k_\mathrm{f}$. △ Less",https://arxiv.org/abs/2509.21141,arxiv_play_page0.csv
"Power residues, digit expansions and relative class numbers",Kurt Girstmair,"This is a survey of a connection between the distribution of certain power residues modulo $p$, $p$ a prime, and relative class numbers. The focus lies on quadratic residues and sixth power residues. Dirichlet's class number formula yields a number of results about the distribution of quadratic residues, for instance, the well-known fact that the interval $[0,p/2]$ contains more quadratic residues than nonresidues. This class number formula is also responsible for some properties of the digit expansions of numbers $m/p$, $p\NDIV m$. In a certain sense the results based on Dirichlet's formula can be extended to sixth power residues, where geometry plays an important role. △ Less",https://arxiv.org/abs/2509.21094,arxiv_play_page0.csv
SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials,"Qixin Wan, Zilong Wang, Jingwen Zhou, Wanting Wang, Ziheng Geng, Jiachen Liu, Ran Cao, Minghui Cheng, Lu Cheng","Foundation models have shown remarkable capabilities in various domains, but their performance on complex, multimodal engineering problems remains largely unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark dataset dedicated to evaluating foundation models on problems in the strength of materials (SoM). The dataset, which contains 1,065 annotated SoM problems, mirrors real-world engineering tasks by including both textual problem statements and schematic diagrams. Due to the limited capabilities of current foundation models in understanding complicated visual information, we propose a novel prompting strategy called Descriptions of Images (DoI), which provides rigorous expert-generated text descriptions of the visual diagrams as the context. We evaluate eight representative foundation models, including both large language models (LLMs) and vision language models (VLMs). Our results show that current foundation models struggle significantly with these engineering problems, with the best-performing model achieving only 56.6% accuracy. Interestingly, we found that LLMs, when provided with DoI, often outperform VLMs provided with visual diagrams. A detailed error analysis reveals that DoI plays a crucial role in mitigating visual misinterpretation errors, suggesting that accurate text-based descriptions can be more effective than direct image input for current foundation models. This work establishes a rigorous benchmark for engineering AI and highlights a critical need for developing more robust multimodal reasoning capabilities in foundation models, particularly in scientific and engineering contexts. △ Less",https://arxiv.org/abs/2509.21079,arxiv_play_page0.csv
Efficient Ensemble Conditional Independence Test Framework for Causal Discovery,"Zhengkang Guan, Kun Kuang","Constraint-based causal discovery relies on numerous conditional independence tests (CITs), but its practical applicability is severely constrained by the prohibitive computational cost, especially as CITs themselves have high time complexity with respect to the sample size. To address this key bottleneck, we introduce the Ensemble Conditional Independence Test (E-CIT), a general and plug-and- play framework. E-CIT operates on an intuitive divide-and-aggregate strategy: it partitions the data into subsets, applies a given base CIT independently to each subset, and aggregates the resulting p-values using a novel method grounded in the properties of stable distributions. This framework reduces the computational complexity of a base CIT to linear in the sample size when the subset size is fixed. Moreover, our tailored p-value combination method offers theoretical consistency guarantees under mild conditions on the subtests. Experimental results demonstrate that E-CIT not only significantly reduces the computational burden of CITs and causal discovery but also achieves competitive performance. Notably, it exhibits an improvement in complex testing scenarios, particularly on real-world datasets. △ Less",https://arxiv.org/abs/2509.21021,arxiv_play_page0.csv
Littlewood's estimates for $L$-functions in the hyperelliptic ensemble,"Emanuel Carneiro, Pranendu Darbar, Mithun Kumar Das, Tolibjon Ismoilov, Antonio Pedro Ramos","We investigate the analogues of certain classical estimates of Littlewood for the Riemann zeta-function in the context of quadratic Dirichlet $L$-functions over function fields. In some situations, we are actually able to establish finer results in the function field setup than what is currently known in the original number field setup, and this leads us to an educated guess on what could happen for the Riemann zeta-function in such situations. Fourier analysis techniques play an important role in our approach. △ Less",https://arxiv.org/abs/2509.21019,arxiv_play_page0.csv
AOT*: Efficient Synthesis Planning via LLM-Empowered AND-OR Tree Search,"Xiaozhuang Song, Xuanhao Pan, Xinjian Zhao, Hangting Ye, Shufei Zhang, Jian Tang, Tianshu Yu","Retrosynthesis planning enables the discovery of viable synthetic routes for target molecules, playing a crucial role in domains like drug discovery and materials design. Multi-step retrosynthetic planning remains computationally challenging due to exponential search spaces and inference costs. While Large Language Models (LLMs) demonstrate chemical reasoning capabilities, their application to synthesis planning faces constraints on efficiency and cost. To address these challenges, we introduce AOT*, a framework that transforms retrosynthetic planning by integrating LLM-generated chemical synthesis pathways with systematic AND-OR tree search. To this end, AOT* atomically maps the generated complete synthesis routes onto AND-OR tree components, with a mathematically sound design of reward assignment strategy and retrieval-based context engineering, thus enabling LLMs to efficiently navigate in the chemical space. Experimental evaluation on multiple synthesis benchmarks demonstrates that AOT* achieves SOTA performance with significantly improved search efficiency. AOT* exhibits competitive solve rates using 3-5$\times$ fewer iterations than existing LLM-based approaches, with the efficiency advantage becoming more pronounced on complex molecular targets. △ Less",https://arxiv.org/abs/2509.20988,arxiv_play_page0.csv
Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM,"Najla Zuhir, Amna Mohammad Salim, Parvathy Premkumar, Moshiur Farazi","We present an advanced approach to mobile app review analysis aimed at addressing limitations inherent in traditional star-rating systems. Star ratings, although intuitive and popular among users, often fail to capture the nuanced feedback present in detailed review texts. Traditional NLP techniques -- such as lexicon-based methods and classical machine learning classifiers -- struggle to interpret contextual nuances, domain-specific terminology, and subtle linguistic features like sarcasm. To overcome these limitations, we propose a modular framework leveraging large language models (LLMs) enhanced by structured prompting techniques. Our method quantifies discrepancies between numerical ratings and textual sentiment, extracts detailed, feature-level insights, and supports interactive exploration of reviews through retrieval-augmented conversational question answering (RAG-QA). Comprehensive experiments conducted on three diverse datasets (AWARE, Google Play , and Spotify) demonstrate that our LLM-driven approach significantly surpasses baseline methods, yielding improved accuracy, robustness, and actionable insights in challenging and context-rich review scenarios. △ Less",https://arxiv.org/abs/2509.20953,arxiv_play_page0.csv
Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models,"Bum Jun Kim, Makoto Kawano, Yusuke Iwasawa, Yutaka Matsuo","While the robustness of vision models is often measured, their dependence on specific architectural design choices is rarely dissected. We investigate why certain vision architectures are inherently more robust to additive Gaussian noise and convert these empirical insights into simple, actionable design rules. Specifically, we performed extensive evaluations on 1,174 pretrained vision models, empirically identifying four consistent design patterns for improved robustness against Gaussian noise: larger stem kernels, smaller input resolutions, average pooling, and supervised vision transformers (ViTs) rather than CLIP ViTs, which yield up to 506 rank improvements and 21.6\%p accuracy gains. We then develop a theoretical analysis that explains these findings, converting observed correlations into causal mechanisms. First, we prove that low-pass stem kernels attenuate noise with a gain that decreases quadratically with kernel size and that anti-aliased downsampling reduces noise energy roughly in proportion to the square of the downsampling factor. Second, we demonstrate that average pooling is unbiased and suppresses noise in proportion to the pooling window area, whereas max pooling incurs a positive bias that grows slowly with window size and yields a relatively higher mean-squared error and greater worst-case sensitivity. Third, we reveal and explain the vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller normalization standard deviations used in CLIP preprocessing amplify worst-case sensitivity by up to 1.91 times relative to the Inception-style preprocessing common in supervised ViTs. Our results collectively disentangle robustness into interpretable modules, provide a theory that explains the observed trends, and build practical, plug-and- play guidelines for designing vision models more robust against Gaussian noise. △ Less",https://arxiv.org/abs/2509.20939,arxiv_play_page0.csv
GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine,"Heming Zhang, Di Huang, Wenyu Li, Michael Province, Yixin Chen, Philip Payne, Fuhai Li","In precision medicine, quantitative multi-omic features, topological context, and textual biological knowledge play vital roles in identifying disease-critical signaling pathways and targets. Existing pipelines capture only part of these-numerical omics ignore topological context, text-centric LLMs lack quantitative grounded reasoning, and graph-only models underuse node semantics and the generalization of LLMs-limiting mechanistic interpretability. Although Process Reward Models (PRMs) aim to guide reasoning in LLMs, they remain limited by unreliable intermediate evaluation, and vulnerability to reward hacking with computational cost. These gaps motivate integrating quantitative multi-omic signals, topological structure with node annotations, and literature-scale text via LLMs, using subgraph reasoning as the principle bridge linking numeric evidence, topological knowledge and language context. Therefore, we propose GALAX (Graph Augmented LAnguage model with eXplainability), an innovative framework that integrates pretrained Graph Neural Networks (GNNs) into Large Language Models (LLMs) via reinforcement guided by a Graph Process Reward Model (GPRM), which generates disease-relevant subgraphs in a step-wise manner initiated by an LLM and iteratively evaluated by a pretrained GNN, enabling process-level supervision without explicit intermediate reasoning annotations. As an application, we also introduced Target-QA, a benchmark combining CRISPR-identified targets, multi-omic profiles, and biomedical graph knowledge across diverse cancer cell lines, which enables GNN pretraining for supervising step-wise graph construction and supports long-context reasoning over text-numeric graphs (TNGs), providing a scalable and biologically grounded framework for explainable, reinforcement-guided subgraph reasoning toward reliable and interpretable target and pathway discovery in precision medicine. △ Less",https://arxiv.org/abs/2509.20935,arxiv_play_page0.csv
Nonlinear corrections to the nuclear heavy flavor structure functions,"F. Abdi, B. Rezaei","We study numerically the small-$x$ behaviour of the nuclear gluon distribution function $ G^A(x,Q^2)$ at next-to-leading order (NLO) approximation of the Gribov-Levin-Ryskin-Mueller-Qiu, Zhu-Ruan-Shen (GLR-MQ-ZRS) nonlinear equation and quantify the impact of gluon recombination in the kinematic range of $x \le 10^{-2}$ and $Q^2 \ge 5 \text{GeV}^2$ respectively. The results are comparable to the Rausch-Guzey-Klasen (RGK) [J.Rausch, V.Guzey and M.Klasen, Phys. Rev. D 107, 054003 (2023)] nuclear gluon distributions and the nCTEQ15 parametrization at the corresponding $Q^2$ values. Using the solutions of $ G^A(x,Q^2)$ in the framework of the nonlinear GLR-MQ-ZRS evolution equation, the linear and nonlinear behavior of the charm structure functions of nuclei per nucleon $F^{c\bar{c}-A}_2(x,Q^2)$ and $F^{c\bar{c}-A}_L(x,Q^2)$ are considered. The results reveal that nonlinear corrections play an important role in charm nuclear reduced cross sections at small-$ x$ and low $Q^2$ values. The computed results are compared with experimental data from the H1 and ZEUS Collaborations. △ Less",https://arxiv.org/abs/2509.20934,arxiv_play_page0.csv
Quantum Simulation and Energy Estimation for Discretized Anharmonic oscillator,"Saurav Suman, Bikash K. Behera, Vivek Vyas, Prasanta k. Panigrahi","Anharmonic potential quantum system play crucial role in physics as they provide a more realistic description of oscillatory phenomena, which often deviate from the idealized harmonic model. However, simulating such system on classical computers is highly challenging due to nonlinear interactions, large state spaces, and the exponential scaling of memory and computational resources. In this work, quantum simulation is employed to model a quantum anharmonic oscillator (QAHO) using a 3-qubit system implemented on IBM's Quantum Experiences platform. A quantum circuit with a filter-based design and Toffoli gates is constructed to track quantum state evolution, capturing key phenomena like quantum revival. The framework is further extended to n-qubit system to enhance resolution and scalability. For energy estimation, the Variational Quantum Eigensolver (VQE) with a TwoLocal ansatz and variational Quantum Deflation (VQD), are used to compute ground and excited state energies. The proposed approach achieves high accuracy with an error of only 1.11% compared to exact methods. Notably, VQE outperforms classical approximations such as perturbation theory (error 6.71%) and the Wentzel-Kramers-Brillouin (WKB) approximation(error 5.36%), yielding more precise energy values. These results highlight the potential of quantum simulation and VQD as effective tools for investigating complex quantum system, paving the way for future application in quantum chemistry and materials science as quantum hardware continues to advance. △ Less",https://arxiv.org/abs/2509.20907,arxiv_play_page0.csv
PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval,"Yixuan Li, Xinyi Liu, Weidong Yang, Ben Fei, Shuhao Li, Mingjie Zhou, Lipeng Ma","Code search aims to precisely find relevant code snippets that match natural language queries within massive codebases, playing a vital role in software development. Recent advances leverage pre-trained language models (PLMs) to bridge the semantic gap between unstructured natural language (NL) and structured programming languages (PL), yielding significant improvements over traditional information retrieval and early deep learning approaches. However, existing PLM-based methods still encounter key challenges, including a fundamental semantic gap between human intent and machine execution logic, as well as limited robustness to diverse code styles. To address these issues, we propose PseudoBridge, a novel code retrieval framework that introduces pseudo-code as an intermediate, semi-structured modality to better align NL semantics with PL logic. Specifically, PseudoBridge consists of two stages. First, we employ an advanced large language model (LLM) to synthesize pseudo-code, enabling explicit alignment between NL queries and pseudo-code. Second, we introduce a logic-invariant code style augmentation strategy and employ the LLM to generate stylistically diverse yet logically equivalent code implementations with pseudo-code, then align the code snippets of different styles with pseudo-code, enhancing model robustness to code style variation. We build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream programming languages. Extensive experiments demonstrate that PseudoBridge consistently outperforms baselines, achieving significant gains in retrieval accuracy and generalization, particularly under zero-shot domain transfer scenarios such as Solidity and XLCoST datasets. These results demonstrate the effectiveness of explicit logical alignment via pseudo-code and highlight PseudoBridge's potential as a robust, generalizable solution for code retrieval. △ Less",https://arxiv.org/abs/2509.20881,arxiv_play_page0.csv
The Unanticipated Asymmetry Between Perceptual Optimization and Assessment,"Jiabei Zhang, Qi Wang, Siyu Wu, Du Chen, Tianhe Wu","Perceptual optimization is primarily driven by the fidelity objective, which enforces both semantic consistency and overall visual realism, while the adversarial objective provides complementary refinement by enhancing perceptual sharpness and fine-grained detail. Despite their central role, the correlation between their effectiveness as optimization objectives and their capability as image quality assessment (IQA) metrics remains underexplored. In this work, we conduct a systematic analysis and reveal an unanticipated asymmetry between perceptual optimization and assessment: fidelity metrics that excel in IQA are not necessarily effective for perceptual optimization, with this misalignment emerging more distinctly under adversarial training. In addition, while discriminators effectively suppress artifacts during optimization, their learned representations offer only limited benefits when reused as backbone initializations for IQA models. Beyond this asymmetry, our findings further demonstrate that discriminator design plays a decisive role in shaping optimization, with patch-level and convolutional architectures providing more faithful detail reconstruction than vanilla or Transformer-based alternatives. These insights advance the understanding of loss function design and its connection to IQA transferability, paving the way for more principled approaches to perceptual optimization. △ Less",https://arxiv.org/abs/2509.20878,arxiv_play_page0.csv
Alternative tangent and cotangent structures and their physical applications,"José F. Cariñena, Jesús Clemente-Gallardo, Giuseppe Marmo","The conditions under which a given manifold $M$ may be given a tangent bundle or a cotangent bundle structure are analyzed. This is an important property arising in different contexts. For instance, in the study of integrability of a given dynamics the existence of alternative compatible structures is very relevant, as well as in the geometric approach to Classical Mechanics. On the other hand in the quantum-to-classical transition, a Weyl system plays an important role for it provides (within the so-called Weyl-Wigner formalism) a description of quantum mechanics on a (symplectic) phase-space $M$. A Lagrangian subspace $Q\subset M$ of the (linear) phase space determines thus a maximal set of pairwise commuting unitary operators, which is used to parametrize the quantum states. As the choice of this maximal Abelian set of observables is not unique, the different choices make the phase space to become diffeomorphic to different cotangent bundles $T^*Q$ corresponding to different choices for the base manifold (and hence the fibers). These motivating ideas are used to study how to define alternative tangent and/or cotangent bundle structures on a phase space. △ Less",https://arxiv.org/abs/2509.20855,arxiv_play_page0.csv
FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting,"Kjersti Engan, Neel Kanwal, Anita Yeconia, Ladislaus Blacy, Yuda Munyaw, Estomih Mduma, Hege Ersdal","Approximately 10\% of newborns require assistance to initiate breathing at birth, and around 5\% need ventilation support. Fetal heart rate (FHR) monitoring plays a crucial role in assessing fetal well-being during prenatal care, enabling the detection of abnormal patterns and supporting timely obstetric interventions to mitigate fetal risks during labor. Applying artificial intelligence (AI) methods to analyze large datasets of continuous FHR monitoring episodes with diverse outcomes may offer novel insights into predicting the risk of needing breathing assistance or interventions. Recent advances in wearable FHR monitors have enabled continuous fetal monitoring without compromising maternal mobility. However, sensor displacement during maternal movement, as well as changes in fetal or maternal position, often lead to signal dropouts, resulting in gaps in the recorded FHR data. Such missing data limits the extraction of meaningful insights and complicates automated (AI-based) analysis. Traditional approaches to handle missing data, such as simple interpolation techniques, often fail to preserve the spectral characteristics of the signals. In this paper, we propose a masked transformer-based autoencoder approach to reconstruct missing FHR signals by capturing both spatial and frequency components of the data. The proposed method demonstrates robustness across varying durations of missing data and can be used for signal inpainting and forecasting. The proposed approach can be applied retrospectively to research datasets to support the development of AI-based risk algorithms. In the future, the proposed method could be integrated into wearable FHR monitoring devices to achieve earlier and more robust risk detection. △ Less",https://arxiv.org/abs/2509.20852,arxiv_play_page0.csv
Baryons as linked vortices in QCD matter with isospin asymmetry,"Yu Hamada, Muneto Nitta, Zebin Qiu","We investigate a baryonic structure in low-energy QCD via a model-independent way using the chiral perturbation theory at the leading order, in the presence of the baryon chemical potential $μ_B$, the isospin chemical potential $μ_I$, and the electromagnetic coupling. For such a scenario in the chiral limit, it has been known that the neutral pion winds like in the chiral soliton lattice, confined within an Abrikosov-Nielsen-Olesen (ANO) vortex of the charged pions. This structure undergoes a drastic transformation when the pion mass is introduced, i.e., both charged and neutral pions condense in the bulk, allowing two distinct types of vortices: the charged pions constitute a local ANO-like vortex, while the neutral pion configures a global vortex which is further attached to a domain wall also known as the chiral soliton. Remarkably, the ANO vortex forms a topological linking with the closed global vortex line, when $μ_B$ exceeds its critical value as a function of $μ_I$. The linking number has the physical meaning of the baryon number in view of the Wess-Zumino-Witten term. In this sense, the linked configuration realizes a stable Skyrmion-type solution, but innovatively without the Skyrme term. We therefore propose a novel phase of dense baryonic matter comprised of such vortices, which shall play a role in the low-energy QCD phase diagram. △ Less",https://arxiv.org/abs/2509.20844,arxiv_play_page0.csv
Nontrivial topology in one- and two-dimensional asymmetric systems with chiral boundary states,"Yunlin Li, Yufu Liu, Xuezhi Wang, Haoran Zhang, Xunya Jiang","Symmetry plays an important role in the topological band theory. In contrary, study on the topological properties of the asymmetric systems is rather limited, especially in higher-dimensional systems. In this work, we explore a new theory to study the topology in various one-dimensional (1D) and two-dimensional (2D) asymmetric systems with chiral boundary states. Starting from the simple SSHm model, we show the chiral topology of its edge states by redefining sublattices. Meanwhile, based on its Rice-Mele-like effective Hamiltonian, a new topological invariant $\bar{Z}$ can be defined and the bulk-edge correspondence is established. With this clear physical picture, our theory can be extended to the more complex asymmetric ladder models, or even the 2D asymmetric systems. In the 2D BBH3 model, new chiral corner states with redefined lattices are found based on our method. These corner states are independent of any spatial symmetry and exhibit the characteristics of topological bound states in the continuum (TBICs). Moreover, the topological invariant can be calculated by introducing $\bar{Z}$ into 2D. At last, we propose an acoustic experiment of the BBH3 model where chiral corner states are numerically observed. Our work exhibits a new approach to study the topological properties of asymmetric systems. By redefining sublattices, we find that the models with entirely different structures might share the same topological origins. △ Less",https://arxiv.org/abs/2509.20834,arxiv_play_page0.csv
Imagining Design Workflows in Agentic AI Futures,"Samangi Wadinambiarachchi, Jenny Waycott, Yvonne Rogers, Greg Wadley","As designers become familiar with Generative AI, a new concept is emerging: Agentic AI. While generative AI produces output in response to prompts, agentic AI systems promise to perform mundane tasks autonomously, potentially freeing designers to focus on what they love: being creative. But how do designers feel about integrating agentic AI systems into their workflows? Through design fiction, we investigated how designers want to interact with a collaborative agentic AI platform. Ten professional designers imagined and discussed collaborating with an AI agent to organise inspiration sources and ideate. Our findings highlight the roles AI agents can play in supporting designers, the division of authority between humans and AI, and how designers' intent can be explained to AI agents beyond prompts. We synthesise our findings into a conceptual framework that identifies authority distribution among humans and AI agents and discuss directions for utilising AI agents in future design workflows. △ Less",https://arxiv.org/abs/2509.20731,arxiv_play_page0.csv
SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning,"Duoteng Xu, Yuguang Chen, Jing Li, Xinhai Liu, Xueqi Ma, Zhuo Chen, Dongyu Zhang, Chunchao Guo","Mesh seams play a pivotal role in partitioning 3D surfaces for UV parametrization and texture mapping. Poorly placed seams often result in severe UV distortion or excessive fragmentation, thereby hindering texture synthesis and disrupting artist workflows. Existing methods frequently trade one failure mode for another-producing either high distortion or many scattered islands. To address this, we introduce SeamCrafter, an autoregressive GPT-style seam generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch point-cloud encoder that disentangles and captures complementary topological and geometric cues during pretraining. To further enhance seam quality, we fine-tune the model using Direct Preference Optimization (DPO) on a preference dataset derived from a novel seam-evaluation framework. This framework assesses seams primarily by UV distortion and fragmentation, and provides pairwise preference labels to guide optimization. Extensive experiments demonstrate that SeamCrafter produces seams with substantially lower distortion and fragmentation than prior approaches, while preserving topological consistency and visual fidelity. △ Less",https://arxiv.org/abs/2509.20725,arxiv_play_page0.csv
CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning,"Zhenpeng Su, Leiyu Pan, Minxuan Lv, Yuntao Li, Wenping Hu, Fuzheng Zhang, Kun Gai, Guorui Zhou","Reinforcement learning (RL) has become a powerful paradigm for optimizing large language models (LLMs) to handle complex reasoning tasks. A core challenge in this process lies in managing policy entropy, which reflects the balance between exploration and exploitation during training. Existing methods, such as proximal policy optimization (PPO) and its variants, discard valuable gradient signals from low-probability tokens due to the clipping mechanism. We systematically analyze the entropy dynamics and reveal that these clipped tokens play a critical yet overlooked role in regulating entropy evolution. We propose \textbf{C}ontrolling \textbf{E}ntropy via \textbf{G}radient-\textbf{P}reserving \textbf{P}olicy \textbf{O}ptimization (CE-GPPO), a novel algorithm that reintroduces gradients from clipped tokens in native PPO in a gentle and bounded manner. By controlling the magnitude of gradients from tokens outside the clipping interval, CE-GPPO is able to achieve an exploration-exploitation trade-off. We provide theoretical justification and empirical evidence showing that CE-GPPO effectively mitigates entropy instability. Extensive experiments on mathematical reasoning benchmarks show that CE-GPPO consistently outperforms strong baselines across different model scales. △ Less",https://arxiv.org/abs/2509.20712,arxiv_play_page0.csv
Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms,"Abhinay Shankar Belde, Rohit Ramkumar, Jonathan Rusert","Adversarial text attack research plays a crucial role in evaluating the robustness of NLP models. However, the increasing complexity of transformer-based architectures has dramatically raised the computational cost of attack testing, especially for researchers with limited resources (e.g., GPUs). Existing popular black-box attack methods often require a large number of queries, which can make them inefficient and impractical for researchers. To address these challenges, we propose two new attack selection strategies called Hybrid and Dynamic Select, which better combine the strengths of previous selection algorithms. Hybrid Select merges generalized BinarySelect techniques with GreedySelect by introducing a size threshold to decide which selection algorithm to use. Dynamic Select provides an alternative approach of combining the generalized Binary and GreedySelect by learning which lengths of texts each selection method should be applied to. This greatly reduces the number of queries needed while maintaining attack effectiveness (a limitation of BinarySelect). Across 4 datasets and 6 target models, our best method(sentence-level Hybrid Select) is able to reduce the number of required queries per attack up 25.82\% on average against both encoder models and LLMs, without losing the effectiveness of the attack. △ Less",https://arxiv.org/abs/2509.20699,arxiv_play_page0.csv
The impact of the point spread function fitting radius on photometric uncertainty based on the Fisher information matrix,"Sebastian Espinosa, Mario L. Vicuña, Rene A. Mendez, Jorge F. Silva, Marcos Orchard","In point spread function (PSF) photometry, the selection of the fitting aperture radius plays a critical role in determining the precision of flux and background estimations. Traditional methods often rely on maximizing the signal-to-noise ratio (S/N) as a criterion for aperture selection. However, S/N-based approaches do not necessarily provide the optimal precision for joint estimation problems as they do not account for the statistical limits imposed by the Fisher information in the context of the Cramér-Rao lower bound (CRLB). This study aims to establish an alternative criterion for selecting the optimal fitting radius based on Fisher information rather than S/N. Fisher information serves as a fundamental measure of estimation precision, providing theoretical guarantees on the achievable accuracy for parameter estimation. By leveraging Fisher information, we seek to define an aperture selection strategy that minimizes the loss of precision. We conducted a series of numerical experiments that analyze the behavior of Fisher information and estimator performance as a function of the PSF aperture radius. Specifically, we revisited fundamental photometric models and explored the relationship between aperture size and information content. We compared the empirical variance of classical estimators, such as maximum likelihood and stochastic weighted least squares, against the theoretical CRLB derived from the Fisher information matrix. Our results indicate that aperture selection based on the Fisher information provides a more robust framework for achieving optimal estimation precision. △ Less",https://arxiv.org/abs/2509.20613,arxiv_play_page0.csv
von Kármán--Howarth Similarity of Spatial Correlations and the Distribution of Correlation Lengths in Solar Photospheric Turbulence,"Rohit Chhiber, Raphael Attie, William H. Matthaeus, Sohom Roy, Barbara J. Thompson","Fluctuations in the Sun's photospheric magnetic field are the primary source of the turbulence that can heat and accelerate the solar atmosphere, and thus play an important role in the production and evolution of the solar wind that permeates the heliosphere. A key parameter that characterizes this turbulence is the correlation scale of fluctuations, which determines the injection of turbulent energy into the plasma and influences the diffusive transport of solar energetic particles. This study employs magnetogram data acquired by the Helioseismic and Magnetic Imager on board the Solar Dynamics Observatory to characterize an ensemble of spatial autocorrelation functions (ACFs) of magnetic fluctuations in the photosphere. It is shown that the two-point ACFs satisfy the similarity-decay hypothesis of von Kármán and Howarth, a fundamental property of turbulent systems: following a rescaling of the ACFs by energy and correlation lengths, a quasi-universal functional form is obtained demonstrating exponential decay of correlations. The probability distribution function of transverse correlation lengths (\(λ\)) is shown to be approximately log-normal. A mosaic of the spatial distribution of \(λ\) over the photosphere is presented; the ``quiet Sun'' tends to have \(λ\sim 1500\) km (albeit with a wide distribution), which is close to the scale of solar granulation; systematically longer lengths are associated with active regions. A positive correlation is observed between mean magnetic field magnitude and \(λ\), and empirical fits are derived to quantify this relationship. These results improve our understanding of the nature of turbulence in the solar photosphere and the origin of coronal and solar-wind turbulence, while providing observational constraints for models that describe the transport of turbulence from solar and stellar photospheres into their atmospheres. △ Less",https://arxiv.org/abs/2509.20590,arxiv_play_page0.csv
Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications,"Samer Alshaer, Ala Khalifeh, Roman Obermaisser","Metascheduling in time-triggered architectures has been crucial in adapting to dynamic and unpredictable environments, ensuring the reliability and efficiency of task execution. However, traditional approaches face significant challenges when training Artificial Intelligence (AI) scheduling inferences offline, particularly due to the complexities involved in constructing a comprehensive Multi-Schedule Graph (MSG) that accounts for all possible scenarios. The process of generating an MSG that captures the vast probability space, especially when considering context events like hardware failures, slack variations, or mode changes, is resource-intensive and often infeasible. To address these challenges, we propose an adaptive online learning unit integrated within the metascheduler to enhance performance in real-time. The primary motivation for developing this unit stems from the limitations of offline training, where the MSG created is inherently a subset of the complete space, focusing only on the most probable and critical context events. In the online mode, Reinforcement Learning (RL) plays a pivotal role by continuously exploring and discovering new scheduling solutions, thus expanding the MSG and enhancing system performance over time. This dynamic adaptation allows the system to handle unexpected events and complex scheduling scenarios more effectively. Several RL models were implemented within the online learning unit, each designed to address specific challenges in scheduling. These models not only facilitate the discovery of new solutions but also optimize existing schedulers, particularly when stricter deadlines or new performance criteria are introduced. By continuously refining the AI inferences through real-time training, the system remains flexible and capable of meeting evolving demands, thus ensuring robustness and efficiency in large-scale, safety-critical environments. △ Less",https://arxiv.org/abs/2509.20520,arxiv_play_page0.csv
How two-dimensional are planet-disc interactions? II. Radiation hydrodynamics and suitable cooling prescriptions,"Alexandros Ziampras, Amelia J. Cordwell, Roman R. Rafikov, Richard P. Nelson","The ring and gap structures found in observed protoplanetary disks are often attributed to embedded gap-opening planets and typically modeled with simplified thermodynamics in the 2D, thin disk approximation. However, it has been shown that radiative cooling and meridional processes play key roles in planet-disk interaction, though their computational cost has limited their exploration. We investigate the differences between 2D and 3D models of gap-opening planets while also comparing thermodynamical frameworks ranging from locally isothermal to fully radiative. We also compare simplified cooling recipes to fully radiative models in an effort to motivate the inclusion of radiative effects in future modeling even in a parametrized manner. We perform hydrodynamical simulations in both 2D and 3D, and then compare the angular momentum deposition by planetary spirals to assess gap opening efficiency. We repeat comparisons with different thermodynamical treatments: locally isothermal, adiabatic, local $β$ cooling, and fully radiative including radiative diffusion. We find that 2D models are able to capture the essential physics of gap opening with remarkable accuracy, even when including full radiation transport in both cases. Simple cooling prescriptions can capture the trends found in fully radiative models, albeit slightly overestimating gap opening efficiency near the planet. Inherently 3D effects such as vertical flows that cannot be captured in 2D can explain the differences between the two approaches, but do not impact gap opening significantly. Our findings encourage the use of models that include radiative processes in the study of planet-disk interaction, even with simplified yet physically motivated cooling prescriptions in lieu of full radiation transport. This is particularly important in the context of substructure-inducing planets in the ALMA-sensitive disk regions (>10 au). △ Less",https://arxiv.org/abs/2509.20464,arxiv_play_page0.csv
Collider probes of baryogenesis with maximal CP asymmetry,"Debasish Borah, Kun Cheng, Arnab Dasgupta, Tao Han, Keping Xie","We propose a novel collider probe of baryogenesis at TeV scale by measuring decay asymmetries into particle and anti-particle final states. Motivated by the idea of Dirac leptogenesis, we consider an extension of the standard model with new colored and $SU(2)_L$ singlet particles in such a way that the out-of-equilibrium decay of heavy colored fermions creates equal and opposite CP asymmetries in two sectors, prevented from equilibrating with each other. While the TeV scale viability of this mechanism requires a resonantly enhanced CP asymmetry, the latter also plays a crucial role leading to observable decay asymmetries in colliders. In addition to discussing conventional signatures of such heavy colored particles, namely, mono-jet plus missing transverse energy, displaced vertex, colored track at hadron colliders, we also show the unique possibility of measuring decay asymmetries via forward-backward and charge asymmetries at future muon colliders. In addition to being a verifiable TeV-scale baryogenesis scenario, the model also predicts a singlet scalar dark matter candidate consistent with the required thermal dark matter properties near the Higgs resonance. △ Less",https://arxiv.org/abs/2509.20459,arxiv_play_page0.csv
Online-Optimized RAG for Tool Use and Function Calling,"Yu Pan, Xiaocheng Li, Hanzhao Wang","In many applications, retrieval-augmented generation (RAG) drives tool use and function calling by embedding the (user) queries and matching them to pre-specified tool/function descriptions. In this paper, we address an embedding misalignment issue that often arises in practical applications due to imperfect embedding models or noisy descriptions; such misalignment may lead to incorrect retrieval and task failure. We introduce Online-Optimized RAG, a deployment-time framework that continually adapts retrieval embeddings from live interactions using minimal feedback (e.g., task success). Online-Optimized RAG applies lightweight online gradient updates with negligible per-query latency and requires no changes to the underlying LLM. The method is plug-and- play : it supports both single- and multi-hop tool use, dynamic tool inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent theoretical analysis that quantifies how the method's performance depends on the initialization quality of the embeddings and other related quantities. Across diverse tool-use and document-retrieval scenarios, our Online-Optimized RAG consistently improves tool selection accuracy and end-task success, thus providing a simple, practical path to robust, self-improving RAG systems. △ Less",https://arxiv.org/abs/2509.20415,arxiv_play_page0.csv
Phoenix-VAD: Streaming Semantic Endpoint Detection for Full-Duplex Speech Interaction,"Weijie Wu, Wenhao Guan, Kaidi Wang, Peijie Chen, Zhuanling Zha, Junbo Li, Jun Fang, Lin Li, Qingyang Hong","Spoken dialogue models have significantly advanced intelligent human\textendash computer interaction, yet they lack a plug\textendash and\textendash play full\textendash duplex prediction module for semantic endpoint detection, hindering seamless audio interactions. In this paper, we introduce Phoenix\textendashVAD, an LLM\textendash based model that enables streaming semantic endpoint detection. Specifically, Phoenix\textendash VAD leverages the semantic comprehension capability of the LLM and a sliding window training strategy to achieve reliable semantic endpoint detection while supporting streaming inference. Experiments on both semantically complete and incomplete speech scenarios indicate that Phoenix\textendash VAD achieves excellent and competitive performance. Furthermore, this design enables the full\textendash duplex prediction module to be optimized independently of the dialogue model, providing more reliable and flexible support for next\textendash generation human\textendash computer interaction. △ Less",https://arxiv.org/abs/2509.20410,arxiv_play_page0.csv
Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models,Leyi Ouyang,"Diplomatic events consistently prompt widespread public discussion and debate. Public sentiment plays a critical role in diplomacy, as a good sentiment provides vital support for policy implementation, helps resolve international issues, and shapes a nation's international image. Traditional methods for gauging public sentiment, such as large-scale surveys or manual content analysis of media, are typically time-consuming, labor-intensive, and lack the capacity for forward-looking analysis. We propose a novel framework that identifies specific modifications for diplomatic event narratives to shift public sentiment from negative to neutral or positive. First, we train a language model to predict public reaction towards diplomatic events. To this end, we construct a dataset comprising descriptions of diplomatic events and their associated public discussions. Second, guided by communication theories and in collaboration with domain experts, we predetermined several textual features for modification, ensuring that any alterations changed the event's narrative framing while preserving its core facts.We develop a counterfactual generation algorithm that employs a large language model to systematically produce modified versions of an original text. The results show that this framework successfully shifted public sentiment to a more favorable state with a 70\% success rate. This framework can therefore serve as a practical tool for diplomats, policymakers, and communication specialists, offering data-driven insights on how to frame diplomatic initiatives or report on events to foster a more desirable public sentiment. △ Less",https://arxiv.org/abs/2509.20367,arxiv_play_page0.csv
Projection-based model order reduction for residence time distribution analysis of an industrial-scale continuous casting tundish,"Harshith Gowrachari, Mattia Giuseppe Barra, Moaad Khamlich, Giovanni Stabile, Gianluca Bazzaro, Gianluigi Rozza","The flow behavior in the continuous casting tundish plays a critical role in steel quality and is typically characterized via residence time distribution (RTD) curves. This study investigates the fluid flow behaviour in a single-strand tundish using numerical and experimental approaches. Full-order model (FOM) steady-state simulations were conducted under both isothermal and non-isothermal conditions to assess the influence of thermal buoyancy on the flow characteristics. The results show that buoyancy effects under non-isothermal conditions have a negligible impact on the overall velocity field. The converged flow fields serve as initial conditions for transient tracer transport simulations, enabling evaluation of RTD curves and volume partitioning. A Galerkin projection-based reduced-order model (ROM) is developed to efficiently derive RTD curves. Comparison of RTD curves from experiments, FOM simulations, and ROM predictions demonstrates strong agreement, with both computational approaches closely matching experimental data. A parameter-time dependent ROM is subsequently developed using Galerkin projection and operator interpolation. This enables efficient evaluation of RTD curves across varying parameter values with significantly reduced computational cost compared to full-order simulations. The ROM framework is well-suited for real-time analysis, design processes, optimization, and digital twin applications in metallurgical processes. △ Less",https://arxiv.org/abs/2509.20366,arxiv_play_page0.csv
Morphological Synthesizer for Ge'ez Language: Addressing Morphological Complexity and Resource Limitations,"Gebrearegawi Gebremariam, Hailay Teklehaymanot, Gebregewergs Mezgebe","Ge'ez is an ancient Semitic language renowned for its unique alphabet. It serves as the script for numerous languages, including Tigrinya and Amharic, and played a pivotal role in Ethiopia's cultural and religious development during the Aksumite kingdom era. Ge'ez remains significant as a liturgical language in Ethiopia and Eritrea, with much of the national identity documentation recorded in Ge'ez. These written materials are invaluable primary sources for studying Ethiopian and Eritrean philosophy, creativity, knowledge, and civilization. Ge'ez has a complex morphological structure with rich inflectional and derivational morphology, and no usable NLP has been developed and published until now due to the scarcity of annotated linguistic data, corpora, labeled datasets, and lexicons. Therefore, we propose a rule-based Ge'ez morphological synthesizer to generate surface words from root words according to the morphological structures of the language. We used 1,102 sample verbs, representing all verb morphological structures, to test and evaluate the system. The system achieves a performance of 97.4%, outperforming the baseline model and suggesting that future work should build a comprehensive system considering morphological variations of the language.
  Keywords: Ge'ez, NLP, morphology, morphological synthesizer, rule-based △ Less",https://arxiv.org/abs/2509.20341,arxiv_play_page0.csv
SIM-CoT: Supervised Implicit Chain-of-Thought,"Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Jiaqi Wang, Xipeng Qiu, Dahua Lin","Implicit Chain-of-Thought (CoT) methods offer a token-efficient alternative to explicit CoT reasoning in Large Language Models (LLMs), but a persistent performance gap has limited their adoption. We identify a core latent instability issue when scaling the computational budget of implicit CoT: as the number of reasoning tokens increases, training often becomes unstable and collapses. Our analysis shows that this instability arises from latent representations becoming homogeneous and losing semantic diversity, caused by insufficient step-level supervision in current implicit CoT methods. To address this, we propose SIM-CoT, a plug-and- play training module that introduces step-level supervision to stabilize and enrich the latent reasoning space. SIM-CoT employs an auxiliary decoder during training to align each implicit token with its corresponding explicit reasoning step, ensuring latent states capture distinct and meaningful information. The auxiliary decoder is removed at inference, preserving the efficiency of implicit CoT with no added overhead. It also provides interpretability by projecting each latent token onto an explicit reasoning vocabulary, enabling per-step visualization and diagnosis. SIM-CoT significantly improves both in-domain accuracy and out-of-domain stability of implicit CoT methods, boosting Coconut by +8.2\% on GPT-2 and CODI by +3.0\% on LLaMA-3.1 8B. It further surpasses the explicit CoT baseline on GPT-2 by 2.1\% with 2.3$\times$ greater token efficiency, while closing the performance gap on larger models like LLaMA-3.1 8B. Code: https://github.com/InternLM/SIM-CoT △ Less",https://arxiv.org/abs/2509.20317,arxiv_play_page0.csv
"Multilingual Hope Speech Detection: A Comparative Study of Logistic Regression, mBERT, and XLM-RoBERTa with Active Learning","T. O. Abiola, K. D. Abiodun, O. E. Olumide, O. O. Adebanji, O. Hiram Calvo, Grigori Sidorov","Hope speech language that fosters encouragement and optimism plays a vital role in promoting positive discourse online. However, its detection remains challenging, especially in multilingual and low-resource settings. This paper presents a multilingual framework for hope speech detection using an active learning approach and transformer-based models, including mBERT and XLM-RoBERTa. Experiments were conducted on datasets in English, Spanish, German, and Urdu, including benchmark test sets from recent shared tasks. Our results show that transformer models significantly outperform traditional baselines, with XLM-RoBERTa achieving the highest overall accuracy. Furthermore, our active learning strategy maintained strong performance even with small annotated datasets. This study highlights the effectiveness of combining multilingual transformers with data-efficient training strategies for hope speech detection. △ Less",https://arxiv.org/abs/2509.20315,arxiv_play_page0.csv
Transfer Learning in Regression with Influential Points,"Bingbing Wang, Jiaqi Wang, Yu Tang","Regression prediction plays a crucial role in practical applications and strongly relies on data annotation. However, due to prohibitive annotation costs or domain-specific constraints, labeled data in the target domain is often scarce, making transfer learning a critical solution by leveraging knowledge from resource-rich source domains. In the practical target scenario, although transfer learning has been widely applied, influential points can significantly distort parameter estimation for the target domain model. This issue is further compounded when influential points are also present in source domains, leading to aggravated performance degradation and posing critical robustness challenges for existing transfer learning frameworks. In this study, we innovatively introduce a transfer learning collaborative optimization (Trans-CO) framework for influential point detection and regression model fitting. Extensive simulation experiments demonstrate that the proposed Trans-CO algorithm outperforms competing methods in terms of model fitting performance and influential point identification accuracy. Furthermore, it achieves superior predictive accuracy on real-world datasets, providing a novel solution for transfer learning in regression with influential points △ Less",https://arxiv.org/abs/2509.20272,arxiv_play_page0.csv
A HyperGraphMamba-Based Multichannel Adaptive Model for ncRNA Classification,"Xin An, Ruijie Li, Qiao Ning, Hui Li, Qian Ma, Shikai Guo","Non-coding RNAs (ncRNAs) play pivotal roles in gene expression regulation and the pathogenesis of various diseases. Accurate classification of ncRNAs is essential for functional annotation and disease diagnosis. To address existing limitations in feature extraction depth and multimodal fusion, we propose HGMamba-ncRNA, a HyperGraphMamba-based multichannel adaptive model, which integrates sequence, secondary structure, and optionally available expression features of ncRNAs to enhance classification performance. Specifically, the sequence of ncRNA is modeled using a parallel Multi-scale Convolution and LSTM architecture (MKC-L) to capture both local patterns and long-range dependencies of nucleotides. The structure modality employs a multi-scale graph transformer (MSGraphTransformer) to represent the multi-level topological characteristics of ncRNA secondary structures. The expression modality utilizes a Chebyshev Polynomial-based Kolmogorov-Arnold Network (CPKAN) to effectively model and interpret high-dimensional expression profiles. Finally, by incorporating virtual nodes to facilitate efficient and comprehensive multimodal interaction, HyperGraphMamba is proposed to adaptively align and integrate multichannel heterogeneous modality features. Experiments conducted on three public datasets demonstrate that HGMamba-ncRNA consistently outperforms state-of-the-art methods in terms of accuracy and other metrics. Extensive empirical studies further confirm the model's robustness, effectiveness, and strong transferability, offering a novel and reliable strategy for complex ncRNA functional classification. Code and datasets are available at https://anonymous.4open.science/r/HGMamba-ncRNA-94D0. △ Less",https://arxiv.org/abs/2509.20240,arxiv_play_page0.csv
Playby the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs,"Parker Glenn, Alfy Samuel, Daben Liu","Integrating LLM powered operators in declarative query languages allows for the combination of cheap and interpretable functions with powerful, generalizable language model reasoning. However, in order to benefit from the optimized execution of a database query language like SQL, generated outputs must align with the rules enforced by both type checkers and database contents. Current approaches address this challenge with orchestrations consisting of many LLM-based post-processing calls to ensure alignment between generated outputs and database values, introducing performance bottlenecks. We perform a study on the ability of various sized open-source language models to both parse and execute functions within a query language based on SQL, showing that small language models can excel as function executors over hybrid data sources. Then, we propose an efficient solution to enforce the well-typedness of LLM functions, demonstrating 7% accuracy improvement on a multi-hop question answering dataset with 53% improvement in latency over comparable solutions. We make our implementation available at https://github.com/parkervg/blendsql △ Less",https://arxiv.org/abs/2509.20208,arxiv_play_page0.csv
Meso-chiral optical properties of plasmonic nanoparticles: uncovering hidden chirality,"Yuanyang Xie, Alexey V. Krasavin, Anatoly V. Zayats","Molecular chirality plays an important role in chemistry and biology, allows control of biological interactions, affects drugs efficacy and safety, and promotes synthesis of new materials. In general, chirality manifests itself in optical activity (circular dichroism or circular birefringence). Chiral plasmonic nanoparticles have been recently developed for molecular enantiomer separation, chiral sensing and chiral photocatalysis. Here, we show that optical chirality of plasmonic nanoparticles exhibiting strong scattering can remain completely undetected using standard characterisation techniques, such as circular dichroism measurements. This phenomenon, which we term meso-chiral in analogy to meso-compounds in chemistry, is based on mutual cancellation of absorption and scattering chiral responses. As a prominent example, the meso-optical behaviour has been numerically demonstrated in multi-wound-SiO2/Au nanoparticles over the entire visible spectral range and in other prototypical chiral nanoparticles in narrower spectral ranges. The meso-chiral property has been experimentally verified by demonstrating chiral absorption of gold helicoid nanoparticles at the wavelength where conventional circular dichroism measurements show absence of chiral response (gext=0). These findings demonstrate a valuable link between microscopic to macroscopic manifestations of chirality and can provide insights for interpreting a wide range of experimental results and designing chiral properties of plasmonic nanoparticles. △ Less",https://arxiv.org/abs/2509.20178,arxiv_play_page0.csv
Numerical evaluation of parton distribution Mellin moments,"Akbari Jahan, Diptimonta Neog","The detailed comprehension of momentum fraction and energy dependence of proton structure functions is among the major difficulties in high-energy physics. Perturbative quantum chromodynamics (QCD) plays as an extensive foundation for analysing deep inelastic scattering (DIS) and experiments with hadron-hadron collisions. In such a framework, where the hard collisions advance through the partonic components of hadrons, a pivotal contribution is imparted by parton distribution functions (PDFs). PDFs provide information about the nucleonic substructure in terms of its components. PDFs have become more and more convictive following the advent of the Large Hadron Collider (LHC). Moments of PDFs are important quantities for the analysis of hadronic internal structure. The Mellin moments of such parton densities have been discussed and their analyses have been carried out numerically. △ Less",https://arxiv.org/abs/2509.20176,arxiv_play_page0.csv
Ergodic Properties of Quantum Markov Semigroups,"Nicolas Mousset, Nina H. Amini","In this paper, we study the ergodic theorem for infinite-dimensional quantum Markov semigroups, originally introduced by Frigerio and Verri in 1982, and its latest version developed by Carbone and Girotti in 2021. We provide a sufficient condition that ensures exponential convergence towards the positive recurrent subspace, a well-known result for irreducible quantum Markov semigroups in finite-dimensional Hilbert spaces. Several illustrative examples are presented to demonstrate the application of the ergodic theorem. Moreover, we show that the positive recurrent subspace plays a crucial role in the study of global asymptotic stability. △ Less",https://arxiv.org/abs/2509.20133,arxiv_play_page0.csv
Configuration and Benchmarking of $\mathrm{e}^+\mathrm{e}^-$ Processes with K4GeneratorsConfig,"Alan Price, Dirk Zerwas","The next generation of electron-positron colliders will require unprecedented precision in both theory and experiment. Sophisticated software frameworks are essential to evaluate detector concepts, optimize designs, and simulating physical processes. In this context, Monte Carlo (MC) event generators play a central role, enabling realistic simulations of Standard Model processes and providing the basis for physics studies. However, technical consistency across different generators remains critical, particularly in domains where agreement is expected. To address this need, we present K4GeneratorsConfig, a Python-based package that automates the benchmarking process for MC generators. The tool translates universal physics inputs into generator-specific configurations, ensuring consistency, reproducibility, and reduced human error. Its modular design allows for straightforward integration of additional generators, supports batch processing, and provides compatibility with the Key4hep software stack △ Less",https://arxiv.org/abs/2509.20116,arxiv_play_page0.csv
Beyond Slater's Condition in Online CMDPs with Stochastic and Adversarial Constraints,"Francesco Emanuele Stradi, Eleonora Fidelia Chiefari, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti","We study \emph{online episodic Constrained Markov Decision Processes} (CMDPs) under both stochastic and adversarial constraints. We provide a novel algorithm whose guarantees greatly improve those of the state-of-the-art best-of-both-worlds algorithm introduced by Stradi et al. (2025). In the stochastic regime, \emph{i.e.}, when the constraints are sampled from fixed but unknown distributions, our method achieves $\widetilde{\mathcal{O}}(\sqrt{T})$ regret and constraint violation without relying on Slater's condition, thereby handling settings where no strictly feasible solution exists. Moreover, we provide guarantees on the stronger notion of \emph{positive} constraint violation, which does not allow to recover from large violation in the early episodes by playing strictly safe policies. In the adversarial regime, \emph{i.e.}, when the constraints may change arbitrarily between episodes, our algorithm ensures sublinear constraint violation without Slater's condition, and achieves sublinear $α$-regret with respect to the \emph{unconstrained} optimum, where $α$ is a suitably defined multiplicative approximation factor. We further validate our results through synthetic experiments, showing the practical effectiveness of our algorithm. △ Less",https://arxiv.org/abs/2509.20114,arxiv_play_page0.csv
The role of photospheric magnetic flux diffusion in initiation of solar eruptions,"Xinkai Bian, Chaowei Jiang, Yang Wang, Peng Zou, Xueshang Feng, Pingbing Zuo, Yi Wang","Solar eruptions may occur at different evolutionary stages of active regions, during which the photospheric motions manifest in various forms, including flux emergence, sunspot rotation, shearing, converging, and magnetic flux diffusion. However, it remains unclear what are the specific roles played by these different motions in leading to eruptions. Here, we employ high resolution magnetohydrodynamic simulations to demonstrate how solar eruptions can be initiated in a single bipolar configuration, driven by first shearing and then flux diffusion at the bottom surface. Flux diffusion disperses the photospheric magnetic flux, driving portions of it toward the polarity inversion line (PIL). This process leads to the expansion of core field, enhancing the pinching effect to form the current sheet. When magnetic reconnection occurs within this current sheet, the eruption is initiated, characterized by a rapid release of magnetic energy and accompanied by the formation of a erupting flux rope. Additionally, flux diffusion contributes to magnetic cancellation near the PIL, leading to the formation of a weakly twisted magnetic flux rope prior to the eruption. However, this pre-exist flux rope plays a limited role in eruption initiation, as its spatial position remains largely unchanged throughout the eruption. These findings demonstrate that the primary role of flux diffusion is to facilitate current sheet formation, highlighting the critical role of current sheet formation in eruption initiation. △ Less",https://arxiv.org/abs/2509.20040,arxiv_play_page0.csv
PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning,"Xueliang Zhao, Wei Wu, Jian Guan, Zhuocheng Gong, Lingpeng Kong","Large language models (LLMs) are evolving from conversational systems into strong reasoners for tasks such as Olympiad mathematics and competitive programming. While scaling parameters and test-time computation has driven progress, a key bottleneck is the lack of high-quality training problems: human-curated datasets are costly and limited, while existing synthetic corpora are often too easy or narrow. PromptCoT 1.0 showed that injecting rationales into prompt synthesis increases problem difficulty. Building on this, we present PromptCoT 2.0, a scalable framework that replaces hand-crafted heuristics with an expectation-maximization (EM) loop, where rationales are iteratively refined to guide prompt construction. This produces problems that are both harder and more diverse than prior corpora. The synthetic prompts support two post-training regimes: (1) Self- Play , where strong models improve autonomously via verifiable feedback without stronger teachers; and (2) Supervised Fine-Tuning (SFT), where weaker models learn from teacher-distilled traces. Extensive experiments demonstrate the effectiveness of this approach. In self- play , applying PromptCoT 2.0 to Qwen3-30B-A3B-Thinking-2507 sets new state-of-the-art results at the 30B scale, with +4.4, +4.8, and +5.3 on AIME 24/25 and HMMT 25, +6.1 and +5.0 on LiveCodeBench v5/v6, and +35 Elo on Codeforces. In SFT, training Qwen2.5-7B-Instruct solely on synthetic prompts boosts accuracy to 73.1 (AIME 24), 65.6 (AIME 25), and 53.4 (LiveCodeBench v5), surpassing models trained on human or hybrid data. Analyses further confirm that PromptCoT 2.0 yields fundamentally harder and distributionally distinct problems. These results establish prompt synthesis as a new axis for scaling reasoning and position PromptCoT 2.0 as a scalable foundation for future open-source models. The implementation is available at https://github.com/inclusionAI/PromptCoT. △ Less",https://arxiv.org/abs/2509.19894,arxiv_play_page0.csv
