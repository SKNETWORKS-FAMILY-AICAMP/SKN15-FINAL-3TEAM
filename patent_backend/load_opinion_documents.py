"""
ì‹¬ì‚¬ì˜ê²¬ì„œ ë°ì´í„°ë¥¼ RDSì— ì ì¬
"""
import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch

# RDS ì—°ê²° ì •ë³´
DB_CONFIG = {
    'dbname': 'patent_db',
    'user': 'postgres',
    'password': '3-bengio123',
    'host': 'my-patent-db.c9iw88yiic4o.ap-northeast-2.rds.amazonaws.com',
    'port': '5432'
}

# CSV íŒŒì¼ ê²½ë¡œ
CSV_FILE = '/home/juhyeong/workspace/opinion_v0.1.csv'

# ë°°ì¹˜ í¬ê¸°
BATCH_SIZE = 500

def load_opinion_documents():
    """
    ì‹¬ì‚¬ì˜ê²¬ì„œ ë°ì´í„° ì ì¬
    """

    print(f"\n{'='*60}")
    print(f"  ì‹¬ì‚¬ì˜ê²¬ì„œ ë°ì´í„° RDS ì ì¬")
    print(f"{'='*60}\n")

    # RDS ì—°ê²°
    print("ğŸ“¡ RDS ì—°ê²° ì¤‘...")
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        print("âœ… RDS ì—°ê²° ì„±ê³µ\n")
    except Exception as e:
        print(f"âŒ RDS ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    cur.execute("SELECT COUNT(*) FROM opinion_documents")
    existing_count = cur.fetchone()[0]

    print(f"â„¹ï¸  ê¸°ì¡´ ë°ì´í„°: {existing_count:,}ê±´")
    print(f"â„¹ï¸  ê¸°ì¡´ ë°ì´í„° ìœ ì§€í•˜ê³  ìƒˆ ë°ì´í„°ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.\n")

    # CSV íŒŒì¼ í¬ê¸° í™•ì¸
    import os
    file_size_mb = os.path.getsize(CSV_FILE) / (1024 * 1024)
    print(f"ğŸ“‚ CSV íŒŒì¼: {CSV_FILE}")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB\n")

    # pandas chunksizeë¡œ ìŠ¤íŠ¸ë¦¬ë° ì½ê¸°
    chunk_size = 500
    total_inserted = 0
    total_skipped = 0

    print(f"ğŸ’¾ ë°ì´í„° ì ì¬ ì¤‘... (ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE})")
    print(f"ğŸ§  ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹\n")

    try:
        # CSVë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
        for chunk_idx, df_chunk in enumerate(pd.read_csv(CSV_FILE, chunksize=chunk_size)):
            batch_data = []

            for _, row in df_chunk.iterrows():
                # application_number ê²€ì¦
                app_number = row.get('application_number')
                content = row.get('full_text')

                if pd.isna(app_number) or str(app_number).strip() == '':
                    total_skipped += 1
                    continue

                if pd.isna(content) or str(content).strip() == '':
                    total_skipped += 1
                    continue

                # ë°ì´í„° ì¤€ë¹„
                batch_data.append((
                    str(app_number).strip(),
                    str(content),
                ))

            # ë°°ì¹˜ ì‚½ì…
            if batch_data:
                insert_query = """
                    INSERT INTO opinion_documents (
                        application_number, full_text, created_at, updated_at
                    ) VALUES (
                        %s, %s, NOW(), NOW()
                    )
                """

                execute_batch(cur, insert_query, batch_data, page_size=BATCH_SIZE)
                conn.commit()

                total_inserted += len(batch_data)
                print(f"  âœ“ {total_inserted:,}ê±´ ì²˜ë¦¬ ì™„ë£Œ (ì²­í¬ {chunk_idx + 1})")

        print(f"\n{'='*60}")
        print(f"  ì ì¬ ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"âœ… ì²˜ë¦¬: {total_inserted:,}ê±´")
        print(f"âš ï¸  ê±´ë„ˆëœ€: {total_skipped:,}ê±´")

        # ìµœì¢… í™•ì¸
        cur.execute("SELECT COUNT(*) FROM opinion_documents")
        final_count = cur.fetchone()[0]
        print(f"ğŸ“Š ì´ ë°ì´í„°: {final_count:,}ê±´\n")

    except Exception as e:
        conn.rollback()
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cur.close()
        conn.close()
        print("\nğŸ”Œ RDS ì—°ê²° ì¢…ë£Œ")


if __name__ == '__main__':
    load_opinion_documents()
