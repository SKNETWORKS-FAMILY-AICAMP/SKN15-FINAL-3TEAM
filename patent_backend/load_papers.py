"""
ë…¼ë¬¸ ë°ì´í„°ë¥¼ RDSì— ì ì¬
"""
import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch

# RDS ì—°ê²° ì •ë³´
DB_CONFIG = {
    'dbname': 'patent_db',
    'user': 'postgres',
    'password': '3-bengio123',
    'host': 'my-patent-db.c9iw88yiic4o.ap-northeast-2.rds.amazonaws.com',
    'port': '5432'
}

# CSV íŒŒì¼ ê²½ë¡œ
CSV_FILE = '/home/juhyeong/workspace/papers_final_translated.csv'

# ë°°ì¹˜ í¬ê¸°
BATCH_SIZE = 100

def load_papers():
    """
    ë…¼ë¬¸ ë°ì´í„° ì ì¬
    """

    print(f"\n{'='*60}")
    print(f"  ë…¼ë¬¸ ë°ì´í„° RDS ì ì¬")
    print(f"{'='*60}\n")

    # RDS ì—°ê²°
    print("ğŸ“¡ RDS ì—°ê²° ì¤‘...")
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        print("âœ… RDS ì—°ê²° ì„±ê³µ\n")
    except Exception as e:
        print(f"âŒ RDS ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    cur.execute("SELECT COUNT(*) FROM papers")
    existing_count = cur.fetchone()[0]

    print(f"â„¹ï¸  ê¸°ì¡´ ë°ì´í„°: {existing_count:,}ê±´")
    print(f"â„¹ï¸  ê¸°ì¡´ ë°ì´í„° ìœ ì§€í•˜ê³  ìƒˆ ë°ì´í„°ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.\n")

    # CSV íŒŒì¼ í¬ê¸° í™•ì¸
    import os
    file_size_mb = os.path.getsize(CSV_FILE) / (1024 * 1024)
    print(f"ğŸ“‚ CSV íŒŒì¼: {CSV_FILE}")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB\n")

    print(f"ğŸ’¾ ë°ì´í„° ì ì¬ ì¤‘... (ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE})\n")

    try:
        # CSV ì „ì²´ ì½ê¸° (ì‘ì€ íŒŒì¼ì´ë¼ í•œ ë²ˆì— ì½ì–´ë„ ë¨)
        df = pd.read_csv(CSV_FILE, encoding='utf-8-sig')  # BOM ì œê±°

        print(f"ğŸ“Š CSVì—ì„œ {len(df)}ê±´ ë¡œë“œ ì™„ë£Œ\n")

        batch_data = []
        total_inserted = 0
        total_skipped = 0

        for _, row in df.iterrows():
            # title_kr ê²€ì¦ (í•„ìˆ˜ í•„ë“œ)
            title_kr = row.get('Title_KR')

            if pd.isna(title_kr) or str(title_kr).strip() == '':
                total_skipped += 1
                continue

            # ë°ì´í„° ì¤€ë¹„
            batch_data.append((
                str(row.get('Title_EN', '')) if pd.notna(row.get('Title_EN')) else None,
                str(title_kr).strip(),
                str(row.get('Authors', '')) if pd.notna(row.get('Authors')) else None,
                str(row.get('Abstract_EN', '')) if pd.notna(row.get('Abstract_EN')) else None,
                str(row.get('Abstract_KR', '')) if pd.notna(row.get('Abstract_KR')) else None,
                str(row.get('Abstract_Page_Link', '')) if pd.notna(row.get('Abstract_Page_Link')) else None,
                str(row.get('PDF_Link', '')) if pd.notna(row.get('PDF_Link')) else None,
                str(row.get('source_file', '')) if pd.notna(row.get('source_file')) else None,
            ))

            # ë°°ì¹˜ í¬ê¸°ë§ˆë‹¤ ì‚½ì…
            if len(batch_data) >= BATCH_SIZE:
                insert_query = """
                    INSERT INTO papers (
                        title_en, title_kr, authors, abstract_en, abstract_kr,
                        abstract_page_link, pdf_link, source_file,
                        created_at, updated_at
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW()
                    )
                """

                execute_batch(cur, insert_query, batch_data, page_size=BATCH_SIZE)
                conn.commit()

                total_inserted += len(batch_data)
                print(f"  âœ“ {total_inserted:,}ê±´ ì ì¬ ì™„ë£Œ")
                batch_data = []

        # ë‚¨ì€ ë°ì´í„° ì‚½ì…
        if batch_data:
            insert_query = """
                INSERT INTO papers (
                    title_en, title_kr, authors, abstract_en, abstract_kr,
                    abstract_page_link, pdf_link, source_file,
                    created_at, updated_at
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW()
                )
            """

            execute_batch(cur, insert_query, batch_data, page_size=BATCH_SIZE)
            conn.commit()

            total_inserted += len(batch_data)
            print(f"  âœ“ {total_inserted:,}ê±´ ì ì¬ ì™„ë£Œ")

        print(f"\n{'='*60}")
        print(f"  ì ì¬ ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"âœ… ì„±ê³µ: {total_inserted:,}ê±´")
        print(f"âš ï¸  ê±´ë„ˆëœ€: {total_skipped:,}ê±´")

        # ìµœì¢… í™•ì¸
        cur.execute("SELECT COUNT(*) FROM papers")
        final_count = cur.fetchone()[0]
        print(f"ğŸ“Š ì´ ë°ì´í„°: {final_count:,}ê±´\n")

        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        cur.execute("SELECT title_kr, authors FROM papers LIMIT 3")
        print("ğŸ“‹ ìƒ˜í”Œ ë…¼ë¬¸:")
        for title, authors in cur.fetchall():
            print(f"  - {title[:50]}... (ì €ì: {authors})")

    except Exception as e:
        conn.rollback()
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cur.close()
        conn.close()
        print("\nğŸ”Œ RDS ì—°ê²° ì¢…ë£Œ")


if __name__ == '__main__':
    load_papers()
